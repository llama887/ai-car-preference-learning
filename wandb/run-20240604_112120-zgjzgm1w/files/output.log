Epoch 0/1000, Train Loss: 1.932428240776062, Val Loss: 0.5647507905960083, Train Acc: 0.5, Val Acc: 1.0, LR: 3.183997940105209e-05
Epoch 10/1000, Train Loss: 2.7758240699768066, Val Loss: 0.5023244619369507, Train Acc: 0.525, Val Acc: 1.0, LR: 3.120829707791141e-05
Epoch 20/1000, Train Loss: 1.7371960878372192, Val Loss: 0.45776453614234924, Train Acc: 0.575, Val Acc: 1.0, LR: 3.057661475477073e-05
Epoch 30/1000, Train Loss: 2.947692036628723, Val Loss: 0.4275667071342468, Train Acc: 0.5, Val Acc: 1.0, LR: 2.9944932431630076e-05
Epoch 40/1000, Train Loss: 2.120370030403137, Val Loss: 0.39740025997161865, Train Acc: 0.525, Val Acc: 1.0, LR: 2.9313250108489436e-05
Epoch 50/1000, Train Loss: 1.5528172254562378, Val Loss: 0.35943588614463806, Train Acc: 0.6, Val Acc: 1.0, LR: 2.8681567785348782e-05
Epoch 60/1000, Train Loss: 1.76228266954422, Val Loss: 0.3331857919692993, Train Acc: 0.65, Val Acc: 1.0, LR: 2.8049885462208132e-05
Epoch 70/1000, Train Loss: 1.7216838598251343, Val Loss: 0.3149002194404602, Train Acc: 0.7, Val Acc: 1.0, LR: 2.741820313906748e-05
Epoch 80/1000, Train Loss: 2.603896677494049, Val Loss: 0.2812879681587219, Train Acc: 0.575, Val Acc: 1.0, LR: 2.678652081592682e-05
Epoch 90/1000, Train Loss: 1.7533525228500366, Val Loss: 0.2590167224407196, Train Acc: 0.625, Val Acc: 1.0, LR: 2.6154838492786174e-05
Epoch 100/1000, Train Loss: 1.659037172794342, Val Loss: 0.23993416130542755, Train Acc: 0.75, Val Acc: 1.0, LR: 2.5523156169645517e-05
Epoch 110/1000, Train Loss: 1.6841336488723755, Val Loss: 0.23687395453453064, Train Acc: 0.55, Val Acc: 1.0, LR: 2.4891473846504873e-05
Epoch 120/1000, Train Loss: 1.1217496395111084, Val Loss: 0.22268514335155487, Train Acc: 0.775, Val Acc: 1.0, LR: 2.4259791523364226e-05
Epoch 130/1000, Train Loss: 2.337958514690399, Val Loss: 0.2072843611240387, Train Acc: 0.625, Val Acc: 1.0, LR: 2.362810920022358e-05
Epoch 140/1000, Train Loss: 1.0723449885845184, Val Loss: 0.19198186695575714, Train Acc: 0.75, Val Acc: 1.0, LR: 2.2996426877082932e-05
Epoch 150/1000, Train Loss: 1.2651826739311218, Val Loss: 0.1782713234424591, Train Acc: 0.725, Val Acc: 1.0, LR: 2.2364744553942295e-05
Epoch 160/1000, Train Loss: 1.2969541549682617, Val Loss: 0.17066186666488647, Train Acc: 0.7, Val Acc: 1.0, LR: 2.173306223080164e-05
Epoch 170/1000, Train Loss: 1.7467400431632996, Val Loss: 0.15715070068836212, Train Acc: 0.625, Val Acc: 1.0, LR: 2.1101379907660994e-05
Epoch 180/1000, Train Loss: 1.4633674025535583, Val Loss: 0.1511116772890091, Train Acc: 0.775, Val Acc: 1.0, LR: 2.046969758452034e-05
Epoch 190/1000, Train Loss: 1.1924075782299042, Val Loss: 0.141808420419693, Train Acc: 0.725, Val Acc: 1.0, LR: 1.983801526137969e-05
Epoch 200/1000, Train Loss: 1.4586102962493896, Val Loss: 0.13083890080451965, Train Acc: 0.8, Val Acc: 1.0, LR: 1.9206332938239036e-05
Epoch 210/1000, Train Loss: 2.227975010871887, Val Loss: 0.12421347945928574, Train Acc: 0.675, Val Acc: 1.0, LR: 1.8574650615098382e-05
Epoch 220/1000, Train Loss: 1.6231838464736938, Val Loss: 0.11918894946575165, Train Acc: 0.6, Val Acc: 1.0, LR: 1.7942968291957742e-05
Epoch 230/1000, Train Loss: 0.8429146409034729, Val Loss: 0.11062709987163544, Train Acc: 0.775, Val Acc: 1.0, LR: 1.7311285968817095e-05
Epoch 240/1000, Train Loss: 1.5157091617584229, Val Loss: 0.10620345920324326, Train Acc: 0.75, Val Acc: 1.0, LR: 1.6679603645676455e-05
Epoch 250/1000, Train Loss: 0.6612660884857178, Val Loss: 0.10190123319625854, Train Acc: 0.825, Val Acc: 1.0, LR: 1.604792132253581e-05
Epoch 260/1000, Train Loss: 1.2638577222824097, Val Loss: 0.10084117949008942, Train Acc: 0.725, Val Acc: 1.0, LR: 1.541623899939517e-05
Epoch 270/1000, Train Loss: 1.0388051271438599, Val Loss: 0.0950654149055481, Train Acc: 0.75, Val Acc: 1.0, LR: 1.478455667625452e-05
Epoch 280/1000, Train Loss: 0.9012340009212494, Val Loss: 0.09030821919441223, Train Acc: 0.725, Val Acc: 1.0, LR: 1.4152874353113872e-05
Epoch 290/1000, Train Loss: 1.4197803735733032, Val Loss: 0.0884399265050888, Train Acc: 0.725, Val Acc: 1.0, LR: 1.3521192029973221e-05
Epoch 300/1000, Train Loss: 1.3387552499771118, Val Loss: 0.0878533273935318, Train Acc: 0.725, Val Acc: 1.0, LR: 1.2889509706832571e-05
Epoch 310/1000, Train Loss: 1.1173774600028992, Val Loss: 0.08597438782453537, Train Acc: 0.8, Val Acc: 1.0, LR: 1.225782738369192e-05
Epoch 320/1000, Train Loss: 0.4761347696185112, Val Loss: 0.07965363562107086, Train Acc: 0.8, Val Acc: 1.0, LR: 1.162614506055127e-05
Epoch 330/1000, Train Loss: 1.423250526189804, Val Loss: 0.07324525713920593, Train Acc: 0.825, Val Acc: 1.0, LR: 1.099446273741062e-05
Epoch 340/1000, Train Loss: 0.8561380505561829, Val Loss: 0.07137616723775864, Train Acc: 0.75, Val Acc: 1.0, LR: 1.036278041426997e-05
Epoch 350/1000, Train Loss: 0.7547191083431244, Val Loss: 0.07141638547182083, Train Acc: 0.85, Val Acc: 1.0, LR: 9.731098091129319e-06
Epoch 360/1000, Train Loss: 0.7757889628410339, Val Loss: 0.07245153188705444, Train Acc: 0.8, Val Acc: 1.0, LR: 9.099415767988668e-06
Epoch 370/1000, Train Loss: 0.6567951142787933, Val Loss: 0.07038477808237076, Train Acc: 0.775, Val Acc: 1.0, LR: 8.467733444848018e-06
Epoch 380/1000, Train Loss: 1.2985433340072632, Val Loss: 0.06803139299154282, Train Acc: 0.7, Val Acc: 1.0, LR: 7.836051121707368e-06
Epoch 390/1000, Train Loss: 0.8914307653903961, Val Loss: 0.06426458060741425, Train Acc: 0.775, Val Acc: 1.0, LR: 7.204368798566718e-06
Epoch 400/1000, Train Loss: 0.6323941349983215, Val Loss: 0.06423874199390411, Train Acc: 0.85, Val Acc: 1.0, LR: 6.57268647542607e-06
Epoch 410/1000, Train Loss: 0.5012626945972443, Val Loss: 0.06353414058685303, Train Acc: 0.875, Val Acc: 1.0, LR: 5.941004152285422e-06
Epoch 420/1000, Train Loss: 0.5655101537704468, Val Loss: 0.0632232278585434, Train Acc: 0.875, Val Acc: 1.0, LR: 5.309321829144772e-06
Epoch 430/1000, Train Loss: 0.82997927069664, Val Loss: 0.06293463706970215, Train Acc: 0.85, Val Acc: 1.0, LR: 4.6776395060041215e-06
Epoch 440/1000, Train Loss: 0.677903562784195, Val Loss: 0.0630359873175621, Train Acc: 0.875, Val Acc: 1.0, LR: 4.045957182863472e-06
Epoch 450/1000, Train Loss: 0.6187252104282379, Val Loss: 0.06248049810528755, Train Acc: 0.85, Val Acc: 1.0, LR: 3.414274859722825e-06
Epoch 460/1000, Train Loss: 0.7860349416732788, Val Loss: 0.06247345358133316, Train Acc: 0.85, Val Acc: 1.0, LR: 2.7825925365821804e-06
Epoch 470/1000, Train Loss: 0.5449569076299667, Val Loss: 0.06191824749112129, Train Acc: 0.875, Val Acc: 1.0, LR: 2.150910213441534e-06
Epoch 480/1000, Train Loss: 0.5958926975727081, Val Loss: 0.061448026448488235, Train Acc: 0.825, Val Acc: 1.0, LR: 1.5192278903008879e-06
Epoch 490/1000, Train Loss: 1.1172917187213898, Val Loss: 0.061097800731658936, Train Acc: 0.8, Val Acc: 1.0, LR: 8.875455671602418e-07
Epoch 500/1000, Train Loss: 0.8694606125354767, Val Loss: 0.060912489891052246, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 510/1000, Train Loss: 0.8030393719673157, Val Loss: 0.060851942747831345, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 520/1000, Train Loss: 0.46430203318595886, Val Loss: 0.060807377099990845, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 530/1000, Train Loss: 1.322275549173355, Val Loss: 0.060738854110240936, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 540/1000, Train Loss: 0.3704812675714493, Val Loss: 0.06066662818193436, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 550/1000, Train Loss: 0.6585681736469269, Val Loss: 0.060631465166807175, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 560/1000, Train Loss: 1.3497174084186554, Val Loss: 0.06055312603712082, Train Acc: 0.775, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 570/1000, Train Loss: 0.5483653545379639, Val Loss: 0.060464758425951004, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 580/1000, Train Loss: 0.7680880427360535, Val Loss: 0.06028091162443161, Train Acc: 0.825, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 590/1000, Train Loss: 1.2083483338356018, Val Loss: 0.060272328555583954, Train Acc: 0.775, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 600/1000, Train Loss: 0.9783178567886353, Val Loss: 0.06015969440340996, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 610/1000, Train Loss: 1.2573582530021667, Val Loss: 0.06008879095315933, Train Acc: 0.775, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 620/1000, Train Loss: 1.2800366282463074, Val Loss: 0.06010289117693901, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 630/1000, Train Loss: 0.34737952053546906, Val Loss: 0.0601675882935524, Train Acc: 0.925, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 640/1000, Train Loss: 0.5987226366996765, Val Loss: 0.060265980660915375, Train Acc: 0.825, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 650/1000, Train Loss: 0.8157236576080322, Val Loss: 0.06025699898600578, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 660/1000, Train Loss: 1.2519989013671875, Val Loss: 0.0601332001388073, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 670/1000, Train Loss: 0.751738429069519, Val Loss: 0.06011459231376648, Train Acc: 0.825, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 680/1000, Train Loss: 0.7957416474819183, Val Loss: 0.060114819556474686, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 690/1000, Train Loss: 0.95722496509552, Val Loss: 0.059968251734972, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 700/1000, Train Loss: 0.7576215267181396, Val Loss: 0.05989522486925125, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 710/1000, Train Loss: 0.39271412789821625, Val Loss: 0.05997898429632187, Train Acc: 0.925, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 720/1000, Train Loss: 0.7190888375043869, Val Loss: 0.060057032853364944, Train Acc: 0.775, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 730/1000, Train Loss: 0.6115393787622452, Val Loss: 0.060061048716306686, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
[34m[1mwandb[39m[22m: [33mWARNING[39m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'Train Loss': 1.932428240776062, 'Validation Loss': 0.5647507905960083, 'Train Accuracy': 0.5, 'Validation Accuracy': 1.0, '_timestamp': 1717514481.582835}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.weight': {'_type': 'histogram', 'values': [5213, 5381, 5463, 5343, 5316, 5363, 5270, 5170, 5281, 5439, 5328, 5236, 5337, 5242, 5268, 5348, 5213, 5347, 5428, 5367, 5260, 5269, 5373, 5448, 5461, 5283, 5371, 5355, 5364, 5406, 5369, 5473, 5220, 5392, 5461, 5339, 5284, 5323, 5465, 5257, 5414, 5309, 5459, 5406, 5492, 5312, 5373, 5324, 5414, 5363, 5485, 5395, 5382, 5345, 5369, 5380, 5482, 5521, 5296, 5484, 5343, 5431, 5376, 5219], 'bins': [-0.09684529900550842, -0.09381882846355438, -0.09079236537218094, -0.0877658948302269, -0.08473942428827286, -0.08171295374631882, -0.07868649065494537, -0.07566002011299133, -0.07263354957103729, -0.06960708647966385, -0.06658061593770981, -0.06355414539575577, -0.060527678579092026, -0.057501208037137985, -0.05447474122047424, -0.0514482706785202, -0.04842180386185646, -0.04539533704519272, -0.04236886650323868, -0.039342399686574936, -0.036315929144620895, -0.03328946232795715, -0.030262993648648262, -0.02723652496933937, -0.02421005629003048, -0.021183587610721588, -0.018157118931412697, -0.01513065118342638, -0.012104182504117489, -0.009077713824808598, -0.006051245611160994, -0.003024777164682746, 1.691281795501709e-06, 0.0030281597282737494, 0.006054628174751997, 0.009081096388399601, 0.012107565067708492, 0.015134033747017384, 0.0181605014950037, 0.02118697017431259, 0.024213438853621483, 0.027239907532930374, 0.030266376212239265, 0.03329284489154816, 0.0363193117082119, 0.03934578225016594, 0.04237224906682968, 0.04539871960878372, 0.048425186425447464, 0.051451653242111206, 0.05447812378406525, 0.05750459060072899, 0.06053106114268303, 0.06355752795934677, 0.06658399850130081, 0.06961046904325485, 0.0726369321346283, 0.07566340267658234, 0.07868987321853638, 0.08171633630990982, 0.08474280685186386, 0.0877692773938179, 0.09079574793577194, 0.09382221102714539, 0.09684868156909943]}, '_timestamp': 1717514481.587928}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.bias': {'_type': 'histogram', 'values': [2, 8, 6, 6, 8, 9, 8, 8, 4, 8, 4, 5, 4, 8, 6, 9, 4, 7, 8, 4, 5, 2, 3, 7, 3, 8, 4, 5, 8, 5, 2, 3, 9, 7, 3, 9, 6, 5, 8, 10, 3, 12, 2, 7, 5, 8, 5, 6, 6, 3, 11, 6, 4, 3, 5, 6, 7, 7, 4, 5, 5, 12, 5, 6], 'bins': [-0.03259245678782463, -0.031567081809043884, -0.030541706830263138, -0.02951633185148239, -0.028490956872701645, -0.0274655818939209, -0.026440206915140152, -0.025414831936359406, -0.02438945695757866, -0.023364081978797913, -0.022338707000017166, -0.02131333202123642, -0.020287957042455673, -0.019262582063674927, -0.01823720708489418, -0.017211832106113434, -0.016186457127332687, -0.015161081217229366, -0.01413570623844862, -0.013110331259667873, -0.012084956280887127, -0.01105958130210638, -0.010034206323325634, -0.009008831344544888, -0.007983455434441566, -0.006958080921322107, -0.005932705942541361, -0.004907330963760614, -0.0038819557521492243, -0.002856580773368478, -0.0018312056781724095, -0.0008058306411840022, 0.0002195443958044052, 0.0012449193745851517, 0.002270294353365898, 0.0032956695649772882, 0.004321044310927391, 0.005346419755369425, 0.006371794734150171, 0.007397169712930918, 0.008422544226050377, 0.009447920136153698, 0.010473295114934444, 0.011498670093715191, 0.012524045072495937, 0.013549420051276684, 0.01457479503005743, 0.015600170008838177, 0.016625545918941498, 0.017650920897722244, 0.01867629587650299, 0.019701670855283737, 0.020727045834064484, 0.02175242081284523, 0.022777795791625977, 0.023803170770406723, 0.02482854574918747, 0.025853920727968216, 0.026879295706748962, 0.02790467068552971, 0.028930045664310455, 0.029955420643091202, 0.030980795621871948, 0.032006170600652695, 0.03303154557943344]}, '_timestamp': 1717514481.588181}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.weight': {'_type': 'histogram', 'values': [202, 22, 8, 10, 3, 1, 1, 2, 3, 2, 0, 2, 1, 3, 4, 0, 3, 2, 2, 1, 3, 2, 2, 2, 2, 2, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 3, 4, 2, 3, 4, 0, 3, 1, 3, 4, 3, 2, 0, 1, 3, 2, 0, 3, 6, 4, 2, 1, 2, 7, 10, 11], 'bins': [0.9999362230300903, 0.9999381899833679, 0.9999402165412903, 0.9999421834945679, 0.9999442100524902, 0.9999461770057678, 0.9999482035636902, 0.9999501705169678, 0.9999521970748901, 0.9999541640281677, 0.9999561905860901, 0.9999581575393677, 0.99996018409729, 0.9999621510505676, 0.99996417760849, 0.9999661445617676, 0.9999681711196899, 0.9999701380729675, 0.9999721050262451, 0.9999741315841675, 0.9999760985374451, 0.9999781250953674, 0.999980092048645, 0.9999821186065674, 0.999984085559845, 0.9999861121177673, 0.9999880790710449, 0.9999901056289673, 0.9999920725822449, 0.9999940991401672, 0.9999960660934448, 0.9999980926513672, 1.0, 1.0000020265579224, 1.0000040531158447, 1.000006079673767, 1.0000079870224, 1.0000100135803223, 1.0000120401382446, 1.000014066696167, 1.0000159740447998, 1.0000180006027222, 1.0000200271606445, 1.000022053718567, 1.0000239610671997, 1.000025987625122, 1.0000280141830444, 1.0000300407409668, 1.0000319480895996, 1.000033974647522, 1.0000360012054443, 1.0000379085540771, 1.0000399351119995, 1.0000419616699219, 1.0000439882278442, 1.000045895576477, 1.0000479221343994, 1.0000499486923218, 1.0000519752502441, 1.000053882598877, 1.0000559091567993, 1.0000579357147217, 1.000059962272644, 1.0000618696212769, 1.0000638961791992]}, '_timestamp': 1717514481.588368}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.bias': {'_type': 'histogram', 'values': [26, 9, 14, 3, 7, 27, 2, 2, 2, 1, 3, 1, 2, 1, 0, 1, 2, 1, 6, 1, 3, 1, 2, 5, 3, 3, 1, 3, 0, 0, 0, 0, 122, 0, 0, 0, 4, 1, 0, 1, 1, 1, 1, 3, 2, 2, 2, 5, 1, 4, 0, 4, 1, 3, 3, 1, 3, 2, 34, 4, 7, 10, 8, 19], 'bins': [-6.381690036505461e-05, -6.182262586662546e-05, -5.9828355006175116e-05, -5.7834080507745966e-05, -5.5839809647295624e-05, -5.3845535148866475e-05, -5.1851260650437325e-05, -4.985698978998698e-05, -4.7862715291557834e-05, -4.586844443110749e-05, -4.387416993267834e-05, -4.187989543424919e-05, -3.988562457379885e-05, -3.78913500753697e-05, -3.589707921491936e-05, -3.390280471649021e-05, -3.190853021806106e-05, -2.9914259357610717e-05, -2.791998667817097e-05, -2.5925712179741822e-05, -2.3931439500302076e-05, -2.193716682086233e-05, -1.9942894141422585e-05, -1.794862146198284e-05, -1.5954348782543093e-05, -1.3960075193608645e-05, -1.1965801604674198e-05, -9.971528925234452e-06, -7.977256245794706e-06, -5.9829826568602584e-06, -3.988709977420513e-06, -1.994436843233416e-06, -1.6370904631912708e-10, 1.9941094251407776e-06, 3.988382559327874e-06, 5.98265523876762e-06, 7.976928827702068e-06, 9.971201507141814e-06, 1.196547418658156e-05, 1.3959747775516007e-05, 1.5954021364450455e-05, 1.79482940438902e-05, 1.9942566723329946e-05, 2.1936839402769692e-05, 2.3931112082209438e-05, 2.5925384761649184e-05, 2.7919659260078333e-05, 2.991393193951808e-05, 3.190820279996842e-05, 3.390247729839757e-05, 3.589675179682672e-05, 3.789102265727706e-05, 3.988529715570621e-05, 4.1879568016156554e-05, 4.3873842514585704e-05, 4.586811701301485e-05, 4.7862387873465195e-05, 4.9856662371894345e-05, 5.185093323234469e-05, 5.3845207730773836e-05, 5.5839482229202986e-05, 5.783375308965333e-05, 5.982802758808248e-05, 6.182229844853282e-05, 6.381657294696197e-05]}, '_timestamp': 1717514481.588535}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.weight': {'_type': 'histogram', 'values': [2220, 2307, 2237, 2273, 2257, 2252, 2315, 2298, 2296, 2293, 2275, 2270, 2289, 2276, 2319, 2250, 2233, 2292, 2335, 2249, 2195, 2275, 2282, 2399, 2262, 2287, 2205, 2226, 2269, 2143, 2261, 2193, 2253, 2239, 2281, 2214, 2322, 2199, 2332, 2217, 2285, 2225, 2341, 2169, 2257, 2325, 2292, 2214, 2381, 2276, 2303, 2301, 2300, 2348, 2222, 2234, 2265, 2224, 2266, 2335, 2291, 2227, 2283, 2207], 'bins': [-0.1255359649658203, -0.12161285430192947, -0.11768974363803864, -0.1137666329741478, -0.10984352231025696, -0.10592041909694672, -0.10199730843305588, -0.09807419776916504, -0.0941510871052742, -0.09022797644138336, -0.08630486577749252, -0.08238175511360168, -0.07845865190029144, -0.0745355412364006, -0.07061243057250977, -0.06668931990861893, -0.06276620924472809, -0.05884309858083725, -0.05491998791694641, -0.05099688097834587, -0.04707377031445503, -0.043150659650564194, -0.039227552711963654, -0.035304442048072815, -0.031381331384181976, -0.027458220720291138, -0.02353511191904545, -0.01961200311779976, -0.01568889245390892, -0.011765782721340656, -0.007842672988772392, -0.003919563256204128, 3.546476364135742e-06, 0.0039266562089324, 0.007849765941500664, 0.011772875674068928, 0.015695985406637192, 0.01961909607052803, 0.02354220487177372, 0.02746531367301941, 0.03138842433691025, 0.035311535000801086, 0.039234645664691925, 0.043157752603292465, 0.047080863267183304, 0.05100397393107414, 0.05492708086967468, 0.05885019153356552, 0.06277330219745636, 0.0666964128613472, 0.07061952352523804, 0.07454263418912888, 0.07846574485301971, 0.08238884806632996, 0.0863119587302208, 0.09023506939411163, 0.09415818005800247, 0.09808129072189331, 0.10200440138578415, 0.10592751204967499, 0.10985061526298523, 0.11377372592687607, 0.1176968365907669, 0.12161994725465775, 0.12554305791854858]}, '_timestamp': 1717514481.589504}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.bias': {'_type': 'histogram', 'values': [9, 8, 3, 4, 5, 9, 4, 7, 6, 12, 3, 4, 7, 9, 7, 5, 9, 8, 8, 6, 4, 4, 8, 4, 8, 5, 3, 4, 5, 5, 10, 7, 8, 7, 6, 10, 4, 7, 6, 4, 1, 1, 7, 5, 5, 5, 9, 3, 6, 8, 2, 4, 6, 6, 11, 4, 4, 9, 4, 2, 5, 8, 6, 8], 'bins': [-0.05087820440530777, -0.0492853969335556, -0.04769258573651314, -0.04609977453947067, -0.044506967067718506, -0.04291415959596634, -0.041321348398923874, -0.03972853720188141, -0.03813572973012924, -0.036542922258377075, -0.03495011106133461, -0.033357299864292145, -0.03176449239253998, -0.030171683058142662, -0.028578873723745346, -0.02698606438934803, -0.025393255054950714, -0.023800445720553398, -0.022207636386156082, -0.020614827051758766, -0.01902201771736145, -0.017429208382964134, -0.015836399048566818, -0.014243589714169502, -0.012650780379772186, -0.01105797104537487, -0.009465161710977554, -0.007872352376580238, -0.006279543042182922, -0.004686733707785606, -0.0030939243733882904, -0.0015011150389909744, 9.169429540634155e-05, 0.0016845036298036575, 0.0032773129642009735, 0.0048701222985982895, 0.0064629316329956055, 0.008055740967392921, 0.009648550301790237, 0.011241359636187553, 0.01283416897058487, 0.014426978304982185, 0.0160197876393795, 0.017612596973776817, 0.019205406308174133, 0.02079821564257145, 0.022391024976968765, 0.02398383431136608, 0.025576643645763397, 0.027169452980160713, 0.02876226231455803, 0.030355071648955345, 0.03194788098335266, 0.03354068845510483, 0.03513349965214729, 0.03672631084918976, 0.038319118320941925, 0.03991192579269409, 0.04150473698973656, 0.04309754818677902, 0.04469035565853119, 0.046283163130283356, 0.04787597432732582, 0.049468785524368286, 0.05106159299612045]}, '_timestamp': 1717514481.589668}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.weight': {'_type': 'histogram', 'values': [71, 30, 31, 17, 12, 3, 12, 2, 2, 1, 4, 1, 1, 4, 1, 4, 1, 3, 2, 2, 2, 2, 3, 3, 1, 4, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 2, 4, 6, 4, 5, 3, 3, 3, 6, 2, 3, 2, 2, 4, 11, 1, 8, 5, 3, 2, 4, 7, 7, 10, 11, 25], 'bins': [0.9999362230300903, 0.9999381899833679, 0.9999402165412903, 0.9999421834945679, 0.9999442100524902, 0.9999461770057678, 0.9999482035636902, 0.9999501705169678, 0.9999521970748901, 0.9999541640281677, 0.9999561905860901, 0.9999581575393677, 0.99996018409729, 0.9999621510505676, 0.99996417760849, 0.9999661445617676, 0.9999681711196899, 0.9999701380729675, 0.9999721050262451, 0.9999741315841675, 0.9999760985374451, 0.9999781250953674, 0.999980092048645, 0.9999821186065674, 0.999984085559845, 0.9999861121177673, 0.9999880790710449, 0.9999901056289673, 0.9999920725822449, 0.9999940991401672, 0.9999960660934448, 0.9999980926513672, 1.0, 1.0000020265579224, 1.0000040531158447, 1.000006079673767, 1.0000079870224, 1.0000100135803223, 1.0000120401382446, 1.000014066696167, 1.0000159740447998, 1.0000180006027222, 1.0000200271606445, 1.000022053718567, 1.0000239610671997, 1.000025987625122, 1.0000280141830444, 1.0000300407409668, 1.0000319480895996, 1.000033974647522, 1.0000360012054443, 1.0000379085540771, 1.0000399351119995, 1.0000419616699219, 1.0000439882278442, 1.000045895576477, 1.0000479221343994, 1.0000499486923218, 1.0000519752502441, 1.000053882598877, 1.0000559091567993, 1.0000579357147217, 1.000059962272644, 1.0000618696212769, 1.0000638961791992]}, '_timestamp': 1717514481.589825}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.bias': {'_type': 'histogram', 'values': [28, 16, 13, 13, 5, 18, 4, 6, 5, 6, 7, 1, 1, 1, 4, 2, 1, 5, 3, 1, 6, 2, 2, 1, 2, 6, 4, 4, 0, 0, 0, 0, 8, 0, 0, 0, 4, 4, 2, 2, 5, 4, 3, 4, 4, 6, 5, 1, 3, 5, 5, 3, 7, 7, 3, 5, 6, 6, 24, 11, 12, 11, 23, 31], 'bins': [-6.380556442309171e-05, -6.181166099850088e-05, -5.9817761211888865e-05, -5.782385778729804e-05, -5.582995436270721e-05, -5.3836050938116387e-05, -5.184215115150437e-05, -4.984824772691354e-05, -4.7854344302322716e-05, -4.5860444515710697e-05, -4.386654109111987e-05, -4.1872637666529045e-05, -3.987873424193822e-05, -3.78848344553262e-05, -3.5890931030735373e-05, -3.389702760614455e-05, -3.190312418155372e-05, -2.9909224394941702e-05, -2.7915320970350876e-05, -2.5921419364749454e-05, -2.3927515940158628e-05, -2.1933614334557205e-05, -1.993971090996638e-05, -1.7945809304364957e-05, -1.5951907698763534e-05, -1.3958004274172708e-05, -1.1964101759076584e-05, -9.97019924398046e-06, -7.976297638379037e-06, -5.982394668535562e-06, -3.988492608186789e-06, -1.9945900930906646e-06, -6.875779945403337e-10, 1.993214937101584e-06, 3.987117452197708e-06, 5.9810195125464816e-06, 7.974922482389957e-06, 9.96882408799138e-06, 1.1962726603087503e-05, 1.3956629118183628e-05, 1.5950532542774454e-05, 1.7944434148375876e-05, 1.99383357539773e-05, 2.1932239178568125e-05, 2.3926140784169547e-05, 2.5920044208760373e-05, 2.7913945814361796e-05, 2.9907849238952622e-05, 3.190174902556464e-05, 3.389565245015547e-05, 3.588955587474629e-05, 3.788345929933712e-05, 3.987735908594914e-05, 4.1871262510539964e-05, 4.386516593513079e-05, 4.5859069359721616e-05, 4.7852969146333635e-05, 4.984687257092446e-05, 5.184077599551529e-05, 5.3834675782127306e-05, 5.582857920671813e-05, 5.782248263130896e-05, 5.9816386055899784e-05, 6.18102858425118e-05, 6.380418926710263e-05]}, '_timestamp': 1717514481.589976}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.weight': {'_type': 'histogram', 'values': [2182, 2217, 2256, 2229, 2291, 2307, 2245, 2228, 2305, 2338, 2278, 2204, 2204, 2259, 2338, 2296, 2239, 2273, 2219, 2270, 2235, 2230, 2228, 2238, 2294, 2301, 2298, 2191, 2242, 2208, 2227, 2229, 2370, 2255, 2338, 2222, 2295, 2241, 2308, 2252, 2269, 2221, 2335, 2260, 2329, 2217, 2309, 2245, 2250, 2337, 2308, 2255, 2225, 2209, 2323, 2321, 2375, 2242, 2322, 2294, 2265, 2331, 2312, 2227], 'bins': [-0.12554094195365906, -0.12161758542060852, -0.11769422888755798, -0.11377087235450745, -0.10984751582145691, -0.10592415928840637, -0.10200080275535583, -0.0980774462223053, -0.09415408968925476, -0.09023074060678482, -0.08630738407373428, -0.08238402754068375, -0.07846067100763321, -0.07453731447458267, -0.07061395794153214, -0.0666906014084816, -0.06276724487543106, -0.058843888342380524, -0.05492053180932999, -0.05099717527627945, -0.04707381874322891, -0.043150465935468674, -0.03922710940241814, -0.0353037528693676, -0.03138039633631706, -0.027457039803266525, -0.023533683270215988, -0.0196103285998106, -0.015686972066760063, -0.011763615533709526, -0.007840259931981564, -0.003916903864592314, 6.452202796936035e-06, 0.003929808270186186, 0.007853164337575436, 0.011776519939303398, 0.015699876472353935, 0.019623233005404472, 0.02354658767580986, 0.027469944208860397, 0.031393300741910934, 0.03531665727496147, 0.03924001380801201, 0.043163370341062546, 0.047086723148822784, 0.05101007968187332, 0.05493343621492386, 0.058856792747974396, 0.06278014928102493, 0.06670350581407547, 0.07062686234712601, 0.07455021888017654, 0.07847357541322708, 0.08239693194627762, 0.08632028847932816, 0.09024364501237869, 0.09416699409484863, 0.09809035062789917, 0.10201370716094971, 0.10593706369400024, 0.10986042022705078, 0.11378377676010132, 0.11770713329315186, 0.12163048982620239, 0.12555384635925293]}, '_timestamp': 1717514481.590933}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.bias': {'_type': 'histogram', 'values': [5, 9, 6, 1, 5, 6, 10, 5, 8, 6, 7, 8, 8, 8, 9, 3, 5, 7, 6, 5, 5, 6, 6, 4, 2, 4, 9, 4, 3, 5, 8, 10, 9, 8, 10, 8, 4, 2, 6, 5, 7, 6, 5, 4, 6, 9, 7, 1, 3, 5, 4, 9, 4, 10, 7, 6, 6, 5, 7, 6, 6, 7, 3, 3], 'bins': [-0.05114191770553589, -0.04954399913549423, -0.047946080565452576, -0.04634816572070122, -0.04475024715065956, -0.043152328580617905, -0.04155441001057625, -0.03995649144053459, -0.038358576595783234, -0.03676065802574158, -0.03516273945569992, -0.033564820885658264, -0.03196690231561661, -0.0303689856082201, -0.028771067038178444, -0.027173150330781937, -0.02557523176074028, -0.023977313190698624, -0.022379396483302116, -0.02078147791326046, -0.019183561205863953, -0.017585642635822296, -0.01598772406578064, -0.014389806427061558, -0.012791888788342476, -0.011193971149623394, -0.009596053510904312, -0.007998134940862656, -0.006400217302143574, -0.004802299663424492, -0.0032043815590441227, -0.0016064636874943972, -8.545815944671631e-06, 0.001589372055605054, 0.0031872899271547794, 0.004785208031535149, 0.0063831256702542305, 0.007981043308973312, 0.009578961879014969, 0.01117687951773405, 0.012774797156453133, 0.014372714795172215, 0.015970632433891296, 0.017568551003932953, 0.01916646957397461, 0.020764386281371117, 0.022362304851412773, 0.02396022155880928, 0.025558140128850937, 0.027156058698892593, 0.0287539754062891, 0.030351893976330757, 0.031949810683727264, 0.03354772925376892, 0.03514564782381058, 0.036743566393852234, 0.03834148496389389, 0.03993939980864525, 0.041537318378686905, 0.04313523694872856, 0.04473315551877022, 0.046331074088811874, 0.04792898893356323, 0.04952690750360489, 0.051124826073646545]}, '_timestamp': 1717514481.5910861}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.weight': {'_type': 'histogram', 'values': [87, 31, 21, 20, 9, 13, 6, 5, 2, 4, 5, 3, 2, 4, 3, 3, 3, 4, 2, 3, 2, 3, 5, 4, 2, 1, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 4, 9, 5, 4, 6, 4, 7, 6, 4, 4, 1, 4, 1, 4, 1, 1, 5, 0, 3, 3, 3, 4, 3, 4, 9, 8, 5, 16], 'bins': [0.9999362230300903, 0.9999381899833679, 0.9999402165412903, 0.9999421834945679, 0.9999442100524902, 0.9999461770057678, 0.9999482035636902, 0.9999501705169678, 0.9999521970748901, 0.9999541640281677, 0.9999561905860901, 0.9999581575393677, 0.99996018409729, 0.9999621510505676, 0.99996417760849, 0.9999661445617676, 0.9999681711196899, 0.9999701380729675, 0.9999721050262451, 0.9999741315841675, 0.9999760985374451, 0.9999781250953674, 0.999980092048645, 0.9999821186065674, 0.999984085559845, 0.9999861121177673, 0.9999880790710449, 0.9999901056289673, 0.9999920725822449, 0.9999940991401672, 0.9999960660934448, 0.9999980926513672, 1.0, 1.0000020265579224, 1.0000040531158447, 1.000006079673767, 1.0000079870224, 1.0000100135803223, 1.0000120401382446, 1.000014066696167, 1.0000159740447998, 1.0000180006027222, 1.0000200271606445, 1.000022053718567, 1.0000239610671997, 1.000025987625122, 1.0000280141830444, 1.0000300407409668, 1.0000319480895996, 1.000033974647522, 1.0000360012054443, 1.0000379085540771, 1.0000399351119995, 1.0000419616699219, 1.0000439882278442, 1.000045895576477, 1.0000479221343994, 1.0000499486923218, 1.0000519752502441, 1.000053882598877, 1.0000559091567993, 1.0000579357147217, 1.000059962272644, 1.0000618696212769, 1.0000638961791992]}, '_timestamp': 1717514481.591239}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.bias': {'_type': 'histogram', 'values': [42, 14, 14, 16, 7, 25, 4, 6, 7, 3, 4, 5, 3, 5, 4, 6, 3, 2, 1, 3, 2, 5, 4, 4, 1, 4, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 6, 5, 7, 4, 3, 5, 2, 3, 4, 4, 6, 5, 3, 2, 2, 5, 4, 3, 2, 6, 11, 7, 14, 11, 17, 31], 'bins': [-6.381726416293532e-05, -6.182336073834449e-05, -5.982945367577486e-05, -5.783555025118403e-05, -5.58416431886144e-05, -5.384773976402357e-05, -5.185383270145394e-05, -4.985992927686311e-05, -4.786602221429348e-05, -4.5872118789702654e-05, -4.387821536511183e-05, -4.1884308302542195e-05, -3.989040487795137e-05, -3.7896497815381736e-05, -3.590259439079091e-05, -3.3908687328221276e-05, -3.191478390363045e-05, -2.992087866005022e-05, -2.792697341646999e-05, -2.593306817288976e-05, -2.3939162929309532e-05, -2.1945259504718706e-05, -1.9951354261138476e-05, -1.7957449017558247e-05, -1.5963543773978017e-05, -1.3969638530397788e-05, -1.1975733286817558e-05, -9.98182895273203e-06, -7.9879237091518e-06, -5.994018465571571e-06, -4.0001136767386924e-06, -2.0062086605321383e-06, -1.2303644325584173e-08, 1.98160137188097e-06, 3.975506388087524e-06, 5.969411176920403e-06, 7.963316420500632e-06, 9.957221664080862e-06, 1.195112599816639e-05, 1.394503124174662e-05, 1.593893648532685e-05, 1.793284172890708e-05, 1.9926746972487308e-05, 2.1920652216067538e-05, 2.3914555640658364e-05, 2.5908460884238593e-05, 2.7902366127818823e-05, 2.9896271371399052e-05, 3.189017661497928e-05, 3.388408003957011e-05, 3.587798710213974e-05, 3.787189052673057e-05, 3.98657975893002e-05, 4.1859701013891026e-05, 4.385360807646066e-05, 4.5847511501051486e-05, 4.784141492564231e-05, 4.9835321988211945e-05, 5.182922541280277e-05, 5.3823132475372404e-05, 5.581703589996323e-05, 5.781094296253286e-05, 5.980484638712369e-05, 6.179875344969332e-05, 6.379265687428415e-05]}, '_timestamp': 1717514481.5913851}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.weight': {'_type': 'histogram', 'values': [8, 9, 8, 7, 6, 5, 9, 5, 5, 4, 5, 3, 8, 2, 8, 7, 10, 7, 6, 1, 7, 4, 6, 9, 10, 10, 8, 7, 4, 7, 7, 7, 4, 3, 3, 5, 2, 5, 8, 6, 6, 7, 5, 7, 6, 2, 6, 8, 6, 8, 6, 7, 10, 3, 7, 4, 5, 9, 1, 5, 6, 1, 4, 7], 'bins': [-0.17626067996025085, -0.17074710130691528, -0.16523350775241852, -0.15971992909908295, -0.15420633554458618, -0.1486927568912506, -0.14317917823791504, -0.13766558468341827, -0.1321520060300827, -0.12663841247558594, -0.12112483382225037, -0.1156112477183342, -0.11009766906499863, -0.10458408296108246, -0.09907049685716629, -0.09355691075325012, -0.08804333209991455, -0.08252974599599838, -0.07701615989208221, -0.07150257378816605, -0.06598898768424988, -0.06047540530562401, -0.05496182292699814, -0.04944823682308197, -0.0439346507191658, -0.03842106834053993, -0.032907482236623764, -0.027393899857997894, -0.021880313754081726, -0.016366729512810707, -0.010853145271539688, -0.005339561030268669, 0.00017402321100234985, 0.005687607452273369, 0.011201191693544388, 0.016714775934815407, 0.022228360176086426, 0.027741946280002594, 0.033255528658628464, 0.03876911476254463, 0.0442826971411705, 0.04979628324508667, 0.05530986934900284, 0.06082345172762871, 0.06633703410625458, 0.07185062021017075, 0.07736420631408691, 0.08287779241800308, 0.08839137852191925, 0.09390495717525482, 0.09941854327917099, 0.10493212938308716, 0.11044571548700333, 0.1159592941403389, 0.12147288024425507, 0.12698645889759064, 0.1325000524520874, 0.13801363110542297, 0.14352722465991974, 0.1490408033132553, 0.15455438196659088, 0.16006797552108765, 0.16558155417442322, 0.17109514772891998, 0.17660872638225555]}, '_timestamp': 1717514481.591545}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.bias': {'_type': 'histogram', 'values': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'bins': [-0.5305652618408203, -0.5149402618408203, -0.4993152916431427, -0.4836902916431427, -0.4680652916431427, -0.4524402916431427, -0.4368152916431427, -0.4211902916431427, -0.4055652916431427, -0.3899402916431427, -0.3743152916431427, -0.3586902916431427, -0.3430652916431427, -0.3274402916431427, -0.3118152916431427, -0.2961902916431427, -0.2805652916431427, -0.2649402916431427, -0.2493152767419815, -0.2336902767419815, -0.2180652767419815, -0.2024402767419815, -0.1868152767419815, -0.1711902767419815, -0.1555652767419815, -0.1399402767419815, -0.1243152841925621, -0.1086902841925621, -0.0930652841925621, -0.0774402841925621, -0.0618152841925621, -0.0461902841925621, -0.030565282329916954, -0.014940282329916954, 0.000684717670083046, 0.016309717670083046, 0.0319347158074379, 0.0475597158074379, 0.0631847158074379, 0.0788097158074379, 0.0944347158074379, 0.1100597158074379, 0.1256847232580185, 0.1413097232580185, 0.1569347232580185, 0.1725597232580185, 0.1881847232580185, 0.2038097232580185, 0.2194347232580185, 0.2350597232580185, 0.2506847083568573, 0.2663097083568573, 0.2819347083568573, 0.2975597083568573, 0.3131847083568573, 0.3288097083568573, 0.3444347083568573, 0.3600597083568573, 0.3756847083568573, 0.3913097083568573, 0.4069347083568573, 0.4225597083568573, 0.4381847083568573, 0.4538097083568573, 0.4694347083568573]}, '_timestamp': 1717514481.591716}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TP Reward Distribution': {'_type': 'histogram', 'values': [1, 1, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [3.4, 4.429166666666666, 5.458333333333333, 6.487499999999999, 7.516666666666666, 8.545833333333333, 9.575, 10.604166666666666, 11.633333333333333, 12.6625, 13.691666666666666, 14.720833333333333, 15.749999999999998, 16.779166666666665, 17.80833333333333, 18.8375, 19.866666666666664, 20.89583333333333, 21.924999999999997, 22.954166666666662, 23.98333333333333, 25.012499999999996, 26.041666666666664, 27.07083333333333, 28.099999999999994, 29.129166666666663, 30.158333333333328, 31.187499999999996, 32.21666666666666, 33.24583333333333, 34.275, 35.30416666666667, 36.33333333333333, 37.3625, 38.39166666666666, 39.42083333333333, 40.449999999999996, 41.479166666666664, 42.508333333333326, 43.537499999999994, 44.56666666666666, 45.595833333333324, 46.62499999999999, 47.65416666666666, 48.68333333333333, 49.71249999999999, 50.74166666666666, 51.77083333333333, 52.79999999999999, 53.82916666666666, 54.85833333333333, 55.887499999999996, 56.91666666666666, 57.945833333333326, 58.974999999999994, 60.00416666666666, 61.033333333333324, 62.06249999999999, 63.09166666666666, 64.12083333333332, 65.14999999999999, 66.17916666666666, 67.20833333333333, 68.2375, 69.26666666666667]}, '_timestamp': 1717514481.5921001}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TN Reward Distribution': {'_type': 'histogram', 'values': [3, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [5.133333333333334, 9.260416666666668, 13.3875, 17.514583333333334, 21.641666666666666, 25.768749999999997, 29.895833333333332, 34.02291666666667, 38.15, 42.27708333333333, 46.40416666666666, 50.53125, 54.65833333333333, 58.78541666666666, 62.9125, 67.03958333333334, 71.16666666666667, 75.29375, 79.42083333333333, 83.54791666666667, 87.675, 91.80208333333334, 95.92916666666667, 100.05625, 104.18333333333334, 108.31041666666667, 112.4375, 116.56458333333333, 120.69166666666668, 124.81875000000001, 128.94583333333333, 133.07291666666666, 137.2, 141.32708333333332, 145.45416666666665, 149.58124999999998, 153.70833333333331, 157.83541666666665, 161.96249999999998, 166.0895833333333, 170.21666666666664, 174.34375, 178.47083333333333, 182.59791666666666, 186.725, 190.85208333333333, 194.97916666666666, 199.10625, 203.23333333333332, 207.36041666666665, 211.48749999999998, 215.61458333333331, 219.74166666666665, 223.86874999999998, 227.9958333333333, 232.12291666666664, 236.25, 240.37708333333333, 244.50416666666666, 248.63125, 252.75833333333333, 256.8854166666667, 261.0125, 265.1395833333333, 269.26666666666665]}, '_timestamp': 1717514481.592285}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FP Reward Distribution': {'_type': 'histogram', 'values': [2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.6666666666666665, 2.7604166666666665, 2.8541666666666665, 2.9479166666666665, 3.0416666666666665, 3.1354166666666665, 3.2291666666666665, 3.3229166666666665, 3.4166666666666665, 3.5104166666666665, 3.6041666666666665, 3.6979166666666665, 3.7916666666666665, 3.8854166666666665, 3.9791666666666665, 4.072916666666666, 4.166666666666666, 4.260416666666666, 4.354166666666666, 4.447916666666666, 4.541666666666666, 4.635416666666666, 4.729166666666666, 4.822916666666666, 4.916666666666666, 5.010416666666666, 5.104166666666666, 5.197916666666666, 5.291666666666666, 5.385416666666666, 5.479166666666666, 5.572916666666666, 5.666666666666666, 5.760416666666666, 5.854166666666666, 5.947916666666666, 6.041666666666666, 6.135416666666666, 6.229166666666666, 6.322916666666666, 6.416666666666666, 6.510416666666666, 6.604166666666666, 6.697916666666666, 6.791666666666666, 6.885416666666666, 6.979166666666666, 7.072916666666666, 7.166666666666666, 7.260416666666666, 7.354166666666666, 7.447916666666666, 7.541666666666666, 7.635416666666666, 7.729166666666666, 7.822916666666666, 7.916666666666666, 8.010416666666666, 8.104166666666666, 8.197916666666666, 8.291666666666666, 8.385416666666666, 8.479166666666666, 8.572916666666666, 8.666666666666666]}, '_timestamp': 1717514481.592444}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FN Reward Distribution': {'_type': 'histogram', 'values': [1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.8666666666666667, 3.146875, 3.4270833333333335, 3.7072916666666664, 3.9875, 4.267708333333333, 4.547916666666667, 4.828125, 5.108333333333333, 5.388541666666667, 5.66875, 5.948958333333334, 6.229166666666666, 6.509375, 6.789583333333333, 7.069791666666667, 7.35, 7.630208333333334, 7.910416666666666, 8.190625, 8.470833333333333, 8.751041666666667, 9.03125, 9.311458333333334, 9.591666666666667, 9.871875, 10.152083333333334, 10.432291666666666, 10.7125, 10.992708333333335, 11.272916666666667, 11.553125000000001, 11.833333333333334, 12.113541666666666, 12.39375, 12.673958333333333, 12.954166666666667, 13.234375, 13.514583333333334, 13.794791666666667, 14.075000000000001, 14.355208333333334, 14.635416666666668, 14.915625, 15.195833333333335, 15.476041666666667, 15.756250000000001, 16.036458333333332, 16.316666666666666, 16.596875, 16.87708333333333, 17.157291666666666, 17.4375, 17.717708333333334, 17.997916666666665, 18.278125, 18.558333333333334, 18.838541666666668, 19.118750000000002, 19.398958333333333, 19.679166666666667, 19.959375, 20.239583333333336, 20.519791666666666, 20.8]}, '_timestamp': 1717514481.592591}).
Epoch 740/1000, Train Loss: 0.715300977230072, Val Loss: 0.05995617434382439, Train Acc: 0.9, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 750/1000, Train Loss: 0.737575352191925, Val Loss: 0.05988519266247749, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 760/1000, Train Loss: 1.0643845796585083, Val Loss: 0.059850387275218964, Train Acc: 0.825, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 770/1000, Train Loss: 1.595712810754776, Val Loss: 0.05990511178970337, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 780/1000, Train Loss: 1.0220556557178497, Val Loss: 0.05986674875020981, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 790/1000, Train Loss: 0.5383511483669281, Val Loss: 0.05975111573934555, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 800/1000, Train Loss: 0.854155957698822, Val Loss: 0.05970031023025513, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 810/1000, Train Loss: 0.8517593145370483, Val Loss: 0.0596499927341938, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 820/1000, Train Loss: 0.6230109483003616, Val Loss: 0.05969623476266861, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 830/1000, Train Loss: 0.6699258089065552, Val Loss: 0.05970730260014534, Train Acc: 0.825, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 840/1000, Train Loss: 0.7980957627296448, Val Loss: 0.05963018536567688, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 850/1000, Train Loss: 0.7223818004131317, Val Loss: 0.05960133671760559, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 860/1000, Train Loss: 1.4879208505153656, Val Loss: 0.05961548537015915, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 870/1000, Train Loss: 0.8962719440460205, Val Loss: 0.059594232589006424, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 880/1000, Train Loss: 0.8844269812107086, Val Loss: 0.0596340075135231, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 890/1000, Train Loss: 0.9012070000171661, Val Loss: 0.0596243254840374, Train Acc: 0.825, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 900/1000, Train Loss: 0.7098647654056549, Val Loss: 0.05970688536763191, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 910/1000, Train Loss: 1.0358259677886963, Val Loss: 0.05965467169880867, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 920/1000, Train Loss: 1.2816390991210938, Val Loss: 0.05952517315745354, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 930/1000, Train Loss: 0.7370361685752869, Val Loss: 0.059503037482500076, Train Acc: 0.9, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 940/1000, Train Loss: 0.888146385550499, Val Loss: 0.059409599751234055, Train Acc: 0.875, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 950/1000, Train Loss: 1.1351354718208313, Val Loss: 0.059394873678684235, Train Acc: 0.8, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 960/1000, Train Loss: 0.9504855573177338, Val Loss: 0.05933338403701782, Train Acc: 0.825, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 970/1000, Train Loss: 0.6362156867980957, Val Loss: 0.05927924066781998, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 980/1000, Train Loss: 0.5622731894254684, Val Loss: 0.05917856842279434, Train Acc: 0.9, Val Acc: 1.0, LR: 3.1903147633366023e-07
Epoch 990/1000, Train Loss: 0.63638836145401, Val Loss: 0.05923834443092346, Train Acc: 0.85, Val Acc: 1.0, LR: 3.1903147633366023e-07
Finished training model...
Simulating on true reward function...
 ****** Running generation 0 ******
[33m[W 2024-06-04 11:21:42,922][39m Trial 0 failed with parameters: {'hidden_size': 381, 'learning_rate': 3.190314763336616e-05, 'weight_decay': 0.00018811905389849344} because of the following error: The value None could not be cast to float..
[33m[W 2024-06-04 11:21:42,922][39m Trial 0 failed with value None.
Population's average fitness: 206.07667 stdev: 475.62562
Best fitness: 2163.13333 - size: (4, 20) - species 1 - id 16
Average adjusted fitness: 0.092
Mean genetic distance 1.176, standard deviation 0.209
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20   2163.1    0.092     0
Total extinctions: 0
Generation time: 1.154 sec
 ****** Running generation 1 ******
Population's average fitness: 522.24333 stdev: 966.66798
Best fitness: 4155.20000 - size: (4, 19) - species 1 - id 22
Average adjusted fitness: 0.124
Mean genetic distance 1.235, standard deviation 0.268
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    1    20   4155.2    0.124     0
Total extinctions: 0
Generation time: 2.517 sec (1.836 average)
 ****** Running generation 2 ******
Population's average fitness: 538.63667 stdev: 976.47114
Best fitness: 4155.20000 - size: (4, 19) - species 1 - id 22
Average adjusted fitness: 0.126
Mean genetic distance 1.117, standard deviation 0.304
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    2    20   4155.2    0.126     1
Total extinctions: 0
Generation time: 2.517 sec (2.063 average)
 ****** Running generation 3 ******
Population's average fitness: 997.84000 stdev: 2218.11855
Best fitness: 9693.06667 - size: (4, 17) - species 1 - id 69
Average adjusted fitness: 0.102
Mean genetic distance 1.170, standard deviation 0.349
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    3    20   9693.1    0.102     0
Total extinctions: 0
Generation time: 3.831 sec (2.505 average)
 ****** Running generation 4 ******
Traceback (most recent call last):
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 100, in <module>
    start_simulation("./config/agent_config.txt", args.generations[0])
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 40, in start_simulation
    run_population(
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 405, in run_population
    best_genome = population.run(
  File "/Users/alextang/.pyenv/versions/nocturne_lab/lib/python3.10/site-packages/neat/population.py", line 89, in run
    fitness_function(list(iteritems(self.population)), self.config)
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 381, in run_simulation
    clock.tick(60)  # 60 FPS
KeyboardInterrupt