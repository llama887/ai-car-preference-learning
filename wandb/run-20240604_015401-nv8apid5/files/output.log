Epoch 0/1000, Train Loss: 1.7598363161087036, Val Loss: 0.6434923410415649, Train Acc: 0.55, Val Acc: 0.800000011920929, LR: 0.0007972467145773867
Epoch 10/1000, Train Loss: 2.520842492580414, Val Loss: 0.5839789509773254, Train Acc: 0.45, Val Acc: 0.800000011920929, LR: 0.000781429912360365
Epoch 20/1000, Train Loss: 1.7351055145263672, Val Loss: 0.5784131288528442, Train Acc: 0.6, Val Acc: 0.800000011920929, LR: 0.0007656131101433434
Epoch 30/1000, Train Loss: 2.3825501203536987, Val Loss: 0.5871784687042236, Train Acc: 0.475, Val Acc: 0.800000011920929, LR: 0.0007497963079263218
Epoch 40/1000, Train Loss: 1.833331286907196, Val Loss: 0.5646965503692627, Train Acc: 0.6, Val Acc: 0.800000011920929, LR: 0.0007339795057092999
Epoch 50/1000, Train Loss: 1.5443331003189087, Val Loss: 0.558881402015686, Train Acc: 0.45, Val Acc: 0.800000011920929, LR: 0.0007181627034922783
Epoch 60/1000, Train Loss: 1.5768849849700928, Val Loss: 0.5116589665412903, Train Acc: 0.65, Val Acc: 0.800000011920929, LR: 0.0007023459012752564
Epoch 70/1000, Train Loss: 1.3904577493667603, Val Loss: 0.4533882737159729, Train Acc: 0.55, Val Acc: 0.800000011920929, LR: 0.0006865290990582348
Epoch 80/1000, Train Loss: 1.138629823923111, Val Loss: 0.408549964427948, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.000670712296841213
Epoch 90/1000, Train Loss: 1.2906097173690796, Val Loss: 0.3958430290222168, Train Acc: 0.575, Val Acc: 0.800000011920929, LR: 0.0006548954946241914
Epoch 100/1000, Train Loss: 1.221367597579956, Val Loss: 0.3920748233795166, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.0006390786924071697
Epoch 110/1000, Train Loss: 1.0418108105659485, Val Loss: 0.3957599401473999, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.0006232618901901481
Epoch 120/1000, Train Loss: 0.7744442820549011, Val Loss: 0.40969720482826233, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.0006074450879731265
Epoch 130/1000, Train Loss: 0.49030450731515884, Val Loss: 0.3847048580646515, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 0.0005916282857561048
Epoch 140/1000, Train Loss: 0.9195044934749603, Val Loss: 0.40879732370376587, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.0005758114835390832
Epoch 150/1000, Train Loss: 0.9605712890625, Val Loss: 0.38162630796432495, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.0005599946813220616
Epoch 160/1000, Train Loss: 0.9753397107124329, Val Loss: 0.40336909890174866, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.0005441778791050399
Epoch 170/1000, Train Loss: 0.6338667571544647, Val Loss: 0.39114874601364136, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 0.0005283610768880183
Epoch 180/1000, Train Loss: 0.6964621543884277, Val Loss: 0.39990878105163574, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 0.0005125442746709966
Epoch 190/1000, Train Loss: 1.0236428678035736, Val Loss: 0.38366779685020447, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 0.000496727472453975
Epoch 200/1000, Train Loss: 0.805194228887558, Val Loss: 0.39293450117111206, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 0.000480910670236953
Epoch 210/1000, Train Loss: 1.1643385589122772, Val Loss: 0.39378875494003296, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.00046509386801993075
Epoch 220/1000, Train Loss: 0.7358355820178986, Val Loss: 0.40989089012145996, Train Acc: 0.85, Val Acc: 0.800000011920929, LR: 0.00044927706580290863
Epoch 230/1000, Train Loss: 0.7289804220199585, Val Loss: 0.403621107339859, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 0.00043346026358588645
Epoch 240/1000, Train Loss: 0.6757388114929199, Val Loss: 0.4046027660369873, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 0.0004176434613688643
Epoch 250/1000, Train Loss: 1.3847121000289917, Val Loss: 0.3913411796092987, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 0.00040182665915184225
Epoch 260/1000, Train Loss: 0.9037257432937622, Val Loss: 0.40407508611679077, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.00038600985693482023
Epoch 270/1000, Train Loss: 0.9069927930831909, Val Loss: 0.3885544240474701, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.0003701930547177981
Epoch 280/1000, Train Loss: 0.674202024936676, Val Loss: 0.39860400557518005, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 0.0003543762525007761
Epoch 290/1000, Train Loss: 0.8279760479927063, Val Loss: 0.4029531478881836, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.0003385594502837539
Epoch 300/1000, Train Loss: 0.6971026360988617, Val Loss: 0.4056292474269867, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 0.0003227426480667317
Epoch 310/1000, Train Loss: 0.8984361886978149, Val Loss: 0.39509379863739014, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.00030692584584970955
Epoch 320/1000, Train Loss: 0.6696375608444214, Val Loss: 0.39967602491378784, Train Acc: 0.85, Val Acc: 0.800000011920929, LR: 0.00029110904363268753
Epoch 330/1000, Train Loss: 0.7119990289211273, Val Loss: 0.4023234248161316, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.00027529224141566535
Epoch 340/1000, Train Loss: 0.7663137912750244, Val Loss: 0.4036775529384613, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.0002594754391986434
Epoch 350/1000, Train Loss: 0.792756199836731, Val Loss: 0.404390811920166, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.00024365863698162134
Epoch 360/1000, Train Loss: 0.7679599225521088, Val Loss: 0.3921307325363159, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.00022784183476459916
Epoch 370/1000, Train Loss: 0.7739994823932648, Val Loss: 0.3997066617012024, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 0.00021202503254757698
Epoch 380/1000, Train Loss: 0.620067372918129, Val Loss: 0.3937831521034241, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 0.0001962082303305548
Epoch 390/1000, Train Loss: 0.8026655316352844, Val Loss: 0.3966980576515198, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 0.00018039142811353262
Epoch 400/1000, Train Loss: 0.8595148026943207, Val Loss: 0.4048841893672943, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 0.00016457462589651044
Epoch 410/1000, Train Loss: 0.5477340519428253, Val Loss: 0.4050881266593933, Train Acc: 0.925, Val Acc: 0.800000011920929, LR: 0.00014875782367948826
Epoch 420/1000, Train Loss: 0.5758669078350067, Val Loss: 0.3908303380012512, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 0.00013294102146246608
Epoch 430/1000, Train Loss: 0.7953271567821503, Val Loss: 0.4010581076145172, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 0.00011712421924544391
Epoch 440/1000, Train Loss: 0.8065696656703949, Val Loss: 0.40080466866493225, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.00010130741702842173
Epoch 450/1000, Train Loss: 0.7830108106136322, Val Loss: 0.399375855922699, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 8.549061481139955e-05
Epoch 460/1000, Train Loss: 0.759826272726059, Val Loss: 0.4013544023036957, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 6.967381259437737e-05
Epoch 470/1000, Train Loss: 0.6310905069112778, Val Loss: 0.3983039855957031, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 5.3857010377355214e-05
Epoch 480/1000, Train Loss: 0.6037010550498962, Val Loss: 0.39815446734428406, Train Acc: 0.85, Val Acc: 0.800000011920929, LR: 3.804020816033306e-05
Epoch 490/1000, Train Loss: 0.824817568063736, Val Loss: 0.39901110529899597, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.2223405943310922e-05
Epoch 500/1000, Train Loss: 0.6342524588108063, Val Loss: 0.3995884358882904, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 510/1000, Train Loss: 0.6730502545833588, Val Loss: 0.39940449595451355, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 520/1000, Train Loss: 0.6191162467002869, Val Loss: 0.3991501033306122, Train Acc: 0.85, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 530/1000, Train Loss: 0.7856921851634979, Val Loss: 0.3988829255104065, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 540/1000, Train Loss: 0.6935529708862305, Val Loss: 0.39918404817581177, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 550/1000, Train Loss: 0.6906636357307434, Val Loss: 0.39869531989097595, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 560/1000, Train Loss: 0.7066721022129059, Val Loss: 0.3982201814651489, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 570/1000, Train Loss: 0.6634704768657684, Val Loss: 0.39741820096969604, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 580/1000, Train Loss: 0.6961647570133209, Val Loss: 0.3964754045009613, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 590/1000, Train Loss: 0.71542689204216, Val Loss: 0.3966465890407562, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 600/1000, Train Loss: 0.6733333766460419, Val Loss: 0.3976894021034241, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 610/1000, Train Loss: 0.7426627576351166, Val Loss: 0.3977276384830475, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 620/1000, Train Loss: 0.8009301424026489, Val Loss: 0.39738863706588745, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 630/1000, Train Loss: 0.8452493250370026, Val Loss: 0.3977900445461273, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 640/1000, Train Loss: 0.6468996107578278, Val Loss: 0.3977201581001282, Train Acc: 0.85, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 650/1000, Train Loss: 0.6766853034496307, Val Loss: 0.3979215621948242, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 660/1000, Train Loss: 0.6580305993556976, Val Loss: 0.3973347842693329, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 670/1000, Train Loss: 0.8167109787464142, Val Loss: 0.39725053310394287, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 680/1000, Train Loss: 0.6934077739715576, Val Loss: 0.3971576392650604, Train Acc: 0.65, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 690/1000, Train Loss: 0.7108896970748901, Val Loss: 0.3964175581932068, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 700/1000, Train Loss: 0.6777689456939697, Val Loss: 0.3960077166557312, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 710/1000, Train Loss: 0.6136134564876556, Val Loss: 0.39636164903640747, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 720/1000, Train Loss: 0.7865374088287354, Val Loss: 0.3961721360683441, Train Acc: 0.85, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 730/1000, Train Loss: 0.7586927115917206, Val Loss: 0.39562109112739563, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 740/1000, Train Loss: 0.7612985074520111, Val Loss: 0.3953871428966522, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 750/1000, Train Loss: 0.7113915383815765, Val Loss: 0.39482271671295166, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 760/1000, Train Loss: 0.7675592005252838, Val Loss: 0.3953012526035309, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 770/1000, Train Loss: 0.8100620210170746, Val Loss: 0.39562857151031494, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 780/1000, Train Loss: 0.5501884967088699, Val Loss: 0.3956054151058197, Train Acc: 0.85, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 790/1000, Train Loss: 0.5959786027669907, Val Loss: 0.3948368430137634, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 800/1000, Train Loss: 0.6538741290569305, Val Loss: 0.39519086480140686, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 810/1000, Train Loss: 0.8775273561477661, Val Loss: 0.39513546228408813, Train Acc: 0.65, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 820/1000, Train Loss: 0.719290167093277, Val Loss: 0.39493876695632935, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 830/1000, Train Loss: 0.6443352997303009, Val Loss: 0.39530107378959656, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 840/1000, Train Loss: 0.562759518623352, Val Loss: 0.39567482471466064, Train Acc: 0.875, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 850/1000, Train Loss: 0.7750158905982971, Val Loss: 0.3955727219581604, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 860/1000, Train Loss: 0.6839900612831116, Val Loss: 0.39496558904647827, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 870/1000, Train Loss: 0.6864250898361206, Val Loss: 0.39529290795326233, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 880/1000, Train Loss: 0.7103306651115417, Val Loss: 0.3962342143058777, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 890/1000, Train Loss: 0.7126192450523376, Val Loss: 0.39631783962249756, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
[34m[1mwandb[39m[22m: [33mWARNING[39m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'Train Loss': 1.7598363161087036, 'Validation Loss': 0.6434923410415649, 'Train Accuracy': 0.55, 'Validation Accuracy': 0.800000011920929, '_timestamp': 1717480442.581792}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.weight': {'_type': 'histogram', 'values': [2576, 3767, 3776, 3736, 3746, 3811, 3766, 3934, 3835, 3753, 3749, 3763, 3740, 3890, 3703, 3804, 3746, 3751, 3855, 3805, 3742, 3761, 3827, 3936, 3768, 3960, 3644, 3854, 3703, 3813, 3978, 3839, 3770, 3828, 3766, 3822, 3864, 3760, 3747, 3849, 3722, 3833, 3712, 3798, 3763, 3761, 3829, 3767, 3769, 3733, 3657, 3737, 3779, 3691, 3741, 3830, 3754, 3804, 3877, 3826, 3723, 3627, 3716, 1314], 'bins': [-0.10307306796312332, -0.09985227137804031, -0.0966314747929573, -0.0934106856584549, -0.09018988907337189, -0.08696909248828888, -0.08374829590320587, -0.08052749931812286, -0.07730670273303986, -0.07408591359853745, -0.07086511701345444, -0.06764432042837143, -0.06442352384328842, -0.061202727258205414, -0.057981934398412704, -0.0547611378133297, -0.05154034495353699, -0.04831954836845398, -0.04509875178337097, -0.04187795892357826, -0.038657162338495255, -0.03543636575341225, -0.03221557289361954, -0.02899477630853653, -0.02577397972345352, -0.022553185001015663, -0.019332390278577805, -0.016111595556139946, -0.012890798971056938, -0.00967000424861908, -0.006449208594858646, -0.0032284134067595005, -7.618218660354614e-06, 0.0032131769694387913, 0.006433972157537937, 0.00965476781129837, 0.012875562533736229, 0.016096359118819237, 0.019317153841257095, 0.022537948563694954, 0.025758743286132812, 0.02897953987121582, 0.03220033645629883, 0.03542112931609154, 0.038641925901174545, 0.04186272248625755, 0.04508351534605026, 0.04830431193113327, 0.05152510851621628, 0.05474590137600899, 0.057966697961091995, 0.061187490820884705, 0.06440828740596771, 0.06762908399105072, 0.07084988057613373, 0.07407067716121674, 0.07729146629571915, 0.08051226288080215, 0.08373305946588516, 0.08695385605096817, 0.09017465263605118, 0.09339544922113419, 0.0966162383556366, 0.0998370349407196, 0.10305783152580261]}, '_timestamp': 1717480442.587778}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.bias': {'_type': 'histogram', 'values': [6, 6, 3, 5, 2, 6, 1, 2, 3, 3, 6, 6, 2, 3, 3, 4, 4, 4, 2, 5, 5, 2, 5, 6, 3, 5, 1, 2, 5, 5, 6, 7, 5, 9, 4, 2, 8, 7, 5, 6, 3, 3, 1, 8, 5, 2, 0, 6, 8, 4, 5, 5, 1, 4, 4, 2, 4, 4, 1, 7, 6, 1, 3, 4], 'bins': [-0.032207515090703964, -0.031215090304613113, -0.030222665518522263, -0.029230238869786263, -0.02823781408369541, -0.02724538929760456, -0.02625296451151371, -0.02526053786277771, -0.02426811307668686, -0.02327568829059601, -0.022283263504505157, -0.021290838718414307, -0.020298412069678307, -0.019305987283587456, -0.018313562497496605, -0.017321137711405754, -0.016328711062669754, -0.015336287207901478, -0.014343861490488052, -0.013351436704397202, -0.012359010986983776, -0.011366586200892925, -0.0103741604834795, -0.009381735697388649, -0.008389310911297798, -0.007396885193884373, -0.006404459942132235, -0.0054120346903800964, -0.004419609904289246, -0.003427184419706464, -0.0024347594007849693, -0.0014423341490328312, -0.00044990889728069305, 0.0005425162962637842, 0.0015349414898082614, 0.0025273666251450777, 0.003519791876897216, 0.00451221689581871, 0.0055046421475708485, 0.006497067399322987, 0.007489492651075125, 0.008481917902827263, 0.009474342688918114, 0.01046676840633154, 0.01145919319242239, 0.012451618909835815, 0.013444043695926666, 0.014436469413340092, 0.015428894199430943, 0.016421319916844368, 0.01741374470293522, 0.01840616948902607, 0.01939859427511692, 0.02039102092385292, 0.02138344570994377, 0.022375870496034622, 0.023368295282125473, 0.024360720068216324, 0.025353146716952324, 0.026345571503043175, 0.027337996289134026, 0.028330421075224876, 0.029322847723960876, 0.030315272510051727, 0.03130769729614258]}, '_timestamp': 1717480442.5880141}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.weight': {'_type': 'histogram', 'values': [109, 14, 7, 13, 12, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 3, 0, 0, 2, 1, 0, 0, 3, 3, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 8, 3, 4, 3, 2, 4, 4, 0, 1, 0, 0, 1, 1, 2, 1, 1, 2, 2, 0, 1, 3, 2, 4, 1, 9, 5, 5, 12], 'bins': [0.9984023571014404, 0.9984523057937622, 0.9985021948814392, 0.998552143573761, 0.9986020922660828, 0.9986519813537598, 0.9987019300460815, 0.9987518787384033, 0.9988018274307251, 0.9988517165184021, 0.9989016652107239, 0.9989516139030457, 0.9990015029907227, 0.9990514516830444, 0.9991014003753662, 0.9991512894630432, 0.999201238155365, 0.9992511868476868, 0.9993010759353638, 0.9993510246276855, 0.9994009733200073, 0.9994508624076843, 0.9995008111000061, 0.9995507597923279, 0.9996006488800049, 0.9996505975723267, 0.9997005462646484, 0.9997504949569702, 0.9998003840446472, 0.999850332736969, 0.9999002814292908, 0.9999501705169678, 1.0000001192092896, 1.0000500679016113, 1.000100016593933, 1.0001499652862549, 1.000199794769287, 1.0002497434616089, 1.0002996921539307, 1.0003496408462524, 1.0003995895385742, 1.000449538230896, 1.0004993677139282, 1.00054931640625, 1.0005992650985718, 1.0006492137908936, 1.0006991624832153, 1.000749111175537, 1.0007989406585693, 1.0008488893508911, 1.000898838043213, 1.0009487867355347, 1.0009987354278564, 1.0010486841201782, 1.0010986328125, 1.0011484622955322, 1.001198410987854, 1.0012483596801758, 1.0012983083724976, 1.0013482570648193, 1.0013982057571411, 1.0014480352401733, 1.0014979839324951, 1.001547932624817, 1.0015978813171387]}, '_timestamp': 1717480442.5881941}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.bias': {'_type': 'histogram', 'values': [19, 3, 1, 3, 1, 29, 3, 2, 2, 2, 1, 1, 1, 1, 0, 1, 1, 3, 1, 0, 0, 1, 0, 2, 2, 0, 0, 4, 0, 0, 0, 0, 77, 0, 0, 0, 7, 0, 4, 0, 1, 1, 4, 4, 5, 6, 2, 0, 1, 2, 1, 2, 2, 2, 2, 3, 1, 2, 13, 4, 8, 5, 7, 15], 'bins': [-0.0015979105373844504, -0.0015479768626391888, -0.001498043187893927, -0.0014481096295639873, -0.0013981759548187256, -0.001348242280073464, -0.0012983086053282022, -0.0012483749305829406, -0.001198441255837679, -0.001148507697507739, -0.0010985740227624774, -0.0010486403480172157, -0.000998706673271954, -0.0009487729985266924, -0.0008988393819890916, -0.00084890570724383, -0.0007989720907062292, -0.0007490384159609675, -0.0006991047412157059, -0.0006491711246781051, -0.0005992374499328434, -0.0005493037751875818, -0.000499370158649981, -0.00044943648390471935, -0.0003995028091594577, -0.00034956916351802647, -0.00029963551787659526, -0.00024970187223516405, -0.00019976819748990238, -0.00014983455184847116, -9.990089165512472e-05, -4.99672387377359e-05, -3.3585820347070694e-08, 4.9900067097041756e-05, 9.983372001443058e-05, 0.00014976738020777702, 0.00019970102584920824, 0.0002496347005944699, 0.0002995683462359011, 0.00034950199187733233, 0.00039943563751876354, 0.0004493693122640252, 0.0004993029870092869, 0.0005492366035468876, 0.0005991702782921493, 0.000649103953037411, 0.0006990375695750117, 0.0007489712443202734, 0.0007989049190655351, 0.0008488385356031358, 0.0008987722103483975, 0.0009487058268859982, 0.00099863950163126, 0.0010485731763765216, 0.0010985068511217833, 0.001148440525867045, 0.0011983740841969848, 0.0012483077589422464, 0.001298241433687508, 0.0013481751084327698, 0.0013981087831780314, 0.0014480424579232931, 0.001497976016253233, 0.0015479096909984946, 0.0015978433657437563]}, '_timestamp': 1717480442.588358}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.weight': {'_type': 'histogram', 'values': [567, 1157, 1151, 1097, 1108, 1105, 1165, 1114, 1082, 1139, 1066, 1087, 1131, 1102, 1145, 1077, 1059, 1159, 1125, 1109, 1110, 1129, 1139, 1069, 1050, 1099, 1124, 1091, 1102, 1131, 1049, 1232, 1177, 1158, 1100, 1103, 1125, 1102, 1154, 1127, 1098, 1098, 1067, 1078, 1062, 1148, 1132, 1067, 1073, 1145, 1169, 1116, 1120, 1104, 1111, 1089, 1142, 1121, 1166, 1080, 1100, 1083, 1154, 586], 'bins': [-0.15201087296009064, -0.14726197719573975, -0.14251308143138885, -0.13776420056819916, -0.13301530480384827, -0.12826640903949738, -0.12351751327514648, -0.11876862496137619, -0.1140197291970253, -0.10927083343267441, -0.10452194511890411, -0.09977304935455322, -0.09502415359020233, -0.09027526527643204, -0.08552636951208115, -0.08077748119831085, -0.07602858543395996, -0.07127968966960907, -0.06653080135583878, -0.061781905591487885, -0.05703301355242729, -0.0522841215133667, -0.04753522574901581, -0.042786333709955215, -0.03803744167089462, -0.03328854963183403, -0.02853965573012829, -0.023790761828422546, -0.019041869789361954, -0.014292976818978786, -0.00954408384859562, -0.004795190878212452, -4.629790782928467e-05, 0.004702595062553883, 0.00945148803293705, 0.014200381003320217, 0.018949273973703384, 0.023698166012763977, 0.02844705991446972, 0.03319595381617546, 0.03794484585523605, 0.042693737894296646, 0.04744262993335724, 0.05219152569770813, 0.05694041773676872, 0.061689309775829315, 0.0664382055401802, 0.0711870938539505, 0.07593598961830139, 0.08068488538265228, 0.08543377369642258, 0.09018266946077347, 0.09493155777454376, 0.09968045353889465, 0.10442934930324554, 0.10917823761701584, 0.11392713338136673, 0.11867602914571762, 0.12342491745948792, 0.1281738132238388, 0.1329227089881897, 0.1376716047525406, 0.14242048561573029, 0.14716938138008118, 0.15191827714443207]}, '_timestamp': 1717480442.588948}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.bias': {'_type': 'histogram', 'values': [2, 3, 4, 6, 2, 2, 2, 3, 8, 1, 10, 1, 7, 5, 2, 7, 5, 8, 5, 7, 4, 2, 4, 5, 2, 1, 5, 5, 8, 3, 6, 6, 8, 2, 2, 6, 2, 2, 2, 4, 4, 4, 3, 4, 5, 3, 5, 7, 4, 3, 5, 2, 7, 5, 4, 6, 4, 1, 1, 7, 2, 5, 1, 4], 'bins': [-0.06224578246474266, -0.06030649691820145, -0.05836721509695053, -0.05642792955040932, -0.0544886440038681, -0.05254936218261719, -0.050610076636075974, -0.04867079108953476, -0.046731509268283844, -0.04479222372174263, -0.042852938175201416, -0.0409136563539505, -0.038974370807409286, -0.03703508526086807, -0.03509580343961716, -0.03315651789307594, -0.03121723234653473, -0.029277948662638664, -0.0273386649787426, -0.025399379432201385, -0.02346009574830532, -0.021520812064409256, -0.019581526517868042, -0.017642242833971977, -0.015702959150075912, -0.013763674534857273, -0.011824389919638634, -0.009885105304419994, -0.00794582162052393, -0.00600653700530529, -0.004067252855747938, -0.0021279684733599424, -0.00018868409097194672, 0.001750600291416049, 0.0036898846738040447, 0.005629168823361397, 0.007568453438580036, 0.009507737122476101, 0.01144702173769474, 0.01338630635291338, 0.015325590968132019, 0.017264874652028084, 0.01920415833592415, 0.021143443882465363, 0.023082727566361427, 0.025022011250257492, 0.026961296796798706, 0.02890058048069477, 0.030839864164590836, 0.03277914971113205, 0.034718435257673264, 0.03665771707892418, 0.03859700262546539, 0.04053628817200661, 0.04247556999325752, 0.04441485553979874, 0.04635414108633995, 0.048293422907590866, 0.05023270845413208, 0.052171994000673294, 0.05411127582192421, 0.056050561368465424, 0.05798984691500664, 0.05992912873625755, 0.06186841428279877]}, '_timestamp': 1717480442.5891058}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.weight': {'_type': 'histogram', 'values': [39, 15, 12, 12, 6, 6, 8, 4, 1, 0, 4, 3, 2, 3, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 4, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 3, 3, 2, 3, 2, 0, 1, 3, 4, 3, 0, 3, 1, 2, 1, 1, 3, 3, 2, 4, 4, 10, 9, 9, 11, 23], 'bins': [0.9984021186828613, 0.9984520673751831, 0.9985019564628601, 0.9985519051551819, 0.9986017942428589, 0.9986517429351807, 0.9987016916275024, 0.9987515807151794, 0.9988015294075012, 0.9988514184951782, 0.9989013671875, 0.9989513158798218, 0.9990012049674988, 0.9990511536598206, 0.9991010427474976, 0.9991509914398193, 0.9992009401321411, 0.9992508292198181, 0.9993007779121399, 0.9993506669998169, 0.9994006156921387, 0.9994505047798157, 0.9995004534721375, 0.9995504021644592, 0.9996002912521362, 0.999650239944458, 0.999700129032135, 0.9997500777244568, 0.9998000264167786, 0.9998499155044556, 0.9998998641967773, 0.9999497532844543, 0.9999997019767761, 1.0000495910644531, 1.000099539756775, 1.0001494884490967, 1.0001994371414185, 1.0002492666244507, 1.0002992153167725, 1.0003491640090942, 1.000399112701416, 1.0004490613937378, 1.00049889087677, 1.0005488395690918, 1.0005987882614136, 1.0006487369537354, 1.0006986856460571, 1.0007485151290894, 1.0007984638214111, 1.000848412513733, 1.0008983612060547, 1.0009483098983765, 1.0009981393814087, 1.0010480880737305, 1.0010980367660522, 1.001147985458374, 1.0011979341506958, 1.001247763633728, 1.0012977123260498, 1.0013476610183716, 1.0013976097106934, 1.0014475584030151, 1.0014973878860474, 1.0015473365783691, 1.001597285270691]}, '_timestamp': 1717480442.589261}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.bias': {'_type': 'histogram', 'values': [21, 15, 9, 7, 2, 16, 4, 5, 2, 2, 2, 4, 3, 3, 1, 1, 1, 3, 1, 6, 1, 4, 3, 3, 5, 4, 3, 3, 0, 0, 0, 8, 0, 0, 0, 0, 5, 0, 3, 3, 3, 5, 3, 1, 2, 4, 2, 1, 4, 2, 2, 2, 2, 2, 1, 2, 2, 3, 11, 2, 10, 14, 8, 24], 'bins': [-0.0015978501178324223, -0.0015479172579944134, -0.0014979842817410827, -0.0014480514219030738, -0.001398118562065065, -0.001348185702227056, -0.0012982527259737253, -0.0012483198661357164, -0.0011983870062977076, -0.0011484541464596987, -0.001098521170206368, -0.001048588310368359, -0.0009986554505303502, -0.0009487225324846804, -0.0008987896726466715, -0.0008488567546010017, -0.0007989238947629929, -0.0007489909767173231, -0.0006990580586716533, -0.0006491251988336444, -0.0005991922807879746, -0.0005492594209499657, -0.0004993265029042959, -0.00044939364306628704, -0.00039946072502061725, -0.0003495278360787779, -0.00029959494713693857, -0.00024966205819509923, -0.0001997291692532599, -0.00014979628031142056, -9.986339136958122e-05, -4.9930502427741885e-05, 2.3865140974521637e-09, 4.993527545593679e-05, 9.986816439777613e-05, 0.00014980105333961546, 0.0001997339422814548, 0.00024966683122329414, 0.0002995997201651335, 0.0003495326091069728, 0.00039946549804881215, 0.00044939841609448195, 0.0004993312759324908, 0.0005492641939781606, 0.0005991970538161695, 0.0006491299718618393, 0.0006990628316998482, 0.000748995749745518, 0.0007989286677911878, 0.0008488615276291966, 0.0008987944456748664, 0.0009487273055128753, 0.0009986602235585451, 0.001048593083396554, 0.0010985259432345629, 0.0011484589194878936, 0.0011983917793259025, 0.0012483246391639113, 0.0012982574990019202, 0.001348190475255251, 0.0013981233350932598, 0.0014480561949312687, 0.0014979890547692776, 0.0015479220310226083, 0.0015978548908606172]}, '_timestamp': 1717480442.5894122}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.weight': {'_type': 'histogram', 'values': [699, 1095, 1059, 1113, 1121, 1105, 1089, 1132, 1125, 1167, 1063, 1115, 1115, 1147, 1073, 1066, 1106, 1109, 1099, 1089, 1106, 1111, 1092, 1014, 1084, 1093, 1182, 1100, 1122, 1136, 1154, 1156, 1144, 1099, 1085, 1140, 1073, 1130, 1130, 1125, 1094, 1075, 1141, 1087, 1138, 1100, 1138, 1152, 1073, 1113, 1090, 1077, 1093, 1073, 1055, 1121, 1121, 1102, 1177, 1151, 1133, 1122, 1122, 714], 'bins': [-0.1520417481660843, -0.14729106426239014, -0.14254039525985718, -0.13778972625732422, -0.13303904235363007, -0.1282883584499359, -0.12353768944740295, -0.1187870129942894, -0.11403633654117584, -0.10928566008806229, -0.10453498363494873, -0.09978430718183517, -0.09503363072872162, -0.09028295427560806, -0.0855322778224945, -0.08078160136938095, -0.0760309249162674, -0.07128024846315384, -0.06652957201004028, -0.06177889555692673, -0.05702821910381317, -0.052277542650699615, -0.04752686619758606, -0.042776189744472504, -0.03802551329135895, -0.03327483683824539, -0.028524160385131836, -0.02377348393201828, -0.019022807478904724, -0.014272131025791168, -0.009521454572677612, -0.004770778119564056, -2.0101666450500488e-05, 0.004730574786663055, 0.009481251239776611, 0.014231927692890167, 0.018982604146003723, 0.02373328059911728, 0.028483957052230835, 0.03323463350534439, 0.03798530995845795, 0.0427359864115715, 0.04748666286468506, 0.052237339317798615, 0.05698801577091217, 0.061738692224025726, 0.06648936867713928, 0.07124004513025284, 0.0759907215833664, 0.08074139803647995, 0.0854920744895935, 0.09024275094270706, 0.09499342739582062, 0.09974410384893417, 0.10449478030204773, 0.10924545675516129, 0.11399613320827484, 0.1187468096613884, 0.12349748611450195, 0.1282481551170349, 0.13299883902072906, 0.13774952292442322, 0.14250019192695618, 0.14725086092948914, 0.1520015448331833]}, '_timestamp': 1717480442.589986}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.bias': {'_type': 'histogram', 'values': [3, 4, 3, 2, 1, 6, 5, 3, 2, 3, 6, 4, 4, 4, 2, 5, 6, 4, 1, 8, 5, 5, 4, 8, 6, 3, 8, 9, 7, 12, 8, 4, 3, 4, 5, 4, 4, 4, 0, 4, 5, 0, 4, 2, 5, 5, 4, 2, 5, 2, 2, 0, 7, 3, 1, 5, 3, 2, 5, 3, 5, 3, 5, 4], 'bins': [-0.06030125916004181, -0.05839572101831436, -0.056490182876586914, -0.05458464473485947, -0.05267910659313202, -0.05077356472611427, -0.048868026584386826, -0.04696248844265938, -0.04505695030093193, -0.04315141215920448, -0.041245874017477036, -0.03934033587574959, -0.03743479773402214, -0.03552925959229469, -0.03362371772527695, -0.0317181795835495, -0.029812641441822052, -0.027907103300094604, -0.026001565158367157, -0.02409602701663971, -0.022190488874912262, -0.020284948870539665, -0.018379410728812218, -0.01647387258708477, -0.014568334445357323, -0.0126627953723073, -0.010757257230579853, -0.008851718157529831, -0.006946180015802383, -0.005040641408413649, -0.003135102801024914, -0.001229564193636179, 0.0006759744137525558, 0.0025815130211412907, 0.0044870516285300255, 0.00639259023591876, 0.008298128843307495, 0.010203666985034943, 0.012109206058084965, 0.014014744199812412, 0.015920283272862434, 0.017825821414589882, 0.01973135955631733, 0.021636897698044777, 0.023542437702417374, 0.02544797584414482, 0.02735351398587227, 0.029259052127599716, 0.031164590269327164, 0.03307012841105461, 0.03497566655278206, 0.036881208419799805, 0.03878674656152725, 0.0406922847032547, 0.04259782284498215, 0.044503360986709595, 0.04640889912843704, 0.04831443727016449, 0.05021997541189194, 0.052125513553619385, 0.05403105542063713, 0.05593659356236458, 0.057842131704092026, 0.05974766984581947, 0.06165320798754692]}, '_timestamp': 1717480442.590139}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.weight': {'_type': 'histogram', 'values': [36, 18, 12, 9, 18, 4, 5, 4, 4, 1, 4, 4, 1, 3, 0, 3, 1, 2, 2, 1, 2, 3, 2, 0, 2, 3, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 8, 5, 3, 1, 4, 3, 0, 2, 2, 1, 2, 0, 3, 1, 0, 2, 5, 3, 2, 2, 1, 1, 4, 6, 9, 16, 26], 'bins': [0.9984021186828613, 0.9984520673751831, 0.9985019564628601, 0.9985519051551819, 0.9986018538475037, 0.9986518025398254, 0.9987016916275024, 0.9987516403198242, 0.998801589012146, 0.998851478099823, 0.9989014267921448, 0.9989513754844666, 0.9990013241767883, 0.9990512132644653, 0.9991011619567871, 0.9991511106491089, 0.9992010593414307, 0.9992509484291077, 0.9993008971214294, 0.9993508458137512, 0.9994007349014282, 0.99945068359375, 0.9995006322860718, 0.9995505809783936, 0.9996004700660706, 0.9996504187583923, 0.9997003674507141, 0.9997502565383911, 0.9998002052307129, 0.9998501539230347, 0.9999001026153564, 0.9999499917030334, 0.9999999403953552, 1.0000498294830322, 1.000099778175354, 1.0001497268676758, 1.0001996755599976, 1.0002496242523193, 1.0002995729446411, 1.000349521636963, 1.0003993511199951, 1.000449299812317, 1.0004992485046387, 1.0005491971969604, 1.0005991458892822, 1.000649094581604, 1.0006990432739258, 1.000748872756958, 1.0007988214492798, 1.0008487701416016, 1.0008987188339233, 1.0009486675262451, 1.000998616218567, 1.0010485649108887, 1.001098394393921, 1.0011483430862427, 1.0011982917785645, 1.0012482404708862, 1.001298189163208, 1.0013481378555298, 1.0013980865478516, 1.0014479160308838, 1.0014978647232056, 1.0015478134155273, 1.0015977621078491]}, '_timestamp': 1717480442.5902898}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.bias': {'_type': 'histogram', 'values': [26, 9, 19, 10, 2, 16, 4, 2, 3, 3, 1, 2, 1, 3, 2, 1, 1, 3, 4, 2, 3, 0, 4, 7, 4, 6, 5, 2, 0, 0, 0, 1, 0, 0, 0, 0, 3, 6, 0, 5, 1, 2, 2, 4, 1, 2, 4, 4, 5, 1, 3, 4, 2, 1, 4, 1, 3, 3, 7, 3, 8, 6, 12, 22], 'bins': [-0.001597921596840024, -0.0015479865251109004, -0.0014980514533817768, -0.0014481163816526532, -0.0013981813099235296, -0.001348246238194406, -0.0012983112828806043, -0.0012483762111514807, -0.001198441139422357, -0.0011485060676932335, -0.00109857099596411, -0.0010486359242349863, -0.0009987008525058627, -0.0009487657807767391, -0.0008988307672552764, -0.0008488956955261528, -0.0007989606237970293, -0.0007490255520679057, -0.0006990904803387821, -0.0006491554668173194, -0.0005992203950881958, -0.0005492853233590722, -0.0004993502516299486, -0.0004494152090046555, -0.0003994801372755319, -0.0003495450655464083, -0.00029961002292111516, -0.00024967495119199157, -0.0001997398940147832, -0.00014980483683757484, -9.986977238440886e-05, -4.993471156922169e-05, 3.4924596548080444e-10, 4.993541006115265e-05, 9.987047087633982e-05, 0.0001498055353295058, 0.00019974059250671417, 0.00024967564968392253, 0.0002996107214130461, 0.00034954576403833926, 0.00039948083576746285, 0.00044941590749658644, 0.0004993509501218796, 0.0005492860218510032, 0.0005992210935801268, 0.0006491561653092504, 0.000699091178830713, 0.0007490262505598366, 0.0007989613222889602, 0.0008488963940180838, 0.0008988314657472074, 0.0009487664792686701, 0.0009987015509977937, 0.0010486366227269173, 0.0010985716944560409, 0.0011485067661851645, 0.001198441837914288, 0.0012483769096434116, 0.0012983119813725352, 0.001348246936686337, 0.0013981820084154606, 0.0014481170801445842, 0.0014980521518737078, 0.0015479872236028314, 0.001597922295331955]}, '_timestamp': 1717480442.590434}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.weight': {'_type': 'histogram', 'values': [3, 4, 1, 3, 4, 1, 4, 4, 8, 2, 5, 4, 9, 3, 3, 5, 7, 2, 2, 5, 2, 4, 6, 6, 6, 4, 6, 1, 2, 3, 7, 3, 6, 7, 1, 7, 3, 6, 3, 0, 6, 5, 4, 5, 4, 1, 4, 4, 3, 5, 5, 8, 5, 3, 6, 5, 1, 1, 7, 5, 1, 5, 4, 6], 'bins': [-0.21156343817710876, -0.20495076477527618, -0.1983380913734436, -0.19172541797161102, -0.18511274456977844, -0.17850007116794586, -0.17188739776611328, -0.1652747243642807, -0.15866205096244812, -0.15204937756061554, -0.14543670415878296, -0.13882404565811157, -0.132211372256279, -0.1255986988544464, -0.11898601800203323, -0.11237334460020065, -0.10576067864894867, -0.09914800524711609, -0.09253533184528351, -0.08592265844345093, -0.07930998504161835, -0.07269731163978577, -0.06608463823795319, -0.059471964836120605, -0.052859291434288025, -0.04624662175774574, -0.03963394835591316, -0.03302127495408058, -0.026408601552248, -0.01979593001306057, -0.01318325661122799, -0.006570584140717983, 4.2088329792022705e-05, 0.006654760800302029, 0.013267433270812035, 0.019880106672644615, 0.026492778211832047, 0.03310545161366463, 0.03971812501549721, 0.04633079841732979, 0.05294346809387207, 0.05955614149570465, 0.06616881489753723, 0.07278148829936981, 0.07939416170120239, 0.08600683510303497, 0.09261950850486755, 0.09923218190670013, 0.10584485530853271, 0.1124575212597847, 0.11907019466161728, 0.12568287551403046, 0.13229554891586304, 0.13890822231769562, 0.145520880818367, 0.15213355422019958, 0.15874622762203217, 0.16535890102386475, 0.17197157442569733, 0.1785842478275299, 0.1851969212293625, 0.19180959463119507, 0.19842226803302765, 0.20503494143486023, 0.2116476148366928]}, '_timestamp': 1717480442.590585}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.bias': {'_type': 'histogram', 'values': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'bins': [-0.46202656626701355, -0.44640156626701355, -0.43077656626701355, -0.41515156626701355, -0.39952656626701355, -0.38390156626701355, -0.36827656626701355, -0.35265156626701355, -0.33702656626701355, -0.32140156626701355, -0.30577656626701355, -0.29015156626701355, -0.27452656626701355, -0.25890156626701355, -0.24327658116817474, -0.22765158116817474, -0.21202658116817474, -0.19640158116817474, -0.18077658116817474, -0.16515158116817474, -0.14952658116817474, -0.13390158116817474, -0.11827658116817474, -0.10265158116817474, -0.08702658116817474, -0.07140158116817474, -0.055776577442884445, -0.040151577442884445, -0.024526577442884445, -0.008901577442884445, 0.006723422557115555, 0.022348422557115555, 0.037973422557115555, 0.053598422557115555, 0.06922341883182526, 0.08484841883182526, 0.10047341883182526, 0.11609841883182526, 0.13172341883182526, 0.14734841883182526, 0.16297341883182526, 0.17859841883182526, 0.19422341883182526, 0.20984841883182526, 0.22547341883182526, 0.24109841883182526, 0.25672343373298645, 0.27234843373298645, 0.28797343373298645, 0.30359843373298645, 0.31922343373298645, 0.33484843373298645, 0.35047343373298645, 0.36609843373298645, 0.38172343373298645, 0.39734843373298645, 0.41297343373298645, 0.42859843373298645, 0.44422343373298645, 0.45984843373298645, 0.47547343373298645, 0.49109843373298645, 0.5067234039306641, 0.5223484039306641, 0.5379734039306641]}, '_timestamp': 1717480442.590753}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TP Reward Distribution': {'_type': 'histogram', 'values': [1, 2, 1, 2, 0, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.6666666666666665, 3.048958333333333, 3.43125, 3.8135416666666666, 4.195833333333333, 4.578125, 4.960416666666666, 5.3427083333333325, 5.725, 6.107291666666667, 6.489583333333333, 6.871874999999999, 7.254166666666666, 7.636458333333334, 8.018749999999999, 8.401041666666666, 8.783333333333333, 9.165624999999999, 9.547916666666666, 9.930208333333333, 10.3125, 10.694791666666665, 11.077083333333333, 11.459375, 11.841666666666665, 12.223958333333332, 12.60625, 12.988541666666665, 13.370833333333332, 13.753124999999999, 14.135416666666666, 14.517708333333331, 14.899999999999999, 15.282291666666666, 15.664583333333331, 16.046875, 16.429166666666667, 16.811458333333334, 17.193749999999998, 17.576041666666665, 17.958333333333332, 18.340625, 18.722916666666666, 19.105208333333334, 19.4875, 19.869791666666668, 20.252083333333335, 20.634375, 21.016666666666666, 21.398958333333333, 21.78125, 22.163541666666667, 22.545833333333334, 22.928125, 23.310416666666665, 23.692708333333332, 24.075, 24.457291666666666, 24.839583333333334, 25.221875, 25.604166666666668, 25.98645833333333, 26.36875, 26.751041666666666, 27.133333333333333]}, '_timestamp': 1717480442.5911522}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TN Reward Distribution': {'_type': 'histogram', 'values': [1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [3.533333333333333, 3.8010416666666664, 4.06875, 4.336458333333333, 4.604166666666666, 4.871874999999999, 5.139583333333333, 5.407291666666667, 5.675, 5.942708333333333, 6.210416666666666, 6.478125, 6.745833333333334, 7.013541666666667, 7.28125, 7.548958333333333, 7.816666666666666, 8.084375, 8.352083333333333, 8.619791666666666, 8.8875, 9.155208333333334, 9.422916666666666, 9.690625, 9.958333333333332, 10.226041666666667, 10.493749999999999, 10.761458333333334, 11.029166666666667, 11.296875, 11.564583333333333, 11.832291666666666, 12.1, 12.367708333333333, 12.635416666666666, 12.903125, 13.170833333333333, 13.438541666666666, 13.706249999999999, 13.973958333333332, 14.241666666666665, 14.509375, 14.777083333333334, 15.044791666666667, 15.3125, 15.580208333333333, 15.847916666666666, 16.115625, 16.383333333333333, 16.651041666666664, 16.91875, 17.186458333333334, 17.454166666666666, 17.721874999999997, 17.989583333333332, 18.257291666666667, 18.525, 18.792708333333334, 19.06041666666667, 19.328125, 19.59583333333333, 19.863541666666663, 20.13125, 20.398958333333333, 20.666666666666668]}, '_timestamp': 1717480442.591352}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FP Reward Distribution': {'_type': 'histogram', 'values': [9, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.6666666666666665, 7.3125, 11.958333333333332, 16.604166666666668, 21.25, 25.895833333333332, 30.541666666666668, 35.18749999999999, 39.83333333333333, 44.479166666666664, 49.12499999999999, 53.77083333333333, 58.416666666666664, 63.06249999999999, 67.70833333333333, 72.35416666666667, 77.0, 81.64583333333333, 86.29166666666667, 90.9375, 95.58333333333333, 100.22916666666667, 104.875, 109.52083333333333, 114.16666666666667, 118.8125, 123.45833333333333, 128.10416666666666, 132.74999999999997, 137.39583333333331, 142.04166666666666, 146.68749999999997, 151.33333333333331, 155.97916666666666, 160.62499999999997, 165.27083333333331, 169.91666666666666, 174.56249999999997, 179.20833333333331, 183.85416666666666, 188.49999999999997, 193.14583333333331, 197.79166666666666, 202.43749999999997, 207.08333333333331, 211.72916666666666, 216.37499999999997, 221.02083333333331, 225.66666666666666, 230.31249999999997, 234.95833333333331, 239.60416666666663, 244.24999999999997, 248.89583333333331, 253.54166666666663, 258.1875, 262.8333333333333, 267.4791666666667, 272.125, 276.7708333333333, 281.4166666666667, 286.0625, 290.7083333333333, 295.3541666666667, 300.0]}, '_timestamp': 1717480442.591514}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FN Reward Distribution': {'_type': 'histogram', 'values': [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [4.666666666666667, 6.24375, 7.820833333333333, 9.397916666666667, 10.975, 12.552083333333332, 14.129166666666666, 15.70625, 17.28333333333333, 18.860416666666666, 20.4375, 22.014583333333334, 23.591666666666665, 25.16875, 26.745833333333334, 28.322916666666664, 29.9, 31.477083333333333, 33.05416666666666, 34.631249999999994, 36.20833333333333, 37.78541666666666, 39.3625, 40.939583333333324, 42.51666666666666, 44.09374999999999, 45.67083333333333, 47.24791666666666, 48.824999999999996, 50.40208333333332, 51.97916666666666, 53.55624999999999, 55.133333333333326, 56.71041666666666, 58.287499999999994, 59.86458333333333, 61.441666666666656, 63.01874999999999, 64.59583333333333, 66.17291666666667, 67.75, 69.32708333333333, 70.90416666666667, 72.48125, 74.05833333333334, 75.63541666666666, 77.21249999999999, 78.78958333333333, 80.36666666666666, 81.94375, 83.52083333333333, 85.09791666666666, 86.675, 88.25208333333333, 89.82916666666667, 91.40625, 92.98333333333333, 94.56041666666667, 96.13749999999999, 97.71458333333332, 99.29166666666666, 100.86874999999999, 102.44583333333333, 104.02291666666666, 105.6]}, '_timestamp': 1717480442.591666}).
Epoch 900/1000, Train Loss: 0.7898127734661102, Val Loss: 0.3959910273551941, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 910/1000, Train Loss: 0.7334729135036469, Val Loss: 0.3966609835624695, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 920/1000, Train Loss: 0.6837699711322784, Val Loss: 0.39596906304359436, Train Acc: 0.875, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 930/1000, Train Loss: 0.7641901075839996, Val Loss: 0.3953726887702942, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 940/1000, Train Loss: 0.6748214662075043, Val Loss: 0.3948797285556793, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 950/1000, Train Loss: 0.6157141178846359, Val Loss: 0.3943302035331726, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 960/1000, Train Loss: 0.8954395949840546, Val Loss: 0.3936745524406433, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 970/1000, Train Loss: 0.7044942677021027, Val Loss: 0.39343374967575073, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 980/1000, Train Loss: 0.6591192185878754, Val Loss: 0.3936966359615326, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Epoch 990/1000, Train Loss: 0.7323343455791473, Val Loss: 0.3942383825778961, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 7.98828394799099e-06
Finished training model...
 ****** Running generation 0 ******
[32m[I 2024-06-04 01:54:20,508][39m Trial 0 finished with value: 0.10217592865228653 and parameters: {'hidden_size': 265, 'learning_rate': 0.0007988283947990888, 'weight_decay': 6.156213559328389e-05}. Best is trial 0 with value: 0.10217592865228653.
Population's average fitness: 342.18000 stdev: 903.95654
Best fitness: 4213.06667 - size: (4, 20) - species 1 - id 4
Average adjusted fitness: 0.079
Mean genetic distance 1.251, standard deviation 0.222
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20   4213.1    0.079     0
Total extinctions: 0
Generation time: 2.683 sec
 ****** Running generation 1 ******
Population's average fitness: 2738.32000 stdev: 8848.34295
Best fitness: 40889.33333 - size: (4, 19) - species 1 - id 24
Average adjusted fitness: 0.067
Mean genetic distance 1.146, standard deviation 0.270
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    1    20  40889.3    0.067     0
Total extinctions: 0
Generation time: 7.745 sec (5.214 average)
 ****** Running generation 2 ******
Population's average fitness: 7992.78333 stdev: 13990.30916
Best fitness: 41157.33333 - size: (4, 19) - species 1 - id 39
Average adjusted fitness: 0.194
Mean genetic distance 0.812, standard deviation 0.227
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    2    20  41157.3    0.194     0
Total extinctions: 0
Generation time: 7.671 sec (6.033 average)
 ****** Running generation 3 ******
Population's average fitness: 16196.66000 stdev: 22546.53630
Best fitness: 72425.40000 - size: (4, 18) - species 1 - id 66
Average adjusted fitness: 0.224
Mean genetic distance 0.677, standard deviation 0.191
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    3    20  72425.4    0.224     0
Total extinctions: 0
Generation time: 7.652 sec (6.438 average)
 ****** Running generation 4 ******
Population's average fitness: 23586.31667 stdev: 23913.51937
Best fitness: 72425.40000 - size: (4, 18) - species 1 - id 66
Average adjusted fitness: 0.326
Mean genetic distance 0.989, standard deviation 0.187
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    4    20  72425.4    0.326     1
Total extinctions: 0
Generation time: 7.676 sec (6.686 average)
 ****** Running generation 5 ******
Population's average fitness: 26211.17333 stdev: 29205.02779
Best fitness: 72526.86667 - size: (4, 19) - species 1 - id 99
Average adjusted fitness: 0.361
Mean genetic distance 0.982, standard deviation 0.250
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    5    20  72526.9    0.361     0
Total extinctions: 0
Generation time: 7.608 sec (6.839 average)
 ****** Running generation 6 ******
Population's average fitness: 27338.64000 stdev: 33602.67120
Best fitness: 85392.73333 - size: (5, 18) - species 1 - id 117
Average adjusted fitness: 0.320
Mean genetic distance 0.693, standard deviation 0.223
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    6    20  85392.7    0.320     0
Total extinctions: 0
Generation time: 7.648 sec (6.955 average)
 ****** Running generation 7 ******
Population's average fitness: 41686.01333 stdev: 34888.23007
Best fitness: 85392.73333 - size: (5, 18) - species 1 - id 117
Average adjusted fitness: 0.488
Mean genetic distance 0.895, standard deviation 0.256
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    7    20  85392.7    0.488     1
Total extinctions: 0
Generation time: 7.597 sec (7.035 average)
 ****** Running generation 8 ******
Population's average fitness: 23410.64000 stdev: 32635.99617
Best fitness: 85392.73333 - size: (5, 18) - species 1 - id 117
Average adjusted fitness: 0.274
Mean genetic distance 0.833, standard deviation 0.263
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    8    20  85392.7    0.274     2
Total extinctions: 0
Generation time: 7.665 sec (7.105 average)
 ****** Running generation 9 ******
Population's average fitness: 36556.37667 stdev: 36271.37878
Best fitness: 87438.20000 - size: (4, 16) - species 1 - id 172
Average adjusted fitness: 0.418
Mean genetic distance 0.776, standard deviation 0.169
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    9    20  87438.2    0.418     0
Total extinctions: 0
Generation time: 7.675 sec (7.162 average)
 ****** Running generation 10 ******
Population's average fitness: 19644.37000 stdev: 32338.10797
Best fitness: 87438.20000 - size: (4, 16) - species 1 - id 172
Average adjusted fitness: 0.225
Mean genetic distance 0.805, standard deviation 0.152
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1   10    20  87438.2    0.225     1
Total extinctions: 0
Generation time: 7.693 sec (7.663 average)
 ****** Running generation 11 ******
Population's average fitness: 29271.82333 stdev: 36253.31054
Best fitness: 87438.20000 - size: (4, 16) - species 1 - id 172
Average adjusted fitness: 0.335
Mean genetic distance 0.895, standard deviation 0.276
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1   11    20  87438.2    0.335     2
Total extinctions: 0
Generation time: 7.664 sec (7.655 average)
 ****** Running generation 12 ******
Population's average fitness: 43792.10667 stdev: 33858.48565
Best fitness: 87438.20000 - size: (4, 16) - species 1 - id 172
Average adjusted fitness: 0.501
Mean genetic distance 0.816, standard deviation 0.215
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1   12    20  87438.2    0.501     3
Total extinctions: 0
Generation time: 7.492 sec (7.637 average)
 ****** Running generation 13 ******
Population's average fitness: 41416.33000 stdev: 37115.26676
Best fitness: 100836.33333 - size: (4, 15) - species 1 - id 226
Average adjusted fitness: 0.411
Mean genetic distance 0.850, standard deviation 0.206
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1   13    20  100836.3    0.411     0
Total extinctions: 0
Generation time: 7.545 sec (7.626 average)
 ****** Running generation 14 ******
Traceback (most recent call last):
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 97, in <module>
    # run the simulation with the true reward function
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 39, in start_simulation
    population.run(run_simulation, max_generations)
  File "/Users/alextang/.pyenv/versions/nocturne_lab/lib/python3.10/site-packages/neat/population.py", line 89, in run
    fitness_function(list(iteritems(self.population)), self.config)
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 379, in run_simulation
    clock.tick(60)  # 60 FPS
KeyboardInterrupt