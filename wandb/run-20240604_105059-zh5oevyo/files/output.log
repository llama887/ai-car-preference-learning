Epoch 0/1000, Train Loss: 4.387224197387695, Val Loss: 0.7567594647407532, Train Acc: 0.475, Val Acc: 0.699999988079071, LR: 0.00026055588777113735
Epoch 10/1000, Train Loss: 3.114758849143982, Val Loss: 0.6296869516372681, Train Acc: 0.4, Val Acc: 0.800000011920929, LR: 0.0002553866460947495
Epoch 20/1000, Train Loss: 1.6154624819755554, Val Loss: 0.5683233141899109, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.00025021740441836165
Epoch 30/1000, Train Loss: 1.167640581727028, Val Loss: 0.5345577001571655, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.0002450481627419738
Epoch 40/1000, Train Loss: 1.5571978986263275, Val Loss: 0.5073838233947754, Train Acc: 0.55, Val Acc: 0.800000011920929, LR: 0.000239878921065586
Epoch 50/1000, Train Loss: 1.7086895108222961, Val Loss: 0.4930797517299652, Train Acc: 0.425, Val Acc: 0.800000011920929, LR: 0.00023470967938919824
Epoch 60/1000, Train Loss: 1.8584948182106018, Val Loss: 0.48546385765075684, Train Acc: 0.65, Val Acc: 0.800000011920929, LR: 0.00022954043771281044
Epoch 70/1000, Train Loss: 1.5078840255737305, Val Loss: 0.45369571447372437, Train Acc: 0.625, Val Acc: 0.800000011920929, LR: 0.00022437119603642267
Epoch 80/1000, Train Loss: 1.8789024949073792, Val Loss: 0.4382496774196625, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.0002192019543600349
Epoch 90/1000, Train Loss: 1.362006962299347, Val Loss: 0.4420359134674072, Train Acc: 0.625, Val Acc: 0.800000011920929, LR: 0.00021403271268364708
Epoch 100/1000, Train Loss: 1.5021467208862305, Val Loss: 0.41830459237098694, Train Acc: 0.6, Val Acc: 0.800000011920929, LR: 0.00020886347100725931
Epoch 110/1000, Train Loss: 1.1353293657302856, Val Loss: 0.4191768169403076, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.00020369422933087155
Epoch 120/1000, Train Loss: 1.3074076473712921, Val Loss: 0.3992401659488678, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.00019852498765448378
Epoch 130/1000, Train Loss: 1.0138803124427795, Val Loss: 0.378855437040329, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 0.00019335574597809595
Epoch 140/1000, Train Loss: 1.519170105457306, Val Loss: 0.3917336165904999, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.00018818650430170818
Epoch 150/1000, Train Loss: 1.452669620513916, Val Loss: 0.3804956078529358, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 0.00018301726262532036
Epoch 160/1000, Train Loss: 1.7112553119659424, Val Loss: 0.37412601709365845, Train Acc: 0.65, Val Acc: 0.800000011920929, LR: 0.00017784802094893257
Epoch 170/1000, Train Loss: 1.2698700428009033, Val Loss: 0.3730952739715576, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.00017267877927254474
Epoch 180/1000, Train Loss: 1.5752626061439514, Val Loss: 0.3802589774131775, Train Acc: 0.625, Val Acc: 0.800000011920929, LR: 0.00016750953759615697
Epoch 190/1000, Train Loss: 1.3372186422348022, Val Loss: 0.3865341544151306, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 0.00016234029591976915
Epoch 200/1000, Train Loss: 1.086990475654602, Val Loss: 0.3824187219142914, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.0001571710542433813
Epoch 210/1000, Train Loss: 1.1205122470855713, Val Loss: 0.38578400015830994, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.00015200181256699348
Epoch 220/1000, Train Loss: 1.2130208611488342, Val Loss: 0.3891350328922272, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.00014683257089060563
Epoch 230/1000, Train Loss: 0.8694158494472504, Val Loss: 0.38586682081222534, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.00014166332921421778
Epoch 240/1000, Train Loss: 0.9046564102172852, Val Loss: 0.40061187744140625, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.00013649408753782993
Epoch 250/1000, Train Loss: 0.8583590239286423, Val Loss: 0.39357441663742065, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 0.00013132484586144208
Epoch 260/1000, Train Loss: 0.8446985185146332, Val Loss: 0.3853467106819153, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 0.00012615560418505423
Epoch 270/1000, Train Loss: 0.716071605682373, Val Loss: 0.3882623612880707, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 0.00012098636250866643
Epoch 280/1000, Train Loss: 1.124068409204483, Val Loss: 0.38660603761672974, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 0.00011581712083227875
Epoch 290/1000, Train Loss: 0.6999764144420624, Val Loss: 0.3847934305667877, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 0.00011064787915589103
Epoch 300/1000, Train Loss: 1.0843629240989685, Val Loss: 0.3854006826877594, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 0.0001054786374795033
Epoch 310/1000, Train Loss: 0.8153652548789978, Val Loss: 0.393939733505249, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 0.00010030939580311557
Epoch 320/1000, Train Loss: 1.1148812770843506, Val Loss: 0.39176028966903687, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 9.514015412672786e-05
Epoch 330/1000, Train Loss: 0.9018225371837616, Val Loss: 0.39507365226745605, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 8.997091245034015e-05
Epoch 340/1000, Train Loss: 0.6845719814300537, Val Loss: 0.3922547996044159, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 8.480167077395247e-05
Epoch 350/1000, Train Loss: 0.7785075902938843, Val Loss: 0.3886301517486572, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 7.963242909756477e-05
Epoch 360/1000, Train Loss: 0.7978213578462601, Val Loss: 0.3896889388561249, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 7.446318742117704e-05
Epoch 370/1000, Train Loss: 0.5517323613166809, Val Loss: 0.38459092378616333, Train Acc: 0.875, Val Acc: 0.800000011920929, LR: 6.929394574478936e-05
Epoch 380/1000, Train Loss: 0.9916182160377502, Val Loss: 0.386908620595932, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 6.41247040684017e-05
Epoch 390/1000, Train Loss: 0.8974988758563995, Val Loss: 0.3892960548400879, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 5.8955462392013954e-05
Epoch 400/1000, Train Loss: 0.8411982655525208, Val Loss: 0.38761845231056213, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 5.378622071562624e-05
Epoch 410/1000, Train Loss: 1.2473434209823608, Val Loss: 0.38862553238868713, Train Acc: 0.65, Val Acc: 0.800000011920929, LR: 4.861697903923852e-05
Epoch 420/1000, Train Loss: 0.661370113492012, Val Loss: 0.3909692168235779, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 4.3447737362850804e-05
Epoch 430/1000, Train Loss: 0.7879469692707062, Val Loss: 0.3894839584827423, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 3.827849568646309e-05
Epoch 440/1000, Train Loss: 0.8456298112869263, Val Loss: 0.39228856563568115, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 3.3109254010075375e-05
Epoch 450/1000, Train Loss: 1.0446524024009705, Val Loss: 0.39631953835487366, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 2.7940012333687647e-05
Epoch 460/1000, Train Loss: 1.1949421167373657, Val Loss: 0.39648279547691345, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 2.277077065729992e-05
Epoch 470/1000, Train Loss: 0.713701605796814, Val Loss: 0.39459818601608276, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 1.7601528980912187e-05
Epoch 480/1000, Train Loss: 0.8197015225887299, Val Loss: 0.3938937187194824, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 1.2432287304524454e-05
Epoch 490/1000, Train Loss: 0.6713263392448425, Val Loss: 0.39381271600723267, Train Acc: 0.9, Val Acc: 0.800000011920929, LR: 7.263045628136713e-06
Epoch 500/1000, Train Loss: 0.9207981824874878, Val Loss: 0.393924742937088, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 510/1000, Train Loss: 0.6799478977918625, Val Loss: 0.39393916726112366, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 520/1000, Train Loss: 0.9605613946914673, Val Loss: 0.39390334486961365, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 530/1000, Train Loss: 0.7147518396377563, Val Loss: 0.39376696944236755, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 540/1000, Train Loss: 0.7061600983142853, Val Loss: 0.3937152028083801, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 550/1000, Train Loss: 1.0013217628002167, Val Loss: 0.3939186930656433, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 560/1000, Train Loss: 0.813301682472229, Val Loss: 0.39391469955444336, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 570/1000, Train Loss: 0.8672689199447632, Val Loss: 0.3934928774833679, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 580/1000, Train Loss: 0.8729721307754517, Val Loss: 0.39297956228256226, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 590/1000, Train Loss: 0.8409655690193176, Val Loss: 0.39327067136764526, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 600/1000, Train Loss: 0.9172675609588623, Val Loss: 0.3933226764202118, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 610/1000, Train Loss: 0.9815883338451385, Val Loss: 0.3929128646850586, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 620/1000, Train Loss: 0.8354019522666931, Val Loss: 0.39308691024780273, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 630/1000, Train Loss: 0.5562811344861984, Val Loss: 0.3928711414337158, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 640/1000, Train Loss: 0.7995325326919556, Val Loss: 0.39310699701309204, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 650/1000, Train Loss: 0.8219863176345825, Val Loss: 0.3926848769187927, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 660/1000, Train Loss: 0.7349618673324585, Val Loss: 0.39256423711776733, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 670/1000, Train Loss: 0.6410425901412964, Val Loss: 0.39237064123153687, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 680/1000, Train Loss: 0.876083493232727, Val Loss: 0.3921072483062744, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 690/1000, Train Loss: 1.0546255707740784, Val Loss: 0.39258304238319397, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 700/1000, Train Loss: 0.9483013153076172, Val Loss: 0.39282822608947754, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 710/1000, Train Loss: 0.9513921141624451, Val Loss: 0.39300134778022766, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 720/1000, Train Loss: 0.6834664344787598, Val Loss: 0.3933085501194, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 730/1000, Train Loss: 0.9901983439922333, Val Loss: 0.3933005928993225, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 740/1000, Train Loss: 0.9019610285758972, Val Loss: 0.39301353693008423, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 750/1000, Train Loss: 1.027702420949936, Val Loss: 0.39310407638549805, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 760/1000, Train Loss: 0.9561191201210022, Val Loss: 0.39318686723709106, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 770/1000, Train Loss: 0.9828888177871704, Val Loss: 0.39338794350624084, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 780/1000, Train Loss: 0.8928676545619965, Val Loss: 0.3930482268333435, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 790/1000, Train Loss: 0.863044798374176, Val Loss: 0.39270898699760437, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 800/1000, Train Loss: 0.723936527967453, Val Loss: 0.39273956418037415, Train Acc: 0.825, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 810/1000, Train Loss: 0.814736932516098, Val Loss: 0.3926507532596588, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 820/1000, Train Loss: 0.7736606299877167, Val Loss: 0.3921385705471039, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 830/1000, Train Loss: 0.8547863662242889, Val Loss: 0.39231258630752563, Train Acc: 0.65, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 840/1000, Train Loss: 0.9036183655261993, Val Loss: 0.3926379382610321, Train Acc: 0.725, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 850/1000, Train Loss: 0.7271984964609146, Val Loss: 0.39263448119163513, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 860/1000, Train Loss: 0.7136792838573456, Val Loss: 0.3930339813232422, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 870/1000, Train Loss: 0.7932526171207428, Val Loss: 0.39248618483543396, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 880/1000, Train Loss: 0.7922481894493103, Val Loss: 0.39287278056144714, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 890/1000, Train Loss: 0.8128421604633331, Val Loss: 0.3932150900363922, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 900/1000, Train Loss: 0.9577163755893707, Val Loss: 0.3933916985988617, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 910/1000, Train Loss: 0.8088975250720978, Val Loss: 0.3932173252105713, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 920/1000, Train Loss: 0.9349757134914398, Val Loss: 0.39317670464515686, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
[34m[1mwandb[39m[22m: [33mWARNING[39m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'Train Loss': 4.387224197387695, 'Validation Loss': 0.7567594647407532, 'Train Accuracy': 0.475, 'Validation Accuracy': 0.699999988079071, '_timestamp': 1717512660.2616751}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.weight': {'_type': 'histogram', 'values': [2983, 3552, 3725, 3736, 3632, 3658, 3808, 3779, 3636, 3734, 3665, 3703, 3811, 3777, 3714, 3750, 3599, 3664, 3950, 3772, 3841, 3858, 3730, 3770, 3734, 3845, 3756, 3693, 3719, 3862, 3635, 3719, 3764, 3702, 3677, 3631, 3678, 3683, 3729, 3640, 3599, 3719, 3841, 3776, 3731, 3712, 3743, 3708, 3696, 3656, 3699, 3779, 3533, 3736, 3730, 3749, 3762, 3742, 3662, 3745, 3795, 3713, 3753, 2807], 'bins': [-0.10207090526819229, -0.09888102114200592, -0.09569114446640015, -0.09250126034021378, -0.0893113762140274, -0.08612149208784103, -0.08293161541223526, -0.07974173128604889, -0.07655184715986252, -0.07336197048425674, -0.07017208635807037, -0.066982202231884, -0.06379232555627823, -0.06060244143009186, -0.05741255730390549, -0.054222676903009415, -0.05103279650211334, -0.04784291237592697, -0.0446530319750309, -0.04146314784884453, -0.038273267447948456, -0.035083383321762085, -0.03189350292086601, -0.02870362065732479, -0.02551373839378357, -0.022323857992887497, -0.019133975729346275, -0.015944093465805054, -0.012754211202263832, -0.009564329870045185, -0.0063744476065039635, -0.003184565808624029, 5.315989255905151e-06, 0.0031951977871358395, 0.006385079585015774, 0.009574961848556995, 0.012764843180775642, 0.015954725444316864, 0.019144607707858086, 0.022334489971399307, 0.02552437037229538, 0.0287142526358366, 0.03190413489937782, 0.035094015300273895, 0.038283899426460266, 0.04147377982735634, 0.04466366395354271, 0.04785354435443878, 0.05104342848062515, 0.054233308881521225, 0.0574231892824173, 0.06061307340860367, 0.06380295753479004, 0.06699283421039581, 0.07018271833658218, 0.07337260246276855, 0.07656247913837433, 0.0797523632645607, 0.08294224739074707, 0.08613212406635284, 0.08932200819253922, 0.09251189231872559, 0.09570177644491196, 0.09889165312051773, 0.1020815372467041]}, '_timestamp': 1717512660.268165}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.bias': {'_type': 'histogram', 'values': [3, 2, 1, 5, 4, 5, 2, 4, 3, 8, 7, 2, 2, 9, 5, 4, 7, 2, 7, 3, 3, 1, 2, 5, 8, 3, 4, 3, 8, 2, 3, 4, 1, 4, 4, 2, 3, 8, 1, 4, 5, 5, 7, 4, 2, 7, 3, 2, 8, 7, 6, 5, 3, 5, 9, 4, 3, 3, 1, 1, 2, 4, 7, 2], 'bins': [-0.03256972134113312, -0.03154834359884262, -0.030526965856552124, -0.029505588114261627, -0.02848421037197113, -0.027462834492325783, -0.026441456750035286, -0.02542007900774479, -0.024398701265454292, -0.023377323523163795, -0.0223559457808733, -0.021334568038582802, -0.020313192158937454, -0.019291814416646957, -0.01827043667435646, -0.017249058932065964, -0.016227681189775467, -0.01520630344748497, -0.014184925705194473, -0.013163548894226551, -0.012142171151936054, -0.011120793409645557, -0.010099416598677635, -0.009078038856387138, -0.008056661114096642, -0.007035283371806145, -0.006013906095176935, -0.004992528818547726, -0.003971151076257229, -0.0029497735667973757, -0.0019283960573375225, -0.0009070185478776693, 0.00011435896158218384, 0.001135736471042037, 0.00215711398050189, 0.0031784914899617434, 0.0041998689994215965, 0.005221246741712093, 0.006242624018341303, 0.007264001294970512, 0.00828537903726101, 0.009306756779551506, 0.010328134521842003, 0.011349511332809925, 0.012370889075100422, 0.013392266817390919, 0.014413643628358841, 0.015435021370649338, 0.016456399112939835, 0.01747777685523033, 0.018499154597520828, 0.019520532339811325, 0.020541910082101822, 0.02156328596174717, 0.022584663704037666, 0.023606041446328163, 0.02462741918861866, 0.025648796930909157, 0.026670174673199654, 0.02769155241549015, 0.028712928295135498, 0.029734306037425995, 0.03075568377971649, 0.03177706152200699, 0.032798439264297485]}, '_timestamp': 1717512660.2684429}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.weight': {'_type': 'histogram', 'values': [159, 13, 5, 7, 6, 1, 2, 1, 4, 1, 0, 0, 0, 3, 1, 0, 1, 1, 1, 2, 0, 1, 1, 2, 1, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 3, 1, 0, 0, 2, 1, 1, 1, 2, 0, 0, 1, 0, 3, 1, 1, 1, 1, 0, 0, 1, 1, 4, 1, 5, 9], 'bins': [0.999477744102478, 0.9994940757751465, 0.9995104074478149, 0.9995266795158386, 0.9995430111885071, 0.9995593428611755, 0.999575674533844, 0.9995920062065125, 0.9996082782745361, 0.9996246099472046, 0.999640941619873, 0.9996572732925415, 0.99967360496521, 0.9996899366378784, 0.9997062087059021, 0.9997225403785706, 0.999738872051239, 0.9997552037239075, 0.9997715353965759, 0.9997878074645996, 0.9998041391372681, 0.9998204708099365, 0.999836802482605, 0.9998531341552734, 0.9998694658279419, 0.9998857378959656, 0.999902069568634, 0.9999184012413025, 0.999934732913971, 0.9999510645866394, 0.9999673366546631, 0.9999836683273315, 1.0, 1.0000163316726685, 1.000032663345337, 1.0000489950180054, 1.0000653266906738, 1.0000816583633423, 1.0000978708267212, 1.0001142024993896, 1.000130534172058, 1.0001468658447266, 1.000163197517395, 1.0001795291900635, 1.000195860862732, 1.0002121925354004, 1.0002285242080688, 1.0002448558807373, 1.0002610683441162, 1.0002774000167847, 1.0002937316894531, 1.0003100633621216, 1.00032639503479, 1.0003427267074585, 1.000359058380127, 1.0003753900527954, 1.0003917217254639, 1.0004080533981323, 1.0004243850708008, 1.0004405975341797, 1.0004569292068481, 1.0004732608795166, 1.000489592552185, 1.0005059242248535, 1.000522255897522]}, '_timestamp': 1717512660.268638}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.bias': {'_type': 'histogram', 'values': [13, 9, 2, 6, 4, 23, 4, 0, 1, 0, 1, 1, 3, 2, 3, 2, 1, 1, 1, 1, 1, 0, 0, 1, 3, 3, 1, 3, 0, 0, 0, 75, 0, 0, 0, 0, 3, 3, 2, 2, 3, 1, 2, 1, 0, 1, 1, 1, 2, 2, 3, 1, 0, 2, 1, 2, 1, 2, 18, 1, 6, 6, 7, 24], 'bins': [-0.0005221550236456096, -0.0005058370879851282, -0.0004895190941169858, -0.0004732011293526739, -0.000456883164588362, -0.00044056519982405007, -0.00042424723505973816, -0.00040792927029542625, -0.00039161130553111434, -0.00037529334076680243, -0.0003589753760024905, -0.0003426574112381786, -0.0003263394464738667, -0.0003100214817095548, -0.0002937035169452429, -0.00027738555218093097, -0.00026106758741661906, -0.0002447496517561376, -0.00022843167243991047, -0.00021211370767559856, -0.00019579574291128665, -0.00017947777814697474, -0.00016315981338266283, -0.00014684184861835092, -0.00013052389840595424, -0.00011420592636568472, -9.788796160137281e-05, -8.15699968370609e-05, -6.52520393487066e-05, -4.8934070946415886e-05, -3.2616109820082784e-05, -1.6298145055770874e-05, 1.9819708541035652e-08, 1.6337784472852945e-05, 3.2655749237164855e-05, 4.897371036349796e-05, 6.529167876578867e-05, 8.160963625414297e-05, 9.792760101845488e-05, 0.00011424556578276679, 0.0001305635378230363, 0.000146881488035433, 0.0001631994527997449, 0.00017951741756405681, 0.00019583538232836872, 0.00021215334709268063, 0.00022847131185699254, 0.0002447892911732197, 0.00026110722683370113, 0.00027742519159801304, 0.00029374315636232495, 0.00031006112112663686, 0.00032637908589094877, 0.0003426970506552607, 0.0003590150154195726, 0.0003753329801838845, 0.0003916509449481964, 0.0004079689097125083, 0.00042428687447682023, 0.00044060483924113214, 0.00045692280400544405, 0.00047324076876975596, 0.0004895587335340679, 0.0005058767274022102, 0.0005221946630626917]}, '_timestamp': 1717512660.268808}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.weight': {'_type': 'histogram', 'values': [853, 1026, 1103, 1080, 1049, 1092, 1121, 1069, 1089, 1071, 1078, 1119, 1070, 1144, 1049, 1040, 1154, 1012, 1165, 976, 1102, 1079, 1062, 1049, 1117, 1123, 1047, 1080, 1130, 1091, 1070, 1159, 1171, 1101, 1148, 1135, 1071, 1027, 1053, 1170, 1109, 1098, 1144, 1081, 1111, 1021, 1129, 1064, 1095, 1097, 1059, 1061, 1022, 1047, 1072, 1092, 1094, 1111, 1026, 1074, 1104, 1050, 1133, 930], 'bins': [-0.15142226219177246, -0.14668861031532288, -0.14195497334003448, -0.1372213214635849, -0.13248766958713531, -0.12775401771068573, -0.12302037328481674, -0.11828672885894775, -0.11355307698249817, -0.10881943255662918, -0.10408578813076019, -0.09935213625431061, -0.09461849182844162, -0.08988483995199203, -0.08515119552612305, -0.08041754364967346, -0.07568389922380447, -0.07095025479793549, -0.0662166029214859, -0.061482954770326614, -0.05674930661916733, -0.05201566219329834, -0.04728201404213905, -0.04254836589097977, -0.03781471773982048, -0.033081069588661194, -0.028347421437501907, -0.02361377514898777, -0.018880126997828484, -0.014146478846669197, -0.009412831626832485, -0.004679183941334486, 5.4463744163513184e-05, 0.004788111429661512, 0.009521759115159512, 0.014255406334996223, 0.01898905448615551, 0.023722702637314796, 0.028456348925828934, 0.03318999707698822, 0.03792364522814751, 0.04265729337930679, 0.04739094153046608, 0.052124589681625366, 0.056858234107494354, 0.06159188225865364, 0.06632553040981293, 0.07105918228626251, 0.0757928267121315, 0.08052647113800049, 0.08526012301445007, 0.08999376744031906, 0.09472741931676865, 0.09946106374263763, 0.10419471561908722, 0.10892836004495621, 0.1136620044708252, 0.11839565634727478, 0.12312930077314377, 0.12786294519901276, 0.13259659707546234, 0.13733024895191193, 0.1420639008283615, 0.1467975378036499, 0.1515311896800995]}, '_timestamp': 1717512660.269492}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.bias': {'_type': 'histogram', 'values': [4, 5, 3, 0, 5, 4, 6, 4, 7, 3, 4, 3, 5, 6, 5, 5, 7, 3, 3, 1, 3, 7, 4, 4, 4, 2, 4, 4, 3, 3, 3, 4, 1, 4, 5, 3, 3, 4, 6, 3, 4, 6, 5, 5, 6, 4, 4, 3, 2, 5, 5, 4, 2, 6, 10, 5, 4, 3, 4, 3, 4, 3, 7, 2], 'bins': [-0.06151072680950165, -0.05959948152303696, -0.05768823251128197, -0.055776987224817276, -0.053865738213062286, -0.051954492926597595, -0.050043247640132904, -0.048131998628377914, -0.04622075334191322, -0.044309504330158234, -0.04239825904369354, -0.04048701375722885, -0.03857576474547386, -0.03666451945900917, -0.03475327417254448, -0.03284202516078949, -0.0309307798743248, -0.029019532725214958, -0.027108285576105118, -0.025197038426995277, -0.023285791277885437, -0.021374545991420746, -0.019463298842310905, -0.017552051693201065, -0.015640804544091225, -0.013729558326303959, -0.011818311177194118, -0.009907064959406853, -0.007995817810297012, -0.006084571126848459, -0.004173324443399906, -0.002262077759951353, -0.0003508310765028, 0.001560415606945753, 0.003471662290394306, 0.005382908973842859, 0.007294155657291412, 0.009205402806401253, 0.011116649024188519, 0.013027896173298359, 0.014939142391085625, 0.016850389540195465, 0.018761636689305305, 0.020672883838415146, 0.022584129124879837, 0.024495376273989677, 0.026406623423099518, 0.028317870572209358, 0.0302291177213192, 0.03214036300778389, 0.03405161201953888, 0.03596285730600357, 0.03787410259246826, 0.03978535160422325, 0.04169659689068794, 0.043607842177152634, 0.04551909118890762, 0.047430336475372314, 0.049341585487127304, 0.051252830773591995, 0.053164076060056686, 0.055075325071811676, 0.05698657035827637, 0.05889781937003136, 0.06080906465649605]}, '_timestamp': 1717512660.2697222}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.weight': {'_type': 'histogram', 'values': [89, 22, 15, 13, 6, 4, 2, 1, 2, 3, 1, 3, 1, 2, 5, 2, 4, 1, 2, 1, 2, 3, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 3, 3, 1, 1, 2, 1, 3, 1, 1, 1, 4, 4, 3, 2, 0, 3, 1, 3, 2, 1, 4, 5, 0, 2, 5, 12], 'bins': [0.999477744102478, 0.9994940757751465, 0.9995104074478149, 0.9995266795158386, 0.9995430111885071, 0.9995593428611755, 0.999575674533844, 0.9995919466018677, 0.9996082782745361, 0.9996246099472046, 0.999640941619873, 0.9996572732925415, 0.9996735453605652, 0.9996898770332336, 0.9997062087059021, 0.9997225403785706, 0.9997388124465942, 0.9997551441192627, 0.9997714757919312, 0.9997878074645996, 0.9998041391372681, 0.9998204112052917, 0.9998367428779602, 0.9998530745506287, 0.9998694062232971, 0.9998857378959656, 0.9999020099639893, 0.9999183416366577, 0.9999346733093262, 0.9999510049819946, 0.9999672770500183, 0.9999836087226868, 0.9999999403953552, 1.000016212463379, 1.0000325441360474, 1.0000488758087158, 1.0000652074813843, 1.0000815391540527, 1.0000978708267212, 1.0001142024993896, 1.000130534172058, 1.0001468658447266, 1.0001630783081055, 1.000179409980774, 1.0001957416534424, 1.0002120733261108, 1.0002284049987793, 1.0002447366714478, 1.0002610683441162, 1.0002774000167847, 1.0002937316894531, 1.000309944152832, 1.0003262758255005, 1.000342607498169, 1.0003589391708374, 1.0003752708435059, 1.0003916025161743, 1.0004079341888428, 1.0004242658615112, 1.0004405975341797, 1.0004568099975586, 1.000473141670227, 1.0004894733428955, 1.000505805015564, 1.0005221366882324]}, '_timestamp': 1717512660.269908}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.bias': {'_type': 'histogram', 'values': [20, 9, 10, 5, 5, 19, 3, 1, 5, 7, 4, 4, 6, 4, 2, 1, 0, 1, 2, 1, 0, 2, 0, 3, 2, 6, 6, 3, 0, 0, 0, 3, 0, 0, 0, 0, 6, 0, 6, 3, 1, 0, 1, 6, 1, 3, 2, 0, 2, 1, 3, 0, 2, 2, 2, 2, 6, 6, 16, 4, 7, 7, 8, 32], 'bins': [-0.0005222263280302286, -0.0005059065879322588, -0.0004895868478342891, -0.00047326707863248885, -0.0004569473385345191, -0.00044062756933271885, -0.0004243078292347491, -0.0004079880891367793, -0.0003916683199349791, -0.0003753485798370093, -0.00035902883973903954, -0.0003427090705372393, -0.00032638933043926954, -0.00031006959034129977, -0.00029374982113949955, -0.0002774300810415298, -0.00026111031183972955, -0.0002447905717417598, -0.00022847083164379, -0.000212151076993905, -0.00019583132234402, -0.00017951158224605024, -0.00016319182759616524, -0.00014687207294628024, -0.00013055233284831047, -0.00011423257819842547, -9.791282354854047e-05, -8.159307617461309e-05, -6.52733288006857e-05, -4.8953574150800705e-05, -3.263382677687332e-05, -1.631407576496713e-05, 5.675246939063072e-09, 1.6325426258845255e-05, 3.2645177270751446e-05, 4.896492464467883e-05, 6.528467929456383e-05, 8.160442666849121e-05, 9.79241740424186e-05, 0.0001142439286923036, 0.0001305636833421886, 0.00014688342344015837, 0.00016320317809004337, 0.00017952293273992836, 0.00019584267283789814, 0.00021216242748778313, 0.00022848218213766813, 0.0002448019222356379, 0.0002611216623336077, 0.0002774414315354079, 0.00029376117163337767, 0.0003100809408351779, 0.00032640068093314767, 0.00034272042103111744, 0.00035904019023291767, 0.00037535993033088744, 0.0003916796704288572, 0.00040799943963065743, 0.0004243191797286272, 0.000440638919826597, 0.0004569586890283972, 0.000473278429126367, 0.0004895981983281672, 0.000505917938426137, 0.0005222376785241067]}, '_timestamp': 1717512660.270072}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.weight': {'_type': 'histogram', 'values': [965, 1083, 1073, 1087, 1061, 1115, 1090, 1016, 1062, 1022, 1050, 1101, 1095, 1068, 1093, 1097, 1120, 1087, 1116, 1084, 1034, 1149, 1034, 1122, 1091, 1147, 1040, 1097, 1096, 1142, 1108, 1143, 1081, 1077, 1041, 1051, 1120, 1087, 1112, 1065, 1064, 1056, 1046, 1070, 1091, 1123, 1070, 1106, 1075, 1111, 1024, 1103, 1076, 1132, 1138, 1017, 1079, 1102, 1077, 1075, 1104, 1124, 1050, 934], 'bins': [-0.15151363611221313, -0.1467795968055725, -0.1420455425977707, -0.13731150329113007, -0.13257746398448944, -0.12784342467784882, -0.1231093779206276, -0.11837533116340637, -0.11364129185676575, -0.10890724509954453, -0.1041732057929039, -0.09943915903568268, -0.09470511972904205, -0.08997107297182083, -0.0852370336651802, -0.08050298690795898, -0.07576894760131836, -0.07103490084409714, -0.06630085408687592, -0.06156681478023529, -0.05683277174830437, -0.052098728716373444, -0.04736468568444252, -0.0426306426525116, -0.037896595895290375, -0.03316255286335945, -0.028428511694073677, -0.023694468662142754, -0.01896042376756668, -0.014226381666958332, -0.009492337703704834, -0.0047582946717739105, -2.425163984298706e-05, 0.004709791392087936, 0.00944383442401886, 0.014177878387272358, 0.018911920487880707, 0.02364596538245678, 0.028380008414387703, 0.03311404958367348, 0.0378480926156044, 0.04258213937282562, 0.047316182404756546, 0.05205022543668747, 0.05678426846861839, 0.061518311500549316, 0.06625235080718994, 0.07098639756441116, 0.07572044432163239, 0.08045448362827301, 0.08518853038549423, 0.08992256969213486, 0.09465661644935608, 0.0993906557559967, 0.10412470251321793, 0.10885874181985855, 0.11359278857707977, 0.1183268278837204, 0.12306087464094162, 0.12779492139816284, 0.13252896070480347, 0.1372630000114441, 0.14199703931808472, 0.14673109352588654, 0.15146513283252716]}, '_timestamp': 1717512660.2706501}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.bias': {'_type': 'histogram', 'values': [2, 6, 3, 6, 2, 3, 4, 4, 2, 3, 3, 3, 2, 4, 7, 1, 6, 6, 3, 2, 11, 1, 3, 3, 5, 4, 5, 3, 7, 3, 7, 7, 4, 4, 9, 3, 7, 5, 4, 3, 1, 3, 5, 6, 4, 1, 4, 2, 6, 4, 4, 8, 6, 6, 2, 5, 2, 4, 5, 3, 6, 2, 2, 2], 'bins': [-0.06167740002274513, -0.05974444001913071, -0.05781148001551628, -0.05587851628661156, -0.05394555628299713, -0.052012596279382706, -0.05007963627576828, -0.048146676272153854, -0.04621371626853943, -0.044280752539634705, -0.04234779253602028, -0.04041483253240585, -0.03848187252879143, -0.036548912525177, -0.03461594879627228, -0.03268298879265785, -0.030750028789043427, -0.028817068785429, -0.026884106919169426, -0.024951146915555, -0.023018185049295425, -0.021085225045681, -0.019152265042066574, -0.017219303175807, -0.015286343172192574, -0.013353382237255573, -0.011420421302318573, -0.009487461298704147, -0.007554500363767147, -0.005621539428830147, -0.003688578959554434, -0.0017556182574480772, 0.00017734244465827942, 0.002110303146764636, 0.004043263848870993, 0.005976224318146706, 0.007909185253083706, 0.009842146188020706, 0.011775106191635132, 0.013708067126572132, 0.015641028061509132, 0.017573988065123558, 0.019506949931383133, 0.02143990993499756, 0.023372869938611984, 0.02530583180487156, 0.027238791808485985, 0.02917175367474556, 0.031104713678359985, 0.03303767368197441, 0.03497063368558884, 0.03690359741449356, 0.038836557418107986, 0.04076951742172241, 0.04270247742533684, 0.04463543742895126, 0.04656840115785599, 0.04850136116147041, 0.05043432116508484, 0.052367281168699265, 0.05430024117231369, 0.056233201175928116, 0.05816616490483284, 0.060099124908447266, 0.06203208491206169]}, '_timestamp': 1717512660.27167}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.weight': {'_type': 'histogram', 'values': [100, 40, 17, 8, 6, 7, 3, 5, 3, 4, 2, 3, 0, 2, 0, 0, 1, 2, 1, 2, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 7, 4, 4, 1, 2, 4, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 0, 0, 2, 1, 4, 1, 2, 5], 'bins': [0.999477744102478, 0.9994940757751465, 0.9995104074478149, 0.9995266795158386, 0.9995430111885071, 0.9995593428611755, 0.999575674533844, 0.9995919466018677, 0.9996082782745361, 0.9996246099472046, 0.999640941619873, 0.9996572732925415, 0.9996735453605652, 0.9996898770332336, 0.9997062087059021, 0.9997225403785706, 0.9997388124465942, 0.9997551441192627, 0.9997714757919312, 0.9997878074645996, 0.9998041391372681, 0.9998204112052917, 0.9998367428779602, 0.9998530745506287, 0.9998694062232971, 0.9998857378959656, 0.9999020099639893, 0.9999183416366577, 0.9999346733093262, 0.9999510049819946, 0.9999672770500183, 0.9999836087226868, 0.9999999403953552, 1.000016212463379, 1.0000325441360474, 1.0000488758087158, 1.0000652074813843, 1.0000815391540527, 1.0000978708267212, 1.0001142024993896, 1.000130534172058, 1.0001468658447266, 1.0001630783081055, 1.000179409980774, 1.0001957416534424, 1.0002120733261108, 1.0002284049987793, 1.0002447366714478, 1.0002610683441162, 1.0002774000167847, 1.0002937316894531, 1.000309944152832, 1.0003262758255005, 1.000342607498169, 1.0003589391708374, 1.0003752708435059, 1.0003916025161743, 1.0004079341888428, 1.0004242658615112, 1.0004405975341797, 1.0004568099975586, 1.000473141670227, 1.0004894733428955, 1.000505805015564, 1.0005221366882324]}, '_timestamp': 1717512660.271824}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.bias': {'_type': 'histogram', 'values': [32, 12, 13, 16, 2, 13, 2, 2, 9, 1, 6, 0, 2, 1, 2, 3, 0, 2, 2, 3, 5, 1, 1, 3, 3, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 1, 6, 4, 4, 4, 3, 1, 3, 3, 1, 2, 1, 3, 6, 2, 2, 4, 1, 2, 1, 4, 4, 4, 9, 11, 28], 'bins': [-0.0005221769097261131, -0.0005058582173660398, -0.0004895395250059664, -0.0004732208326458931, -0.00045690214028581977, -0.00044058344792574644, -0.00042426472646184266, -0.00040794603410176933, -0.000391627341741696, -0.00037530864938162267, -0.00035898995702154934, -0.000342671264661476, -0.0003263525723014027, -0.00031003387994132936, -0.00029371518758125603, -0.0002773964952211827, -0.0002610777737572789, -0.0002447590813972056, -0.0002284404035890475, -0.00021212169667705894, -0.0001958030043169856, -0.00017948431195691228, -0.00016316561959683895, -0.00014684692723676562, -0.0001305282348766923, -0.00011420953524066135, -9.789083560463041e-05, -8.157214324455708e-05, -6.525345088448375e-05, -4.893475124845281e-05, -3.2616058888379484e-05, -1.629736289032735e-05, 2.1333107724785805e-08, 1.634002910577692e-05, 3.2658725103829056e-05, 4.8977417463902384e-05, 6.529611709993333e-05, 8.161480946000665e-05, 9.793350182007998e-05, 0.00011425220145611092, 0.00013057090109214187, 0.0001468895934522152, 0.00016320828581228852, 0.00017952697817236185, 0.00019584567053243518, 0.0002121643628925085, 0.00022848306980449706, 0.00024480174761265516, 0.0002611204399727285, 0.0002774391614366323, 0.0002937578537967056, 0.00031007654615677893, 0.00032639523851685226, 0.0003427139308769256, 0.0003590326232369989, 0.00037535131559707224, 0.00039167000795714557, 0.0004079887003172189, 0.00042430739267729223, 0.000440626114141196, 0.00045694480650126934, 0.00047326349886134267, 0.000489582191221416, 0.0005059008835814893, 0.0005222195759415627]}, '_timestamp': 1717512660.271969}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.weight': {'_type': 'histogram', 'values': [8, 2, 7, 4, 4, 6, 2, 3, 4, 8, 7, 4, 4, 3, 6, 6, 4, 2, 7, 1, 5, 3, 6, 11, 1, 4, 4, 5, 1, 6, 5, 2, 5, 3, 1, 5, 2, 4, 2, 3, 5, 1, 4, 1, 6, 2, 3, 5, 6, 8, 2, 2, 4, 3, 4, 1, 3, 6, 2, 6, 7, 3, 2, 7], 'bins': [-0.20932887494564056, -0.20278869569301605, -0.19624853134155273, -0.18970835208892822, -0.1831681728363037, -0.1766279935836792, -0.1700878143310547, -0.16354764997959137, -0.15700747072696686, -0.15046729147434235, -0.14392712712287903, -0.13738694787025452, -0.13084676861763, -0.1243065893650055, -0.11776641756296158, -0.11122624576091766, -0.10468606650829315, -0.09814588725566864, -0.09160571545362473, -0.08506554365158081, -0.0785253643989563, -0.07198518514633179, -0.06544501334428787, -0.05890483781695366, -0.052364662289619446, -0.04582448676228523, -0.03928431123495102, -0.032744135707616806, -0.026203960180282593, -0.01966378465294838, -0.013123609125614166, -0.006583433598279953, -4.3258070945739746e-05, 0.0064969174563884735, 0.013037092983722687, 0.0195772685110569, 0.026117444038391113, 0.03265761956572533, 0.03919779509305954, 0.04573797062039375, 0.052278146147727966, 0.05881832167506218, 0.06535849720239639, 0.07189866900444031, 0.07843884825706482, 0.08497902750968933, 0.09151919931173325, 0.09805937111377716, 0.10459955036640167, 0.11113972961902618, 0.1176799014210701, 0.12422007322311401, 0.13076025247573853, 0.13730043172836304, 0.14384061098098755, 0.15038077533245087, 0.15692095458507538, 0.1634611338376999, 0.1700012981891632, 0.17654147744178772, 0.18308165669441223, 0.18962183594703674, 0.19616201519966125, 0.20270217955112457, 0.20924235880374908]}, '_timestamp': 1717512660.2721238}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.bias': {'_type': 'histogram', 'values': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'bins': [-0.503677248954773, -0.48805224895477295, -0.47242724895477295, -0.45680224895477295, -0.44117724895477295, -0.42555224895477295, -0.40992724895477295, -0.39430224895477295, -0.37867724895477295, -0.36305224895477295, -0.34742724895477295, -0.33180224895477295, -0.31617724895477295, -0.30055224895477295, -0.28492724895477295, -0.26930224895477295, -0.25367724895477295, -0.23805226385593414, -0.22242726385593414, -0.20680226385593414, -0.19117726385593414, -0.17555226385593414, -0.15992726385593414, -0.14430226385593414, -0.12867726385593414, -0.11305226385593414, -0.09742726385593414, -0.08180226385593414, -0.06617726385593414, -0.05055226385593414, -0.03492726385593414, -0.019302263855934143, -0.003677263157442212, 0.011947737075388432, 0.027572736144065857, 0.04319773614406586, 0.05882273614406586, 0.07444773614406586, 0.09007273614406586, 0.10569773614406586, 0.12132273614406586, 0.13694773614406586, 0.15257273614406586, 0.16819773614406586, 0.18382273614406586, 0.19944773614406586, 0.21507273614406586, 0.23069773614406586, 0.24632273614406586, 0.26194775104522705, 0.27757275104522705, 0.29319775104522705, 0.30882275104522705, 0.32444775104522705, 0.34007275104522705, 0.35569775104522705, 0.37132275104522705, 0.38694775104522705, 0.40257275104522705, 0.41819775104522705, 0.43382275104522705, 0.44944775104522705, 0.46507275104522705, 0.48069775104522705, 0.49632275104522705]}, '_timestamp': 1717512660.272297}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TP Reward Distribution': {'_type': 'histogram', 'values': [1, 0, 0, 1, 0, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.6666666666666665, 3.048958333333333, 3.43125, 3.8135416666666666, 4.195833333333333, 4.578125, 4.960416666666666, 5.3427083333333325, 5.725, 6.107291666666667, 6.489583333333333, 6.871874999999999, 7.254166666666666, 7.636458333333334, 8.018749999999999, 8.401041666666666, 8.783333333333333, 9.165624999999999, 9.547916666666666, 9.930208333333333, 10.3125, 10.694791666666665, 11.077083333333333, 11.459375, 11.841666666666665, 12.223958333333332, 12.60625, 12.988541666666665, 13.370833333333332, 13.753124999999999, 14.135416666666666, 14.517708333333331, 14.899999999999999, 15.282291666666666, 15.664583333333331, 16.046875, 16.429166666666667, 16.811458333333334, 17.193749999999998, 17.576041666666665, 17.958333333333332, 18.340625, 18.722916666666666, 19.105208333333334, 19.4875, 19.869791666666668, 20.252083333333335, 20.634375, 21.016666666666666, 21.398958333333333, 21.78125, 22.163541666666667, 22.545833333333334, 22.928125, 23.310416666666665, 23.692708333333332, 24.075, 24.457291666666666, 24.839583333333334, 25.221875, 25.604166666666668, 25.98645833333333, 26.36875, 26.751041666666666, 27.133333333333333]}, '_timestamp': 1717512660.272463}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TN Reward Distribution': {'_type': 'histogram', 'values': [5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.6666666666666665, 7.3125, 11.958333333333332, 16.604166666666668, 21.25, 25.895833333333332, 30.541666666666668, 35.18749999999999, 39.83333333333333, 44.479166666666664, 49.12499999999999, 53.77083333333333, 58.416666666666664, 63.06249999999999, 67.70833333333333, 72.35416666666667, 77.0, 81.64583333333333, 86.29166666666667, 90.9375, 95.58333333333333, 100.22916666666667, 104.875, 109.52083333333333, 114.16666666666667, 118.8125, 123.45833333333333, 128.10416666666666, 132.74999999999997, 137.39583333333331, 142.04166666666666, 146.68749999999997, 151.33333333333331, 155.97916666666666, 160.62499999999997, 165.27083333333331, 169.91666666666666, 174.56249999999997, 179.20833333333331, 183.85416666666666, 188.49999999999997, 193.14583333333331, 197.79166666666666, 202.43749999999997, 207.08333333333331, 211.72916666666666, 216.37499999999997, 221.02083333333331, 225.66666666666666, 230.31249999999997, 234.95833333333331, 239.60416666666663, 244.24999999999997, 248.89583333333331, 253.54166666666663, 258.1875, 262.8333333333333, 267.4791666666667, 272.125, 276.7708333333333, 281.4166666666667, 286.0625, 290.7083333333333, 295.3541666666667, 300.0]}, '_timestamp': 1717512660.272602}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FP Reward Distribution': {'_type': 'histogram', 'values': [2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [3.533333333333333, 3.8135416666666666, 4.09375, 4.373958333333333, 4.654166666666667, 4.934374999999999, 5.214583333333333, 5.494791666666666, 5.7749999999999995, 6.055208333333333, 6.335416666666666, 6.615625, 6.895833333333332, 7.176041666666666, 7.456249999999999, 7.736458333333332, 8.016666666666666, 8.296875, 8.577083333333333, 8.857291666666665, 9.1375, 9.417708333333332, 9.697916666666664, 9.978124999999999, 10.258333333333333, 10.538541666666665, 10.818749999999998, 11.098958333333332, 11.379166666666665, 11.659374999999999, 11.939583333333331, 12.219791666666666, 12.499999999999998, 12.78020833333333, 13.060416666666665, 13.340624999999998, 13.620833333333332, 13.901041666666664, 14.181249999999999, 14.461458333333331, 14.741666666666665, 15.021874999999998, 15.30208333333333, 15.582291666666665, 15.862499999999997, 16.14270833333333, 16.422916666666666, 16.703125, 16.98333333333333, 17.26354166666666, 17.543749999999996, 17.82395833333333, 18.104166666666664, 18.384375, 18.664583333333333, 18.944791666666664, 19.224999999999994, 19.50520833333333, 19.785416666666663, 20.065624999999997, 20.34583333333333, 20.626041666666666, 20.90625, 21.186458333333327, 21.466666666666665]}, '_timestamp': 1717512660.2727349}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FN Reward Distribution': {'_type': 'histogram', 'values': [5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [3.3333333333333335, 4.93125, 6.529166666666667, 8.127083333333333, 9.725, 11.322916666666666, 12.920833333333334, 14.51875, 16.116666666666667, 17.714583333333334, 19.3125, 20.910416666666666, 22.508333333333333, 24.10625, 25.704166666666666, 27.302083333333332, 28.9, 30.497916666666665, 32.09583333333333, 33.69375, 35.291666666666664, 36.889583333333334, 38.487500000000004, 40.08541666666667, 41.68333333333334, 43.28125, 44.87916666666667, 46.47708333333333, 48.075, 49.672916666666666, 51.270833333333336, 52.86875, 54.46666666666667, 56.06458333333334, 57.6625, 59.26041666666667, 60.858333333333334, 62.456250000000004, 64.05416666666666, 65.65208333333334, 67.25, 68.84791666666666, 70.44583333333333, 72.04374999999999, 73.64166666666667, 75.23958333333333, 76.83749999999999, 78.43541666666665, 80.03333333333333, 81.63125, 83.22916666666666, 84.82708333333333, 86.425, 88.02291666666666, 89.62083333333332, 91.21875, 92.81666666666666, 94.41458333333333, 96.01249999999999, 97.61041666666667, 99.20833333333333, 100.80624999999999, 102.40416666666665, 104.00208333333333, 105.6]}, '_timestamp': 1717512660.272865}).
Epoch 930/1000, Train Loss: 0.6665849685668945, Val Loss: 0.3931449055671692, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 940/1000, Train Loss: 0.7173075973987579, Val Loss: 0.3925691246986389, Train Acc: 0.775, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 950/1000, Train Loss: 0.6841578781604767, Val Loss: 0.3921797573566437, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 960/1000, Train Loss: 0.7760547399520874, Val Loss: 0.3919190466403961, Train Acc: 0.7, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 970/1000, Train Loss: 0.9285672008991241, Val Loss: 0.3922842741012573, Train Acc: 0.75, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 980/1000, Train Loss: 0.9071493744850159, Val Loss: 0.3925364315509796, Train Acc: 0.8, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Epoch 990/1000, Train Loss: 0.8968432247638702, Val Loss: 0.3927469849586487, Train Acc: 0.675, Val Acc: 0.800000011920929, LR: 2.61072811938775e-06
Finished training model...
Simulating on true reward function...
 ****** Running generation 0 ******
[33m[W 2024-06-04 10:51:17,541][39m Trial 0 failed with parameters: {'hidden_size': 263, 'learning_rate': 0.00026107281193877614, 'weight_decay': 0.0007759257559497646} because of the following error: The value None could not be cast to float..
[33m[W 2024-06-04 10:51:17,541][39m Trial 0 failed with value None.
Population's average fitness: 2897.37667 stdev: 11644.37732
Best fitness: 53590.73333 - size: (4, 20) - species 1 - id 13
Average adjusted fitness: 0.054
Mean genetic distance 1.158, standard deviation 0.232
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20  53590.7    0.054     0
Total extinctions: 0
Generation time: 7.832 sec
 ****** Running generation 1 ******
Population's average fitness: 7498.69333 stdev: 16076.94967
Best fitness: 53590.73333 - size: (4, 20) - species 1 - id 13
Average adjusted fitness: 0.140
Mean genetic distance 1.260, standard deviation 0.234
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    1    20  53590.7    0.140     1
Total extinctions: 0
Generation time: 7.754 sec (7.793 average)
 ****** Running generation 2 ******
Population's average fitness: 21868.61333 stdev: 20750.88800
Best fitness: 53590.73333 - size: (4, 20) - species 1 - id 13
Average adjusted fitness: 0.408
Mean genetic distance 1.299, standard deviation 0.267
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    2    20  53590.7    0.408     2
Total extinctions: 0
Generation time: 7.555 sec (7.714 average)
 ****** Running generation 3 ******
Population's average fitness: 25225.37667 stdev: 24649.21356
Best fitness: 67650.00000 - size: (5, 20) - species 1 - id 70
Average adjusted fitness: 0.373
Mean genetic distance 1.149, standard deviation 0.329
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    3    20  67650.0    0.373     0
Total extinctions: 0
Generation time: 7.604 sec (7.686 average)
 ****** Running generation 4 ******
Population's average fitness: 30718.44000 stdev: 27736.76523
Best fitness: 67650.00000 - size: (5, 20) - species 1 - id 70
Average adjusted fitness: 0.454
Mean genetic distance 0.846, standard deviation 0.275
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    4    20  67650.0    0.454     1
Total extinctions: 0
Generation time: 7.565 sec (7.662 average)
 ****** Running generation 5 ******
Population's average fitness: 31515.42333 stdev: 30861.99028
Best fitness: 67650.00000 - size: (5, 20) - species 1 - id 70
Average adjusted fitness: 0.466
Mean genetic distance 0.913, standard deviation 0.322
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    5    20  67650.0    0.466     2
Total extinctions: 0
Generation time: 7.560 sec (7.645 average)
 ****** Running generation 6 ******
Population's average fitness: 44493.40667 stdev: 33036.64783
Best fitness: 115935.53333 - size: (5, 19) - species 1 - id 121
Average adjusted fitness: 0.384
Mean genetic distance 0.817, standard deviation 0.256
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    6    20  115935.5    0.384     0
Total extinctions: 0
Generation time: 7.471 sec (7.620 average)
 ****** Running generation 7 ******
Population's average fitness: 37830.07333 stdev: 39664.62413
Best fitness: 115935.53333 - size: (5, 19) - species 1 - id 121
Average adjusted fitness: 0.326
Mean genetic distance 0.762, standard deviation 0.194
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    7    20  115935.5    0.326     1
Total extinctions: 0
Generation time: 7.574 sec (7.614 average)
 ****** Running generation 8 ******
Population's average fitness: 43829.92000 stdev: 37983.54785
Best fitness: 115935.53333 - size: (5, 19) - species 1 - id 121
Average adjusted fitness: 0.378
Mean genetic distance 0.766, standard deviation 0.218
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    8    20  115935.5    0.378     2
Total extinctions: 0
Generation time: 7.525 sec (7.604 average)
 ****** Running generation 9 ******
Population's average fitness: 50741.88333 stdev: 35645.69711
Best fitness: 115935.53333 - size: (5, 19) - species 1 - id 121
Average adjusted fitness: 0.438
Mean genetic distance 0.927, standard deviation 0.161
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    9    20  115935.5    0.438     3
Total extinctions: 0
Generation time: 7.536 sec (7.598 average)
simulating on trained reward function...
 ****** Running generation 0 ******
Population's average fitness: -4.76545 stdev: 15.88106
Best fitness: 1.04234 - size: (4, 20) - species 1 - id 8
Average adjusted fitness: 0.922
Mean genetic distance 1.114, standard deviation 0.348
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20      1.0    0.922     0
Total extinctions: 0
Generation time: 7.776 sec
 ****** Running generation 1 ******
Population's average fitness: -1.64069 stdev: 1.73962
Best fitness: 0.54276 - size: (4, 20) - species 1 - id 8
Average adjusted fitness: 0.678
Mean genetic distance 1.094, standard deviation 0.347
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    1    20      0.5    0.678     1
Total extinctions: 0
Generation time: 1.115 sec (4.446 average)
 ****** Running generation 2 ******
Population's average fitness: -1.66384 stdev: 2.26284
Best fitness: 1.36887 - size: (4, 19) - species 1 - id 45
Average adjusted fitness: 0.737
Mean genetic distance 1.323, standard deviation 0.215
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    2    20      1.4    0.737     0
Total extinctions: 0
Generation time: 0.986 sec (3.292 average)
 ****** Running generation 3 ******
Traceback (most recent call last):
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 106, in <module>
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 39, in start_simulation
    population.run(run_simulation, max_generations)
  File "/Users/alextang/.pyenv/versions/nocturne_lab/lib/python3.10/site-packages/neat/population.py", line 89, in run
    fitness_function(list(iteritems(self.population)), self.config)
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 379, in run_simulation
    clock.tick(60)  # 60 FPS
KeyboardInterrupt