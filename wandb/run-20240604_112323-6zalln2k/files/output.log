Epoch 0/1000, Train Loss: 2.6774362325668335, Val Loss: 0.7943891882896423, Train Acc: 0.525, Val Acc: 0.0, LR: 0.0008561514907965211
Epoch 10/1000, Train Loss: 3.1553558111190796, Val Loss: 0.5853219628334045, Train Acc: 0.375, Val Acc: 1.0, LR: 0.0008391660601260226
Epoch 20/1000, Train Loss: 1.8112388849258423, Val Loss: 0.609346330165863, Train Acc: 0.575, Val Acc: 1.0, LR: 0.0008221806294555241
Epoch 30/1000, Train Loss: 1.4899336099624634, Val Loss: 0.6043971180915833, Train Acc: 0.475, Val Acc: 1.0, LR: 0.0008051951987850252
Epoch 40/1000, Train Loss: 1.7681725025177002, Val Loss: 0.5813716650009155, Train Acc: 0.475, Val Acc: 1.0, LR: 0.0007882097681145264
Epoch 50/1000, Train Loss: 1.5979390740394592, Val Loss: 0.5593300461769104, Train Acc: 0.6, Val Acc: 1.0, LR: 0.0007712243374440276
Epoch 60/1000, Train Loss: 1.6225103735923767, Val Loss: 0.5543478727340698, Train Acc: 0.625, Val Acc: 1.0, LR: 0.0007542389067735286
Epoch 70/1000, Train Loss: 1.2796661853790283, Val Loss: 0.4953298568725586, Train Acc: 0.6, Val Acc: 1.0, LR: 0.0007372534761030297
Epoch 80/1000, Train Loss: 1.2024129629135132, Val Loss: 0.44921836256980896, Train Acc: 0.575, Val Acc: 1.0, LR: 0.0007202680454325307
Epoch 90/1000, Train Loss: 1.2373512983322144, Val Loss: 0.3716544508934021, Train Acc: 0.625, Val Acc: 1.0, LR: 0.0007032826147620321
Epoch 100/1000, Train Loss: 0.7122049927711487, Val Loss: 0.23287947475910187, Train Acc: 0.875, Val Acc: 1.0, LR: 0.0006862971840915331
Epoch 110/1000, Train Loss: 0.5775602757930756, Val Loss: 0.14699015021324158, Train Acc: 0.8, Val Acc: 1.0, LR: 0.0006693117534210345
Epoch 120/1000, Train Loss: 1.043558657169342, Val Loss: 0.12851352989673615, Train Acc: 0.7, Val Acc: 1.0, LR: 0.0006523263227505356
Epoch 130/1000, Train Loss: 1.2493278086185455, Val Loss: 0.14452466368675232, Train Acc: 0.775, Val Acc: 1.0, LR: 0.0006353408920800369
Epoch 140/1000, Train Loss: 0.5992860198020935, Val Loss: 0.13156132400035858, Train Acc: 0.825, Val Acc: 1.0, LR: 0.0006183554614095381
Epoch 150/1000, Train Loss: 0.8702352941036224, Val Loss: 0.14818890392780304, Train Acc: 0.8, Val Acc: 1.0, LR: 0.000601370030739039
Epoch 160/1000, Train Loss: 0.8875179588794708, Val Loss: 0.12351435422897339, Train Acc: 0.725, Val Acc: 1.0, LR: 0.0005843846000685401
Epoch 170/1000, Train Loss: 0.6888718605041504, Val Loss: 0.1019231304526329, Train Acc: 0.85, Val Acc: 1.0, LR: 0.0005673991693980414
Epoch 180/1000, Train Loss: 0.9245530962944031, Val Loss: 0.11527249962091446, Train Acc: 0.825, Val Acc: 1.0, LR: 0.0005504137387275427
Epoch 190/1000, Train Loss: 0.6740475744009018, Val Loss: 0.10232262313365936, Train Acc: 0.875, Val Acc: 1.0, LR: 0.0005334283080570437
Epoch 200/1000, Train Loss: 0.7006122767925262, Val Loss: 0.15367263555526733, Train Acc: 0.85, Val Acc: 1.0, LR: 0.0005164428773865447
Epoch 210/1000, Train Loss: 1.1463424563407898, Val Loss: 0.10139743983745575, Train Acc: 0.775, Val Acc: 1.0, LR: 0.0004994574467160459
Epoch 220/1000, Train Loss: 0.7351594567298889, Val Loss: 0.09390755742788315, Train Acc: 0.85, Val Acc: 1.0, LR: 0.000482472016045547
Epoch 230/1000, Train Loss: 0.5790670216083527, Val Loss: 0.10293459892272949, Train Acc: 0.8, Val Acc: 1.0, LR: 0.0004654865853750484
Epoch 240/1000, Train Loss: 1.0156054496765137, Val Loss: 0.09972912818193436, Train Acc: 0.75, Val Acc: 1.0, LR: 0.00044850115470454976
Epoch 250/1000, Train Loss: 0.7463500201702118, Val Loss: 0.09825751930475235, Train Acc: 0.825, Val Acc: 1.0, LR: 0.000431515724034051
Epoch 260/1000, Train Loss: 0.7724148631095886, Val Loss: 0.12348882108926773, Train Acc: 0.8, Val Acc: 1.0, LR: 0.00041453029336355256
Epoch 270/1000, Train Loss: 0.6376686096191406, Val Loss: 0.09701527655124664, Train Acc: 0.825, Val Acc: 1.0, LR: 0.0003975448626930541
Epoch 280/1000, Train Loss: 0.8753561675548553, Val Loss: 0.11719608306884766, Train Acc: 0.85, Val Acc: 1.0, LR: 0.00038055943202255563
Epoch 290/1000, Train Loss: 0.42738600075244904, Val Loss: 0.09504115581512451, Train Acc: 0.925, Val Acc: 1.0, LR: 0.0003635740013520571
Epoch 300/1000, Train Loss: 0.6291983723640442, Val Loss: 0.0904313176870346, Train Acc: 0.825, Val Acc: 1.0, LR: 0.00034658857068155854
Epoch 310/1000, Train Loss: 0.5056068003177643, Val Loss: 0.09170619398355484, Train Acc: 0.85, Val Acc: 1.0, LR: 0.00032960314001105996
Epoch 320/1000, Train Loss: 0.36324442923069, Val Loss: 0.08302401751279831, Train Acc: 0.925, Val Acc: 1.0, LR: 0.00031261770934056155
Epoch 330/1000, Train Loss: 0.6648772656917572, Val Loss: 0.08739490807056427, Train Acc: 0.8, Val Acc: 1.0, LR: 0.0002956322786700631
Epoch 340/1000, Train Loss: 0.7095333337783813, Val Loss: 0.0855526477098465, Train Acc: 0.9, Val Acc: 1.0, LR: 0.0002786468479995647
Epoch 350/1000, Train Loss: 0.36456921696662903, Val Loss: 0.08258236199617386, Train Acc: 0.95, Val Acc: 1.0, LR: 0.00026166141732906627
Epoch 360/1000, Train Loss: 0.5139731466770172, Val Loss: 0.0859716385602951, Train Acc: 0.875, Val Acc: 1.0, LR: 0.00024467598665856764
Epoch 370/1000, Train Loss: 0.5512391030788422, Val Loss: 0.08534689247608185, Train Acc: 0.875, Val Acc: 1.0, LR: 0.00022769055598806902
Epoch 380/1000, Train Loss: 0.3616914749145508, Val Loss: 0.08928308635950089, Train Acc: 0.9, Val Acc: 1.0, LR: 0.0002107051253175704
Epoch 390/1000, Train Loss: 0.6679886281490326, Val Loss: 0.08676241338253021, Train Acc: 0.825, Val Acc: 1.0, LR: 0.00019371969464707157
Epoch 400/1000, Train Loss: 0.3209339380264282, Val Loss: 0.08097943663597107, Train Acc: 0.9, Val Acc: 1.0, LR: 0.00017673426397657287
Epoch 410/1000, Train Loss: 0.32765695452690125, Val Loss: 0.08111802488565445, Train Acc: 0.925, Val Acc: 1.0, LR: 0.00015974883330607413
Epoch 420/1000, Train Loss: 0.5692657232284546, Val Loss: 0.08429230749607086, Train Acc: 0.85, Val Acc: 1.0, LR: 0.00014276340263557537
Epoch 430/1000, Train Loss: 0.45595279335975647, Val Loss: 0.08111904561519623, Train Acc: 0.85, Val Acc: 1.0, LR: 0.00012577797196507658
Epoch 440/1000, Train Loss: 0.4767914116382599, Val Loss: 0.08134907484054565, Train Acc: 0.85, Val Acc: 1.0, LR: 0.00010879254129457787
Epoch 450/1000, Train Loss: 0.4716802388429642, Val Loss: 0.08993746340274811, Train Acc: 0.9, Val Acc: 1.0, LR: 9.180711062407923e-05
Epoch 460/1000, Train Loss: 0.7014196515083313, Val Loss: 0.08127127587795258, Train Acc: 0.925, Val Acc: 1.0, LR: 7.482167995358058e-05
Epoch 470/1000, Train Loss: 0.5534228533506393, Val Loss: 0.08091975003480911, Train Acc: 0.85, Val Acc: 1.0, LR: 5.783624928308193e-05
Epoch 480/1000, Train Loss: 0.7857253402471542, Val Loss: 0.08380039036273956, Train Acc: 0.825, Val Acc: 1.0, LR: 4.0850818612583234e-05
Epoch 490/1000, Train Loss: 0.8179811537265778, Val Loss: 0.08401770889759064, Train Acc: 0.8, Val Acc: 1.0, LR: 2.3865387942084543e-05
Epoch 500/1000, Train Loss: 0.707272857427597, Val Loss: 0.08181043714284897, Train Acc: 0.8, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 510/1000, Train Loss: 0.9447011649608612, Val Loss: 0.08145599067211151, Train Acc: 0.85, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 520/1000, Train Loss: 0.6207582950592041, Val Loss: 0.08126012980937958, Train Acc: 0.825, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 530/1000, Train Loss: 0.556541234254837, Val Loss: 0.08116983622312546, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 540/1000, Train Loss: 0.4473710060119629, Val Loss: 0.08159651607275009, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 550/1000, Train Loss: 0.5207128822803497, Val Loss: 0.08225175738334656, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 560/1000, Train Loss: 0.66109699010849, Val Loss: 0.08214449882507324, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 570/1000, Train Loss: 0.7598485946655273, Val Loss: 0.082206130027771, Train Acc: 0.8, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 580/1000, Train Loss: 0.7712099254131317, Val Loss: 0.08199283480644226, Train Acc: 0.825, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 590/1000, Train Loss: 0.7092533707618713, Val Loss: 0.08191835880279541, Train Acc: 0.85, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 600/1000, Train Loss: 0.37736746668815613, Val Loss: 0.0820055678486824, Train Acc: 0.925, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 610/1000, Train Loss: 0.4952218532562256, Val Loss: 0.08213797956705093, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 620/1000, Train Loss: 0.3285306990146637, Val Loss: 0.08246368914842606, Train Acc: 0.975, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 630/1000, Train Loss: 0.638819083571434, Val Loss: 0.08240203559398651, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 640/1000, Train Loss: 0.8174479007720947, Val Loss: 0.08237147331237793, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 650/1000, Train Loss: 0.6459378749132156, Val Loss: 0.08172853291034698, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 660/1000, Train Loss: 0.697129637002945, Val Loss: 0.08174119889736176, Train Acc: 0.825, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 670/1000, Train Loss: 0.7004168629646301, Val Loss: 0.082127146422863, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 680/1000, Train Loss: 0.53977981954813, Val Loss: 0.08218361437320709, Train Acc: 0.925, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 690/1000, Train Loss: 0.4774133414030075, Val Loss: 0.08151690661907196, Train Acc: 0.925, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 700/1000, Train Loss: 0.34860658645629883, Val Loss: 0.08089534938335419, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 710/1000, Train Loss: 0.4035974144935608, Val Loss: 0.08175139129161835, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 720/1000, Train Loss: 0.5295157581567764, Val Loss: 0.08202116936445236, Train Acc: 0.85, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 730/1000, Train Loss: 0.5768486857414246, Val Loss: 0.08261927217245102, Train Acc: 0.825, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 740/1000, Train Loss: 0.5062007009983063, Val Loss: 0.0829727053642273, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 750/1000, Train Loss: 0.4007110148668289, Val Loss: 0.08276674896478653, Train Acc: 0.925, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 760/1000, Train Loss: 0.6241709589958191, Val Loss: 0.08200539648532867, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 770/1000, Train Loss: 0.4395620822906494, Val Loss: 0.0813441053032875, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 780/1000, Train Loss: 0.5285813212394714, Val Loss: 0.08155329525470734, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 790/1000, Train Loss: 0.36209045350551605, Val Loss: 0.08282089233398438, Train Acc: 0.925, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 800/1000, Train Loss: 0.19761770218610764, Val Loss: 0.08295001834630966, Train Acc: 0.975, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 810/1000, Train Loss: 0.39008454978466034, Val Loss: 0.08277035504579544, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 820/1000, Train Loss: 0.5633964240550995, Val Loss: 0.0824926346540451, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 830/1000, Train Loss: 0.5264996439218521, Val Loss: 0.08212259411811829, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 840/1000, Train Loss: 0.650799036026001, Val Loss: 0.08274774253368378, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 850/1000, Train Loss: 0.38360288739204407, Val Loss: 0.08190146833658218, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 860/1000, Train Loss: 0.3413161635398865, Val Loss: 0.08194015920162201, Train Acc: 0.925, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 870/1000, Train Loss: 0.6819785237312317, Val Loss: 0.08283667266368866, Train Acc: 0.85, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 880/1000, Train Loss: 0.5117369592189789, Val Loss: 0.08234363049268723, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 890/1000, Train Loss: 0.6393057405948639, Val Loss: 0.08167342841625214, Train Acc: 0.825, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 900/1000, Train Loss: 0.39505724608898163, Val Loss: 0.08195333182811737, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 910/1000, Train Loss: 0.519729346036911, Val Loss: 0.08239340037107468, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 920/1000, Train Loss: 0.7230881750583649, Val Loss: 0.08265765011310577, Train Acc: 0.9, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 930/1000, Train Loss: 0.6453498303890228, Val Loss: 0.08256135880947113, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 940/1000, Train Loss: 0.48189596831798553, Val Loss: 0.08179030567407608, Train Acc: 0.975, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 950/1000, Train Loss: 0.5072112679481506, Val Loss: 0.08148904889822006, Train Acc: 0.925, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 960/1000, Train Loss: 0.4624345302581787, Val Loss: 0.080989770591259, Train Acc: 0.925, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 970/1000, Train Loss: 0.6431357115507126, Val Loss: 0.080935038626194, Train Acc: 0.85, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 980/1000, Train Loss: 0.5487322956323624, Val Loss: 0.0810757428407669, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Epoch 990/1000, Train Loss: 0.8381123840808868, Val Loss: 0.08179885894060135, Train Acc: 0.875, Val Acc: 1.0, LR: 8.578500338635723e-06
Finished training model...
Simulating on true reward function...
 ****** Running generation 0 ******
[33m[W 2024-06-04 11:23:39,159][39m Trial 0 failed with parameters: {'hidden_size': 135, 'learning_rate': 0.000857850033863571, 'weight_decay': 0.0007237100263002759} because of the following error: The value None could not be cast to float..
[33m[W 2024-06-04 11:23:39,160][39m Trial 0 failed with value None.
[34m[1mwandb[39m[22m: [33mWARNING[39m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'Train Loss': 2.6774362325668335, 'Validation Loss': 0.7943891882896423, 'Train Accuracy': 0.525, 'Validation Accuracy': 0.0, '_timestamp': 1717514605.758688}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.weight': {'_type': 'histogram', 'values': [741, 1992, 1883, 1926, 1933, 1917, 1869, 1934, 1982, 1900, 1900, 1907, 1966, 1883, 1929, 1957, 1895, 1913, 1989, 1906, 1879, 1923, 1918, 1916, 1946, 1924, 1969, 1982, 1940, 1939, 1880, 1885, 1935, 1913, 1915, 1931, 1867, 1974, 1935, 1907, 2047, 1982, 1888, 1943, 1941, 1948, 1886, 1990, 1882, 1956, 1905, 1947, 1892, 1908, 1882, 1987, 1911, 1988, 1895, 1956, 1917, 1962, 1960, 1127], 'bins': [-0.10928960889577866, -0.10587334632873535, -0.10245708376169205, -0.09904082864522934, -0.09562456607818604, -0.09220830351114273, -0.08879204094409943, -0.08537578582763672, -0.08195952326059341, -0.07854326069355011, -0.0751269981265068, -0.0717107430100441, -0.0682944804430008, -0.06487821787595749, -0.06146195903420448, -0.05804569646716118, -0.05462943762540817, -0.05121317505836487, -0.047796912491321564, -0.04438065364956856, -0.04096439108252525, -0.03754813224077225, -0.03413186967372894, -0.030715610831975937, -0.027299348264932632, -0.023883087560534477, -0.020466826856136322, -0.017050566151738167, -0.013634305447340012, -0.010218044742941856, -0.006801784038543701, -0.003385523334145546, 3.073737025260925e-05, 0.0034469980746507645, 0.00686325877904892, 0.010279519483447075, 0.01369578018784523, 0.017112040892243385, 0.02052830159664154, 0.023944562301039696, 0.02736082300543785, 0.030777085572481155, 0.03419334441423416, 0.037609606981277466, 0.04102586582303047, 0.044442128390073776, 0.04785838723182678, 0.05127464979887009, 0.05469091236591339, 0.0581071712076664, 0.0615234337747097, 0.06493969261646271, 0.06835595518350601, 0.07177221775054932, 0.07518847286701202, 0.07860473543405533, 0.08202099800109863, 0.08543726056814194, 0.08885351568460464, 0.09226977825164795, 0.09568604081869125, 0.09910230338573456, 0.10251855850219727, 0.10593482106924057, 0.10935108363628387]}, '_timestamp': 1717514605.7628129}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.bias': {'_type': 'histogram', 'values': [2, 4, 2, 3, 3, 2, 0, 4, 3, 1, 2, 2, 2, 3, 3, 1, 2, 1, 4, 0, 3, 1, 4, 2, 2, 2, 0, 3, 1, 3, 3, 1, 1, 1, 2, 5, 1, 2, 2, 2, 3, 2, 4, 0, 3, 1, 0, 0, 2, 4, 2, 2, 4, 3, 0, 2, 2, 4, 0, 3, 2, 3, 2, 2], 'bins': [-0.030646340921521187, -0.02967548556625843, -0.028704630210995674, -0.027733774855732918, -0.02676291950047016, -0.025792064145207405, -0.02482120878994465, -0.023850353434681892, -0.022879498079419136, -0.02190864272415638, -0.020937787368893623, -0.019966932013630867, -0.01899607665836811, -0.018025221303105354, -0.017054365947842598, -0.01608351059257984, -0.015112655237317085, -0.014141798950731754, -0.013170943595468998, -0.012200088240206242, -0.011229232884943485, -0.010258377529680729, -0.009287522174417973, -0.008316666819155216, -0.00734581146389246, -0.0063749561086297035, -0.005404100753366947, -0.004433245398104191, -0.0034623900428414345, -0.002491534687578678, -0.0015206793323159218, -0.0005498239770531654, 0.0004210313782095909, 0.0013918867334723473, 0.0023627420887351036, 0.00333359744399786, 0.004304452799260616, 0.005275308154523373, 0.006246163509786129, 0.007217018865048885, 0.008187874220311642, 0.009158729575574398, 0.010129584930837154, 0.01110044028609991, 0.012071295641362667, 0.013042150996625423, 0.01401300635188818, 0.014983861707150936, 0.015954717993736267, 0.016925573348999023, 0.01789642870426178, 0.018867284059524536, 0.019838139414787292, 0.02080899477005005, 0.021779850125312805, 0.02275070548057556, 0.023721560835838318, 0.024692416191101074, 0.02566327154636383, 0.026634126901626587, 0.027604982256889343, 0.0285758376121521, 0.029546692967414856, 0.030517548322677612, 0.03148840367794037]}, '_timestamp': 1717514605.763056}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.weight': {'_type': 'histogram', 'values': [74, 5, 11, 5, 1, 3, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 2, 2, 7], 'bins': [0.9982840418815613, 0.9983376264572144, 0.9983912110328674, 0.9984447956085205, 0.9984983801841736, 0.9985519647598267, 0.9986055493354797, 0.9986591339111328, 0.9987127184867859, 0.998766303062439, 0.998819887638092, 0.9988734722137451, 0.9989270567893982, 0.9989806413650513, 0.9990342259407043, 0.9990878105163574, 0.9991413950920105, 0.9991949796676636, 0.9992485642433167, 0.9993021488189697, 0.9993557333946228, 0.9994093179702759, 0.999462902545929, 0.999516487121582, 0.9995700716972351, 0.9996236562728882, 0.9996772408485413, 0.9997308254241943, 0.9997844099998474, 0.9998379945755005, 0.9998915791511536, 0.9999451637268066, 0.9999988079071045, 1.0000523328781128, 1.0001059770584106, 1.000159502029419, 1.0002131462097168, 1.000266671180725, 1.000320315361023, 1.0003738403320312, 1.000427484512329, 1.0004810094833374, 1.0005346536636353, 1.0005881786346436, 1.0006418228149414, 1.0006953477859497, 1.0007489919662476, 1.0008025169372559, 1.0008561611175537, 1.000909686088562, 1.0009633302688599, 1.0010168552398682, 1.001070499420166, 1.0011240243911743, 1.0011776685714722, 1.0012311935424805, 1.0012848377227783, 1.0013383626937866, 1.0013920068740845, 1.0014455318450928, 1.0014991760253906, 1.001552700996399, 1.0016063451766968, 1.001659870147705, 1.001713514328003]}, '_timestamp': 1717514605.763243}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.bias': {'_type': 'histogram', 'values': [4, 3, 3, 0, 0, 27, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 5, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 38, 0, 0, 0, 0, 4, 0, 2, 2, 1, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 6, 0, 1, 1, 7, 13], 'bins': [-0.0017146370373666286, -0.0016610340680927038, -0.0016074312152341008, -0.001553828245960176, -0.001500225393101573, -0.0014466224238276482, -0.0013930194545537233, -0.0013394166016951203, -0.0012858136324211955, -0.0012322107795625925, -0.0011786078102886677, -0.0011250048410147429, -0.0010714019881561399, -0.001017799018882215, -0.0009641961078159511, -0.0009105931967496872, -0.0008569902856834233, -0.0008033873746171594, -0.0007497844635508955, -0.0006961814942769706, -0.0006425785832107067, -0.0005889756721444428, -0.0005353727610781789, -0.0004817698209080845, -0.0004281669098418206, -0.0003745639987755567, -0.0003209610586054623, -0.0002673581475391984, -0.00021375522192101926, -0.00016015229630284011, -0.00010654937796061859, -5.294645598041825e-05, 6.564659997820854e-07, 5.425938797998242e-05, 0.00010786230996018276, 0.00016146522830240428, 0.00021506815392058343, 0.00026867107953876257, 0.0003222739906050265, 0.00037587693077512085, 0.00042947984184138477, 0.0004830827529076487, 0.000536685693077743, 0.000590288604144007, 0.0006438915152102709, 0.0006974944262765348, 0.0007510973955504596, 0.0008047003066167235, 0.0008583032176829875, 0.0009119061287492514, 0.0009655090398155153, 0.0010191119508817792, 0.001072714920155704, 0.001126317773014307, 0.0011799207422882318, 0.0012335237115621567, 0.0012871265644207597, 0.0013407295336946845, 0.0013943323865532875, 0.0014479353558272123, 0.0015015383251011372, 0.0015551411779597402, 0.001608744147233665, 0.001662347000092268, 0.0017159499693661928]}, '_timestamp': 1717514605.763407}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.weight': {'_type': 'histogram', 'values': [193, 263, 268, 303, 288, 295, 299, 308, 337, 277, 279, 276, 278, 299, 258, 266, 301, 312, 259, 255, 279, 268, 280, 288, 293, 275, 304, 287, 264, 273, 288, 324, 320, 268, 288, 275, 303, 326, 281, 298, 289, 282, 292, 307, 294, 305, 294, 297, 291, 266, 269, 294, 317, 276, 278, 271, 287, 304, 290, 278, 272, 265, 293, 218], 'bins': [-0.21188807487487793, -0.20526769757270813, -0.19864732027053833, -0.19202694296836853, -0.18540658056735992, -0.17878620326519012, -0.17216582596302032, -0.16554544866085052, -0.15892507135868073, -0.15230469405651093, -0.14568431675434113, -0.13906395435333252, -0.13244357705116272, -0.12582319974899292, -0.11920282244682312, -0.11258244514465332, -0.10596206784248352, -0.09934169799089432, -0.09272132068872452, -0.08610094338655472, -0.07948057353496552, -0.07286019623279572, -0.06623981893062592, -0.059619445353746414, -0.05299907177686691, -0.04637869447469711, -0.03975832089781761, -0.03313794359564781, -0.02651757001876831, -0.01989719457924366, -0.01327681913971901, -0.006656443700194359, -3.606826066970825e-05, 0.006584307178854942, 0.013204682618379593, 0.019825058057904243, 0.026445433497428894, 0.033065807074308395, 0.039686184376478195, 0.0463065579533577, 0.052926935255527496, 0.059547308832407, 0.0661676824092865, 0.0727880597114563, 0.0794084370136261, 0.0860288068652153, 0.0926491841673851, 0.0992695614695549, 0.1058899313211441, 0.1125103086233139, 0.1191306859254837, 0.1257510632276535, 0.1323714405298233, 0.1389918178319931, 0.1456121802330017, 0.1522325575351715, 0.1588529348373413, 0.1654733121395111, 0.1720936894416809, 0.1787140667438507, 0.1853344440460205, 0.1919548064470291, 0.1985751837491989, 0.2051955610513687, 0.2118159383535385]}, '_timestamp': 1717514605.763684}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.bias': {'_type': 'histogram', 'values': [5, 2, 4, 2, 1, 1, 0, 4, 1, 1, 0, 4, 3, 1, 4, 1, 6, 1, 1, 2, 2, 5, 0, 1, 4, 1, 3, 1, 0, 8, 2, 0, 1, 2, 0, 2, 1, 0, 0, 2, 2, 3, 1, 2, 2, 3, 0, 2, 1, 5, 3, 1, 3, 6, 3, 4, 2, 0, 4, 2, 3, 0, 2, 2], 'bins': [-0.08373419940471649, -0.08109065145254135, -0.07844710350036621, -0.07580355554819107, -0.07316000759601593, -0.07051645964384079, -0.06787290424108505, -0.06522935628890991, -0.06258580833673477, -0.05994226038455963, -0.05729871243238449, -0.05465516448020935, -0.05201161652803421, -0.04936806857585907, -0.04672451689839363, -0.04408096894621849, -0.04143742099404335, -0.03879387304186821, -0.03615032508969307, -0.03350677341222763, -0.03086322546005249, -0.02821967750787735, -0.02557612955570221, -0.02293257974088192, -0.02028903178870678, -0.01764548383653164, -0.01500193402171135, -0.012358386069536209, -0.009714837186038494, -0.007071288302540779, -0.004427739884704351, -0.00178419123403728, 0.0008593574166297913, 0.0035029060672968626, 0.006146454717963934, 0.008790003135800362, 0.011433552019298077, 0.014077100902795792, 0.016720648854970932, 0.01936419866979122, 0.022007746621966362, 0.024651294574141502, 0.027294844388961792, 0.029938392341136932, 0.03258194029331207, 0.03522548824548721, 0.03786903992295265, 0.04051258787512779, 0.04315613582730293, 0.04579968377947807, 0.048443231731653214, 0.05108678340911865, 0.05373033136129379, 0.05637387931346893, 0.059017427265644073, 0.061660975217819214, 0.06430452316999435, 0.0669480711221695, 0.06959161907434464, 0.07223517447710037, 0.07487872242927551, 0.07752227038145065, 0.0801658183336258, 0.08280936628580093, 0.08545291423797607]}, '_timestamp': 1717514605.763844}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.weight': {'_type': 'histogram', 'values': [36, 7, 10, 6, 7, 5, 0, 3, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 2, 2, 1, 0, 1, 0, 1, 2, 0, 0, 0, 2, 1, 1, 2, 1, 1, 1, 2, 5, 5, 4], 'bins': [0.9982839822769165, 0.9983373284339905, 0.9983906745910645, 0.9984440803527832, 0.9984974265098572, 0.9985507726669312, 0.9986041188240051, 0.9986574649810791, 0.9987108707427979, 0.9987642168998718, 0.9988175630569458, 0.9988709092140198, 0.9989242553710938, 0.9989776015281677, 0.9990310072898865, 0.9990843534469604, 0.9991376996040344, 0.9991910457611084, 0.9992443919181824, 0.9992977976799011, 0.9993511438369751, 0.9994044899940491, 0.999457836151123, 0.999511182308197, 0.999564528465271, 0.9996179342269897, 0.9996712803840637, 0.9997246265411377, 0.9997779726982117, 0.9998313188552856, 0.9998847246170044, 0.9999380707740784, 0.9999914169311523, 1.000044822692871, 1.0000981092453003, 1.000151515007019, 1.0002048015594482, 1.000258207321167, 1.0003116130828857, 1.000364899635315, 1.0004183053970337, 1.000471591949463, 1.0005249977111816, 1.0005784034729004, 1.0006316900253296, 1.0006850957870483, 1.0007383823394775, 1.0007917881011963, 1.000845193862915, 1.0008984804153442, 1.000951886177063, 1.0010051727294922, 1.001058578491211, 1.0011118650436401, 1.0011652708053589, 1.0012186765670776, 1.0012719631195068, 1.0013253688812256, 1.0013786554336548, 1.0014320611953735, 1.0014854669570923, 1.0015387535095215, 1.0015921592712402, 1.0016454458236694, 1.0016988515853882]}, '_timestamp': 1717514605.763998}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.bias': {'_type': 'histogram', 'values': [9, 5, 8, 2, 5, 9, 1, 1, 0, 0, 2, 1, 3, 2, 1, 2, 0, 0, 1, 2, 1, 0, 0, 1, 0, 3, 1, 2, 0, 0, 0, 4, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 1, 1, 3, 0, 3, 0, 0, 1, 3, 0, 0, 2, 0, 1, 7, 0, 6, 8, 2, 19], 'bins': [-0.0017148582264780998, -0.0016612641047686338, -0.001607669866643846, -0.0015540756285190582, -0.0015004815068095922, -0.0014468873851001263, -0.0013932931469753385, -0.0013396989088505507, -0.0012861047871410847, -0.0012325106654316187, -0.0011789164273068309, -0.001125322189182043, -0.001071728067472577, -0.0010181339457631111, -0.0009645397076383233, -0.0009109455277211964, -0.0008573513478040695, -0.0008037571678869426, -0.0007501629879698157, -0.0006965688080526888, -0.0006429746281355619, -0.000589380448218435, -0.0005357862683013082, -0.00048219208838418126, -0.00042859790846705437, -0.0003750037285499275, -0.0003214095486328006, -0.0002678153687156737, -0.0002142211887985468, -0.0001606270088814199, -0.000107032828964293, -5.343864904716611e-05, 1.555308699607849e-07, 5.374971078708768e-05, 0.00010734389070421457, 0.00016093807062134147, 0.00021453225053846836, 0.00026812643045559525, 0.00032172061037272215, 0.00037531479028984904, 0.00042890897020697594, 0.00048250315012410283, 0.0005360973300412297, 0.0005896915099583566, 0.0006432856898754835, 0.0006968798697926104, 0.0007504740497097373, 0.0008040682296268642, 0.0008576624095439911, 0.000911256589461118, 0.0009648507693782449, 0.0010184450075030327, 0.0010720391292124987, 0.0011256332509219646, 0.0011792274890467525, 0.0012328217271715403, 0.0012864158488810062, 0.0013400099705904722, 0.00139360420871526, 0.0014471984468400478, 0.0015007925685495138, 0.0015543866902589798, 0.0016079809283837676, 0.0016615751665085554, 0.0017151692882180214]}, '_timestamp': 1717514605.7641459}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.weight': {'_type': 'histogram', 'values': [198, 274, 294, 306, 295, 295, 321, 287, 314, 303, 285, 328, 269, 290, 281, 285, 287, 290, 277, 286, 273, 294, 306, 290, 282, 294, 276, 289, 296, 277, 296, 308, 275, 293, 274, 289, 256, 277, 294, 288, 295, 291, 298, 294, 284, 256, 261, 274, 284, 276, 290, 294, 286, 286, 279, 280, 302, 284, 297, 271, 256, 266, 295, 234], 'bins': [-0.21232494711875916, -0.20568858087062836, -0.19905219972133636, -0.19241583347320557, -0.18577945232391357, -0.17914308607578278, -0.17250671982765198, -0.16587033867835999, -0.1592339724302292, -0.1525975912809372, -0.1459612250328064, -0.1393248587846756, -0.1326884776353836, -0.1260521113872528, -0.11941573768854141, -0.11277936398983002, -0.10614299029111862, -0.09950661659240723, -0.09287024289369583, -0.08623387664556503, -0.07959750294685364, -0.07296112924814224, -0.06632475554943085, -0.05968838557600975, -0.053052011877298355, -0.04641563817858696, -0.03977926820516586, -0.03314289450645447, -0.026506522670388222, -0.019870150834321976, -0.013233778066933155, -0.006597405765205622, 3.896653652191162e-05, 0.006675338838249445, 0.013311711139976978, 0.0199480839073658, 0.026584455743432045, 0.03322082757949829, 0.039857201278209686, 0.04649357125163078, 0.05312994495034218, 0.059766318649053574, 0.06640268862247467, 0.07303906232118607, 0.07967543601989746, 0.08631180971860886, 0.09294817596673965, 0.09958454966545105, 0.10622092336416245, 0.11285729706287384, 0.11949367076158524, 0.12613004446029663, 0.13276641070842743, 0.13940279185771942, 0.14603915810585022, 0.15267552435398102, 0.159311905503273, 0.1659482717514038, 0.1725846529006958, 0.1792210191488266, 0.1858573853969574, 0.1924937665462494, 0.1991301327943802, 0.20576651394367218, 0.21240288019180298]}, '_timestamp': 1717514605.764406}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.bias': {'_type': 'histogram', 'values': [2, 1, 5, 0, 4, 4, 2, 6, 0, 2, 2, 1, 0, 2, 2, 5, 2, 1, 1, 1, 1, 2, 5, 2, 0, 2, 2, 1, 2, 0, 1, 1, 0, 1, 2, 1, 3, 0, 3, 3, 1, 5, 2, 1, 1, 3, 2, 4, 7, 2, 3, 1, 1, 1, 2, 1, 5, 0, 4, 3, 0, 6, 4, 1], 'bins': [-0.08602596819400787, -0.0833573192358017, -0.08068867772817612, -0.07802002876996994, -0.07535138726234436, -0.07268273830413818, -0.0700140967965126, -0.06734544783830643, -0.06467680633068085, -0.06200815737247467, -0.05933951213955879, -0.056670866906642914, -0.05400221794843674, -0.05133357271552086, -0.04866492748260498, -0.0459962822496891, -0.043327637016773224, -0.040658991783857346, -0.03799034655094147, -0.03532170131802559, -0.03265305608510971, -0.029984408989548683, -0.027315761893987656, -0.024647116661071777, -0.0219784714281559, -0.01930982619524002, -0.016641180962324142, -0.013972533866763115, -0.011303888633847237, -0.008635243400931358, -0.005966597236692905, -0.00329795153811574, -0.0006293058395385742, 0.0020393398590385914, 0.004707985557615757, 0.007376631256192923, 0.010045276954770088, 0.012713922187685966, 0.01538256835192442, 0.018051214516162872, 0.02071985974907875, 0.02338850498199463, 0.026057150214910507, 0.028725797310471535, 0.03139444440603256, 0.03406308963894844, 0.03673173487186432, 0.0394003801047802, 0.042069025337696075, 0.044737670570611954, 0.04740631580352783, 0.05007496103644371, 0.05274360626935959, 0.055412255227565765, 0.058080900460481644, 0.06074954569339752, 0.0634181946516037, 0.06608683615922928, 0.06875548511743546, 0.07142412662506104, 0.07409277558326721, 0.07676141709089279, 0.07943006604909897, 0.08209870755672455, 0.08476735651493073]}, '_timestamp': 1717514605.764556}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.weight': {'_type': 'histogram', 'values': [35, 10, 11, 4, 6, 3, 3, 2, 1, 4, 1, 0, 0, 3, 3, 1, 1, 0, 2, 1, 1, 1, 2, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 2, 4, 0, 3, 0, 0, 1, 0, 0, 0, 1, 1, 1, 2, 2, 3, 1, 2, 0, 0, 1, 0, 3, 3, 0, 2], 'bins': [0.9982840418815613, 0.9983376860618591, 0.9983912706375122, 0.9984449148178101, 0.9984984993934631, 0.998552143573761, 0.9986057877540588, 0.9986593723297119, 0.9987130165100098, 0.9987666010856628, 0.9988202452659607, 0.9988738894462585, 0.9989274740219116, 0.9989811182022095, 0.9990347623825073, 0.9990883469581604, 0.9991419911384583, 0.9991955757141113, 0.9992492198944092, 0.999302864074707, 0.9993564486503601, 0.999410092830658, 0.999463677406311, 0.9995173215866089, 0.9995709657669067, 0.9996245503425598, 0.9996781945228577, 0.9997317790985107, 0.9997854232788086, 0.9998390674591064, 0.9998926520347595, 0.9999462962150574, 0.9999998807907104, 1.0000535249710083, 1.0001071691513062, 1.000160813331604, 1.0002143383026123, 1.0002679824829102, 1.000321626663208, 1.0003752708435059, 1.0004289150238037, 1.000482439994812, 1.0005360841751099, 1.0005897283554077, 1.0006433725357056, 1.0006970167160034, 1.0007506608963013, 1.0008041858673096, 1.0008578300476074, 1.0009114742279053, 1.0009651184082031, 1.001018762588501, 1.0010722875595093, 1.0011259317398071, 1.001179575920105, 1.0012332201004028, 1.0012868642807007, 1.001340389251709, 1.0013940334320068, 1.0014476776123047, 1.0015013217926025, 1.0015549659729004, 1.0016084909439087, 1.0016621351242065, 1.0017157793045044]}, '_timestamp': 1717514605.764707}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.bias': {'_type': 'histogram', 'values': [22, 5, 3, 2, 3, 10, 3, 1, 3, 2, 2, 0, 2, 1, 0, 0, 1, 1, 3, 2, 0, 3, 0, 0, 1, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 2, 3, 1, 0, 1, 0, 3, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 4, 1, 4, 4, 5, 11], 'bins': [-0.0017156426329165697, -0.0016620231326669455, -0.0016084035160019994, -0.0015547840157523751, -0.0015011645155027509, -0.0014475448988378048, -0.0013939253985881805, -0.0013403058983385563, -0.0012866862816736102, -0.001233066781423986, -0.0011794472811743617, -0.0011258276645094156, -0.0010722081642597914, -0.0010185886640101671, -0.000964969047345221, -0.0009113495470955968, -0.0008577299886383116, -0.0008041104301810265, -0.0007504909299314022, -0.000696871371474117, -0.0006432518130168319, -0.0005896323127672076, -0.0005360127543099225, -0.0004823931958526373, -0.0004287736664991826, -0.00037515413714572787, -0.0003215345786884427, -0.000267915049334988, -0.00021429550542961806, -0.00016067596152424812, -0.0001070564248948358, -5.343688462744467e-05, 1.8265563994646072e-07, 5.380219590733759e-05, 0.00010742173617472872, 0.00016104127280414104, 0.00021466081670951098, 0.0002682803606148809, 0.00032189988996833563, 0.0003755194484256208, 0.0004291389777790755, 0.0004827585071325302, 0.0005363780655898154, 0.0005899976240471005, 0.0006436171242967248, 0.00069723668275401, 0.0007508562412112951, 0.0008044757414609194, 0.0008580952999182045, 0.0009117148583754897, 0.000965334358625114, 0.00101895397529006, 0.0010725734755396843, 0.0011261929757893085, 0.0011798125924542546, 0.0012334320927038789, 0.0012870515929535031, 0.0013406712096184492, 0.0013942907098680735, 0.0014479102101176977, 0.0015015298267826438, 0.001555149327032268, 0.0016087688272818923, 0.0016623884439468384, 0.0017160079441964626]}, '_timestamp': 1717514605.764852}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.weight': {'_type': 'histogram', 'values': [4, 1, 0, 3, 2, 1, 2, 3, 1, 0, 2, 2, 2, 2, 3, 5, 1, 2, 0, 3, 2, 5, 0, 5, 4, 3, 1, 1, 1, 3, 1, 0, 4, 1, 2, 0, 2, 2, 2, 2, 0, 2, 3, 2, 5, 2, 5, 4, 2, 3, 0, 2, 2, 2, 3, 3, 3, 2, 0, 1, 2, 2, 3, 2], 'bins': [-0.2910359501838684, -0.2819242477416992, -0.2728125751018524, -0.2637008726596832, -0.25458917021751404, -0.24547748267650604, -0.23636578023433685, -0.22725409269332886, -0.21814239025115967, -0.20903070271015167, -0.19991901516914368, -0.1908073127269745, -0.1816956251859665, -0.1725839227437973, -0.1634722352027893, -0.15436053276062012, -0.14524884521961212, -0.13613715767860413, -0.12702545523643494, -0.11791376024484634, -0.10880206525325775, -0.09969037771224976, -0.09057868272066116, -0.08146698772907257, -0.07235529273748398, -0.06324359774589539, -0.05413190275430679, -0.0450202114880085, -0.03590851649641991, -0.026796821504831314, -0.01768512837588787, -0.008573434315621853, 0.000538259744644165, 0.009649953804910183, 0.0187616478651762, 0.027873340994119644, 0.03698503598570824, 0.04609673097729683, 0.05520842224359512, 0.06432011723518372, 0.07343181222677231, 0.0825435072183609, 0.0916552022099495, 0.10076689720153809, 0.10987858474254608, 0.11899027973413467, 0.12810197472572327, 0.13721367716789246, 0.14632536470890045, 0.15543705224990845, 0.16454875469207764, 0.17366044223308563, 0.18277214467525482, 0.19188383221626282, 0.200995534658432, 0.21010722219944, 0.219218909740448, 0.2283306121826172, 0.23744229972362518, 0.24655400216579437, 0.25566568970680237, 0.26477739214897156, 0.27388909459114075, 0.28300076723098755, 0.29211246967315674]}, '_timestamp': 1717514605.765004}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.bias': {'_type': 'histogram', 'values': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'bins': [-0.5751432180404663, -0.5595182180404663, -0.5438932180404663, -0.5282682180404663, -0.5126432180404663, -0.4970182478427887, -0.4813932478427887, -0.4657682478427887, -0.4501432478427887, -0.4345182478427887, -0.4188932478427887, -0.4032682478427887, -0.3876432478427887, -0.3720182478427887, -0.3563932478427887, -0.3407682478427887, -0.3251432478427887, -0.3095182478427887, -0.2938932478427887, -0.2782682478427887, -0.2626432478427887, -0.2470182478427887, -0.2313932478427887, -0.2157682478427887, -0.2001432478427887, -0.1845182478427887, -0.1688932478427887, -0.1532682478427887, -0.1376432478427887, -0.1220182403922081, -0.1063932403922081, -0.0907682403922081, -0.0751432403922081, -0.0595182403922081, -0.0438932403922081, -0.0282682403922081, -0.0126432403922081, 0.0029817596077919006, 0.0186067596077919, 0.0342317596077919, 0.0498567596077919, 0.0654817596077919, 0.0811067596077919, 0.0967317596077919, 0.1123567596077919, 0.1279817521572113, 0.1436067521572113, 0.1592317521572113, 0.1748567521572113, 0.1904817521572113, 0.2061067521572113, 0.2217317521572113, 0.2373567521572113, 0.2529817521572113, 0.2686067521572113, 0.2842317521572113, 0.2998567521572113, 0.3154817521572113, 0.3311067521572113, 0.3467317521572113, 0.3623567521572113, 0.3779817521572113, 0.3936067521572113, 0.4092317521572113, 0.4248567521572113]}, '_timestamp': 1717514605.765177}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TP Reward Distribution': {'_type': 'histogram', 'values': [3, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.8666666666666667, 3.904166666666667, 4.941666666666666, 5.979166666666667, 7.0166666666666675, 8.054166666666667, 9.091666666666667, 10.129166666666668, 11.166666666666668, 12.204166666666667, 13.241666666666667, 14.279166666666669, 15.316666666666668, 16.354166666666668, 17.39166666666667, 18.429166666666667, 19.46666666666667, 20.50416666666667, 21.541666666666668, 22.57916666666667, 23.616666666666667, 24.65416666666667, 25.69166666666667, 26.729166666666668, 27.76666666666667, 28.80416666666667, 29.84166666666667, 30.87916666666667, 31.91666666666667, 32.954166666666666, 33.99166666666667, 35.02916666666667, 36.06666666666667, 37.10416666666667, 38.14166666666667, 39.17916666666667, 40.21666666666667, 41.25416666666667, 42.29166666666667, 43.32916666666667, 44.36666666666667, 45.40416666666667, 46.44166666666667, 47.47916666666667, 48.51666666666667, 49.554166666666674, 50.59166666666667, 51.62916666666667, 52.66666666666667, 53.70416666666667, 54.741666666666674, 55.77916666666667, 56.81666666666667, 57.85416666666667, 58.89166666666667, 59.929166666666674, 60.966666666666676, 62.00416666666667, 63.04166666666667, 64.07916666666667, 65.11666666666667, 66.15416666666667, 67.19166666666666, 68.22916666666667, 69.26666666666667]}, '_timestamp': 1717514605.765339}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TN Reward Distribution': {'_type': 'histogram', 'values': [4, 3, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.6666666666666665, 6.832291666666666, 10.997916666666665, 15.163541666666665, 19.329166666666666, 23.494791666666664, 27.660416666666666, 31.826041666666665, 35.99166666666666, 40.15729166666666, 44.32291666666666, 48.488541666666656, 52.65416666666666, 56.81979166666666, 60.98541666666666, 65.15104166666666, 69.31666666666666, 73.48229166666667, 77.64791666666666, 81.81354166666667, 85.97916666666666, 90.14479166666666, 94.31041666666665, 98.47604166666666, 102.64166666666667, 106.80729166666666, 110.97291666666666, 115.13854166666665, 119.30416666666666, 123.46979166666665, 127.63541666666666, 131.80104166666663, 135.96666666666664, 140.13229166666665, 144.29791666666665, 148.46354166666663, 152.62916666666663, 156.79479166666664, 160.96041666666665, 165.12604166666662, 169.29166666666663, 173.45729166666663, 177.62291666666664, 181.78854166666665, 185.95416666666662, 190.11979166666663, 194.28541666666663, 198.45104166666664, 202.61666666666665, 206.78229166666662, 210.94791666666663, 215.11354166666663, 219.27916666666664, 223.44479166666662, 227.61041666666662, 231.77604166666663, 235.94166666666663, 240.10729166666664, 244.27291666666662, 248.43854166666662, 252.60416666666663, 256.76979166666666, 260.93541666666664, 265.1010416666667, 269.26666666666665]}, '_timestamp': 1717514605.7654872}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FP Reward Distribution': {'_type': 'histogram', 'values': [3, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.6666666666666665, 5.452083333333333, 8.2375, 11.022916666666667, 13.808333333333334, 16.59375, 19.37916666666667, 22.164583333333336, 24.950000000000003, 27.73541666666667, 30.520833333333336, 33.30625, 36.09166666666667, 38.87708333333333, 41.6625, 44.447916666666664, 47.233333333333334, 50.018750000000004, 52.80416666666667, 55.58958333333334, 58.375, 61.16041666666667, 63.94583333333333, 66.73125, 69.51666666666668, 72.30208333333334, 75.0875, 77.87291666666668, 80.65833333333335, 83.44375000000001, 86.22916666666667, 89.01458333333335, 91.80000000000001, 94.58541666666667, 97.37083333333335, 100.15625000000001, 102.94166666666668, 105.72708333333334, 108.51250000000002, 111.29791666666668, 114.08333333333334, 116.86875000000002, 119.65416666666668, 122.43958333333335, 125.22500000000001, 128.01041666666669, 130.79583333333332, 133.58125, 136.36666666666667, 139.15208333333334, 141.9375, 144.72291666666666, 147.50833333333333, 150.29375, 153.07916666666668, 155.86458333333334, 158.65, 161.43541666666667, 164.22083333333333, 167.00625, 169.79166666666666, 172.57708333333335, 175.3625, 178.14791666666667, 180.93333333333334]}, '_timestamp': 1717514605.765632}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FN Reward Distribution': {'_type': 'histogram', 'values': [2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [4.0, 4.271875, 4.54375, 4.815625, 5.0875, 5.359375, 5.63125, 5.903124999999999, 6.175, 6.446875, 6.71875, 6.990625, 7.262499999999999, 7.534375, 7.8062499999999995, 8.078125, 8.35, 8.621875, 8.89375, 9.165624999999999, 9.4375, 9.709375, 9.98125, 10.253125, 10.524999999999999, 10.796875, 11.06875, 11.340625, 11.612499999999999, 11.884374999999999, 12.15625, 12.428125, 12.7, 12.971874999999999, 13.243749999999999, 13.515625, 13.7875, 14.059375, 14.331249999999999, 14.603124999999999, 14.875, 15.146875, 15.41875, 15.690624999999999, 15.962499999999999, 16.234375, 16.50625, 16.778125, 17.049999999999997, 17.321875, 17.59375, 17.865625, 18.1375, 18.409374999999997, 18.68125, 18.953125, 19.224999999999998, 19.496875, 19.768749999999997, 20.040625, 20.3125, 20.584374999999998, 20.85625, 21.128124999999997, 21.4]}, '_timestamp': 1717514605.7657669}).
Population's average fitness: 116.42333 stdev: 178.22524
Best fitness: 585.20000 - size: (4, 20) - species 1 - id 3
Average adjusted fitness: 0.190
Mean genetic distance 1.072, standard deviation 0.311
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20    585.2    0.190     0
Total extinctions: 0
Generation time: 1.120 sec
 ****** Running generation 1 ******
Population's average fitness: 171.94667 stdev: 211.12902
Best fitness: 585.20000 - size: (4, 20) - species 1 - id 3
Average adjusted fitness: 0.282
Mean genetic distance 0.984, standard deviation 0.191
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    1    20    585.2    0.282     1
Total extinctions: 0
Generation time: 0.985 sec (1.053 average)
 ****** Running generation 2 ******
Population's average fitness: 2348.44000 stdev: 8844.68802
Best fitness: 40889.33333 - size: (4, 19) - species 1 - id 46
Average adjusted fitness: 0.057
Mean genetic distance 0.955, standard deviation 0.340
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    2    20  40889.3    0.057     0
Total extinctions: 0
Generation time: 7.729 sec (3.278 average)
 ****** Running generation 3 ******
Population's average fitness: 2530.09333 stdev: 8845.00577
Best fitness: 40889.33333 - size: (4, 19) - species 1 - id 46
Average adjusted fitness: 0.062
Mean genetic distance 1.036, standard deviation 0.220
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    3    20  40889.3    0.062     1
Total extinctions: 0
Generation time: 7.736 sec (4.393 average)
 ****** Running generation 4 ******
Population's average fitness: 5319.48333 stdev: 11966.33460
Best fitness: 40889.33333 - size: (4, 19) - species 1 - id 46
Average adjusted fitness: 0.130
Mean genetic distance 0.918, standard deviation 0.221
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    4    20  40889.3    0.130     2
Total extinctions: 0
Generation time: 7.727 sec (5.059 average)
 ****** Running generation 5 ******
Population's average fitness: 10276.58333 stdev: 17519.43795
Best fitness: 55570.80000 - size: (5, 17) - species 1 - id 89
Average adjusted fitness: 0.185
Mean genetic distance 0.928, standard deviation 0.258
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    5    20  55570.8    0.185     0
Total extinctions: 0
Generation time: 7.680 sec (5.496 average)
 ****** Running generation 6 ******
Population's average fitness: 15684.60333 stdev: 20283.01119
Best fitness: 55570.80000 - size: (5, 17) - species 1 - id 89
Average adjusted fitness: 0.282
Mean genetic distance 0.756, standard deviation 0.313
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    6    20  55570.8    0.282     1
Total extinctions: 0
Generation time: 7.638 sec (5.802 average)
 ****** Running generation 7 ******
Population's average fitness: 13252.07667 stdev: 19936.50834
Best fitness: 55570.80000 - size: (5, 17) - species 1 - id 89
Average adjusted fitness: 0.238
Mean genetic distance 0.952, standard deviation 0.280
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    7    20  55570.8    0.238     2
Total extinctions: 0
Generation time: 7.726 sec (6.043 average)
 ****** Running generation 8 ******
Population's average fitness: 7925.29000 stdev: 16354.77614
Best fitness: 55570.80000 - size: (5, 17) - species 1 - id 89
Average adjusted fitness: 0.142
Mean genetic distance 0.846, standard deviation 0.289
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    8    20  55570.8    0.142     3
Total extinctions: 0
Generation time: 7.761 sec (6.234 average)
 ****** Running generation 9 ******
Population's average fitness: 13349.81000 stdev: 19120.36020
Best fitness: 55570.80000 - size: (5, 17) - species 1 - id 89
Average adjusted fitness: 0.240
Mean genetic distance 1.042, standard deviation 0.289
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    9    20  55570.8    0.240     4
Total extinctions: 0
Generation time: 7.714 sec (6.382 average)
Simulating on trained reward function...
 ****** Running generation 0 ******
Population's average fitness: -13.53157 stdev: 33.89464
Best fitness: 0.65513 - size: (4, 20) - species 1 - id 15
Average adjusted fitness: 0.909
Mean genetic distance 1.138, standard deviation 0.204
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20      0.7    0.909     0
Total extinctions: 0
Generation time: 7.776 sec
 ****** Running generation 1 ******
Population's average fitness: -14.04802 stdev: 38.02065
Best fitness: 0.54172 - size: (4, 19) - species 1 - id 36
Average adjusted fitness: 0.898
Mean genetic distance 1.025, standard deviation 0.240
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    1    20      0.5    0.898     1
Total extinctions: 0
Generation time: 7.775 sec (7.776 average)
 ****** Running generation 2 ******
Traceback (most recent call last):
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 105, in <module>
    start_simulation("./config/agent_config.txt", args.generations[0])
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 40, in start_simulation
    run_population(
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 405, in run_population
    parse.add_argument(
  File "/Users/alextang/.pyenv/versions/nocturne_lab/lib/python3.10/site-packages/neat/population.py", line 89, in run
    fitness_function(list(iteritems(self.population)), self.config)
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 381, in run_simulation
    neat.DefaultSpeciesSet,
KeyboardInterrupt