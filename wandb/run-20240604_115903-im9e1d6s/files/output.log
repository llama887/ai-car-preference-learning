Epoch 0/1000, Train Loss: 2.0288639664649963, Val Loss: 0.5823585987091064, Train Acc: 0.5, Val Acc: 0.8500000238418579, LR: 0.0004028820367776413
Epoch 10/1000, Train Loss: 1.6805322468280792, Val Loss: 0.5410064458847046, Train Acc: 0.5, Val Acc: 0.8500000238418579, LR: 0.0003908807966020239
Epoch 20/1000, Train Loss: 1.4181788861751556, Val Loss: 0.5443946123123169, Train Acc: 0.5625, Val Acc: 0.8999999761581421, LR: 0.00037887955642640646
Epoch 30/1000, Train Loss: 1.2452215254306793, Val Loss: 0.49108871817588806, Train Acc: 0.55, Val Acc: 0.8999999761581421, LR: 0.00036687831625078896
Epoch 40/1000, Train Loss: 1.1542960703372955, Val Loss: 0.4162394106388092, Train Acc: 0.575, Val Acc: 0.8999999761581421, LR: 0.0003548770760751715
Epoch 50/1000, Train Loss: 1.3013309240341187, Val Loss: 0.35926124453544617, Train Acc: 0.6, Val Acc: 0.8999999761581421, LR: 0.000342875835899554
Epoch 60/1000, Train Loss: 1.155084103345871, Val Loss: 0.336953341960907, Train Acc: 0.7, Val Acc: 0.8999999761581421, LR: 0.0003308745957239367
Epoch 70/1000, Train Loss: 1.1788274049758911, Val Loss: 0.32788076996803284, Train Acc: 0.6125, Val Acc: 0.8999999761581421, LR: 0.0003188733555483194
Epoch 80/1000, Train Loss: 1.0118069797754288, Val Loss: 0.2892886996269226, Train Acc: 0.6625, Val Acc: 0.8999999761581421, LR: 0.0003068721153727021
Epoch 90/1000, Train Loss: 0.8572805523872375, Val Loss: 0.29168230295181274, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 0.0002948708751970848
Epoch 100/1000, Train Loss: 0.8306873887777328, Val Loss: 0.2829664945602417, Train Acc: 0.7125, Val Acc: 0.8999999761581421, LR: 0.00028286963502146753
Epoch 110/1000, Train Loss: 0.9608753025531769, Val Loss: 0.2849605977535248, Train Acc: 0.725, Val Acc: 0.8999999761581421, LR: 0.00027086839484585025
Epoch 120/1000, Train Loss: 1.0649356245994568, Val Loss: 0.27951401472091675, Train Acc: 0.7, Val Acc: 0.8999999761581421, LR: 0.0002588671546702328
Epoch 130/1000, Train Loss: 0.8633942902088165, Val Loss: 0.30205702781677246, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 0.0002468659144946155
Epoch 140/1000, Train Loss: 0.7984574288129807, Val Loss: 0.28720057010650635, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 0.00023486467431899777
Epoch 150/1000, Train Loss: 0.762691855430603, Val Loss: 0.2932760417461395, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 0.0002228634341433801
Epoch 160/1000, Train Loss: 0.7143450081348419, Val Loss: 0.2826816141605377, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 0.0002108621939677625
Epoch 170/1000, Train Loss: 0.6490491032600403, Val Loss: 0.29463306069374084, Train Acc: 0.825, Val Acc: 0.8999999761581421, LR: 0.00019886095379214493
Epoch 180/1000, Train Loss: 0.7221222668886185, Val Loss: 0.2798759341239929, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 0.00018685971361652727
Epoch 190/1000, Train Loss: 0.757244661450386, Val Loss: 0.2896650433540344, Train Acc: 0.6625, Val Acc: 0.8999999761581421, LR: 0.00017485847344090964
Epoch 200/1000, Train Loss: 0.7719592750072479, Val Loss: 0.31114980578422546, Train Acc: 0.7375, Val Acc: 0.8999999761581421, LR: 0.00016285723326529196
Epoch 210/1000, Train Loss: 0.9141719788312912, Val Loss: 0.28676652908325195, Train Acc: 0.725, Val Acc: 0.8999999761581421, LR: 0.0001508559930896743
Epoch 220/1000, Train Loss: 0.6746968477964401, Val Loss: 0.29730597138404846, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 0.0001388547529140566
Epoch 230/1000, Train Loss: 0.8877653032541275, Val Loss: 0.28690019249916077, Train Acc: 0.7125, Val Acc: 0.8999999761581421, LR: 0.00012685351273843896
Epoch 240/1000, Train Loss: 0.8614795506000519, Val Loss: 0.3049347996711731, Train Acc: 0.7, Val Acc: 0.8999999761581421, LR: 0.00011485227256282128
Epoch 250/1000, Train Loss: 1.0258962512016296, Val Loss: 0.3033396601676941, Train Acc: 0.7375, Val Acc: 0.8999999761581421, LR: 0.00010285103238720373
Epoch 260/1000, Train Loss: 0.7171190232038498, Val Loss: 0.30498602986335754, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 9.084979221158614e-05
Epoch 270/1000, Train Loss: 0.7642417252063751, Val Loss: 0.31098002195358276, Train Acc: 0.725, Val Acc: 0.8999999761581421, LR: 7.884855203596857e-05
Epoch 280/1000, Train Loss: 0.7082984000444412, Val Loss: 0.30471134185791016, Train Acc: 0.7125, Val Acc: 0.8999999761581421, LR: 6.684731186035104e-05
Epoch 290/1000, Train Loss: 0.609064131975174, Val Loss: 0.3033580183982849, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 5.4846071684733456e-05
Epoch 300/1000, Train Loss: 0.6460782289505005, Val Loss: 0.29851409792900085, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.2844831509115826e-05
Epoch 310/1000, Train Loss: 0.7622368931770325, Val Loss: 0.29917484521865845, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 3.0843591333498175e-05
Epoch 320/1000, Train Loss: 0.6864876002073288, Val Loss: 0.3024168312549591, Train Acc: 0.8, Val Acc: 0.8999999761581421, LR: 1.8842351157880525e-05
Epoch 330/1000, Train Loss: 0.5029188990592957, Val Loss: 0.30459991097450256, Train Acc: 0.825, Val Acc: 0.8999999761581421, LR: 6.841110982262865e-06
Epoch 340/1000, Train Loss: 0.7163015753030777, Val Loss: 0.30424362421035767, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 350/1000, Train Loss: 0.7125948369503021, Val Loss: 0.3024929463863373, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 360/1000, Train Loss: 0.5929633677005768, Val Loss: 0.3012670874595642, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 370/1000, Train Loss: 0.5899800658226013, Val Loss: 0.3006986975669861, Train Acc: 0.825, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 380/1000, Train Loss: 0.7275988608598709, Val Loss: 0.3007434010505676, Train Acc: 0.8, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 390/1000, Train Loss: 0.6769166886806488, Val Loss: 0.30095162987709045, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 400/1000, Train Loss: 0.7367989420890808, Val Loss: 0.30118247866630554, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 410/1000, Train Loss: 0.7130558788776398, Val Loss: 0.300870805978775, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 420/1000, Train Loss: 0.6242209374904633, Val Loss: 0.3006792366504669, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 430/1000, Train Loss: 0.6389674693346024, Val Loss: 0.29941874742507935, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 440/1000, Train Loss: 0.6703266203403473, Val Loss: 0.2998541593551636, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 450/1000, Train Loss: 0.6528941690921783, Val Loss: 0.30049359798431396, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 460/1000, Train Loss: 0.6105608493089676, Val Loss: 0.30099478363990784, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 470/1000, Train Loss: 0.6655542105436325, Val Loss: 0.30119481682777405, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 480/1000, Train Loss: 0.6546437442302704, Val Loss: 0.3009704351425171, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 490/1000, Train Loss: 0.5424695387482643, Val Loss: 0.3004685938358307, Train Acc: 0.8375, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 500/1000, Train Loss: 0.5736839547753334, Val Loss: 0.3000006675720215, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 510/1000, Train Loss: 0.4251229241490364, Val Loss: 0.30002710223197937, Train Acc: 0.875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 520/1000, Train Loss: 0.7301792651414871, Val Loss: 0.3003503978252411, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 530/1000, Train Loss: 0.8664987236261368, Val Loss: 0.299368679523468, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 540/1000, Train Loss: 0.6870775669813156, Val Loss: 0.29938074946403503, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 550/1000, Train Loss: 0.7327024042606354, Val Loss: 0.30048102140426636, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 560/1000, Train Loss: 0.6460762321949005, Val Loss: 0.300606369972229, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 570/1000, Train Loss: 0.5954612642526627, Val Loss: 0.29953938722610474, Train Acc: 0.8375, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 580/1000, Train Loss: 0.7397263199090958, Val Loss: 0.29897457361221313, Train Acc: 0.725, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 590/1000, Train Loss: 0.6236796379089355, Val Loss: 0.2988066077232361, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 600/1000, Train Loss: 0.5117431432008743, Val Loss: 0.3001616895198822, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 610/1000, Train Loss: 0.6089334189891815, Val Loss: 0.3014190196990967, Train Acc: 0.825, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 620/1000, Train Loss: 0.6979204714298248, Val Loss: 0.30247509479522705, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 630/1000, Train Loss: 0.7129560261964798, Val Loss: 0.3029528856277466, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 640/1000, Train Loss: 0.5839859694242477, Val Loss: 0.3007540702819824, Train Acc: 0.85, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 650/1000, Train Loss: 0.7962614595890045, Val Loss: 0.2996181845664978, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 660/1000, Train Loss: 0.7834006994962692, Val Loss: 0.2980527877807617, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 670/1000, Train Loss: 0.659098669886589, Val Loss: 0.2960115075111389, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 680/1000, Train Loss: 0.6180008947849274, Val Loss: 0.2953234314918518, Train Acc: 0.8, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 690/1000, Train Loss: 0.6284022629261017, Val Loss: 0.29499679803848267, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 700/1000, Train Loss: 0.7162213176488876, Val Loss: 0.2947174608707428, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 710/1000, Train Loss: 0.7214067131280899, Val Loss: 0.2943407893180847, Train Acc: 0.725, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 720/1000, Train Loss: 0.6646468788385391, Val Loss: 0.2955555021762848, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 730/1000, Train Loss: 0.576740950345993, Val Loss: 0.2950699031352997, Train Acc: 0.8375, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 740/1000, Train Loss: 0.5816980749368668, Val Loss: 0.2952781319618225, Train Acc: 0.775, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 750/1000, Train Loss: 0.4813899099826813, Val Loss: 0.2952442169189453, Train Acc: 0.8625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 760/1000, Train Loss: 0.6927658915519714, Val Loss: 0.29444214701652527, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 770/1000, Train Loss: 0.6094995439052582, Val Loss: 0.2927558720111847, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 780/1000, Train Loss: 0.815127357840538, Val Loss: 0.29244211316108704, Train Acc: 0.7375, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 790/1000, Train Loss: 0.4983917623758316, Val Loss: 0.29355236887931824, Train Acc: 0.8375, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 800/1000, Train Loss: 0.5684078931808472, Val Loss: 0.2933391332626343, Train Acc: 0.8375, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 810/1000, Train Loss: 0.5345196574926376, Val Loss: 0.2934895157814026, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 820/1000, Train Loss: 0.59015291929245, Val Loss: 0.29259341955184937, Train Acc: 0.825, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 830/1000, Train Loss: 0.5808829367160797, Val Loss: 0.292530357837677, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 840/1000, Train Loss: 0.6746208071708679, Val Loss: 0.29292625188827515, Train Acc: 0.7375, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 850/1000, Train Loss: 0.5178586095571518, Val Loss: 0.2941163182258606, Train Acc: 0.8375, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 860/1000, Train Loss: 0.6430466324090958, Val Loss: 0.2929668128490448, Train Acc: 0.8, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 870/1000, Train Loss: 0.6112125664949417, Val Loss: 0.29151368141174316, Train Acc: 0.8, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 880/1000, Train Loss: 0.75169737637043, Val Loss: 0.29074326157569885, Train Acc: 0.75, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 890/1000, Train Loss: 0.6394473910331726, Val Loss: 0.2903648614883423, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 900/1000, Train Loss: 0.6588465571403503, Val Loss: 0.28942611813545227, Train Acc: 0.725, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 910/1000, Train Loss: 0.5724967122077942, Val Loss: 0.2889336347579956, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 920/1000, Train Loss: 0.5763832777738571, Val Loss: 0.28878894448280334, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 930/1000, Train Loss: 0.5823623090982437, Val Loss: 0.28912055492401123, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 940/1000, Train Loss: 0.7441738471388817, Val Loss: 0.2884348928928375, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 950/1000, Train Loss: 0.5928669422864914, Val Loss: 0.2874790132045746, Train Acc: 0.7875, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 960/1000, Train Loss: 0.8153244704008102, Val Loss: 0.2877189815044403, Train Acc: 0.675, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 970/1000, Train Loss: 0.6398930847644806, Val Loss: 0.287613183259964, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
[34m[1mwandb[39m[22m: [33mWARNING[39m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'Train Loss': 2.0288639664649963, 'Validation Loss': 0.5823585987091064, 'Train Accuracy': 0.5, 'Validation Accuracy': 0.8500000238418579, '_timestamp': 1717516744.7689779}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.weight': {'_type': 'histogram', 'values': [676, 1181, 1164, 1156, 1191, 1241, 1189, 1177, 1181, 1137, 1125, 1145, 1113, 1172, 1124, 1187, 1162, 1231, 1170, 1224, 1143, 1170, 1194, 1160, 1226, 1160, 1225, 1224, 1141, 1183, 1179, 1211, 1218, 1129, 1133, 1155, 1150, 1188, 1213, 1153, 1187, 1144, 1283, 1139, 1149, 1168, 1195, 1196, 1177, 1147, 1205, 1180, 1216, 1228, 1192, 1225, 1193, 1157, 1161, 1217, 1226, 1203, 1140, 871], 'bins': [-0.11156699061393738, -0.10807890444993973, -0.10459081828594208, -0.10110273212194443, -0.09761464595794678, -0.09412656724452972, -0.09063848108053207, -0.08715039491653442, -0.08366230875253677, -0.08017422258853912, -0.07668613642454147, -0.07319805026054382, -0.06970996409654617, -0.06622187793254852, -0.06273379921913147, -0.05924570932984352, -0.05575762689113617, -0.05226954072713852, -0.04878145456314087, -0.04529336839914322, -0.04180528223514557, -0.03831719979643822, -0.03482911363244057, -0.03134102746844292, -0.027852941304445267, -0.024364857003092766, -0.020876770839095116, -0.017388686537742615, -0.013900600373744965, -0.010412515141069889, -0.0069244299083948135, -0.003436344675719738, 5.1740556955337524e-05, 0.003539825789630413, 0.007027911022305489, 0.010515996254980564, 0.01400408148765564, 0.01749216765165329, 0.02098025195300579, 0.02446833811700344, 0.027956422418355942, 0.03144450858235359, 0.03493259474635124, 0.03842068091034889, 0.041908763349056244, 0.045396849513053894, 0.048884935677051544, 0.052373021841049194, 0.055861108005046844, 0.059349190443754196, 0.06283728033304214, 0.0663253590464592, 0.06981344521045685, 0.0733015313744545, 0.07678961753845215, 0.0802777037024498, 0.08376578986644745, 0.0872538760304451, 0.09074196219444275, 0.0942300483584404, 0.09771812707185745, 0.1012062132358551, 0.10469429939985275, 0.1081823855638504, 0.11167047172784805]}, '_timestamp': 1717516744.7705019}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.bias': {'_type': 'histogram', 'values': [1, 0, 0, 1, 3, 1, 0, 2, 1, 0, 0, 0, 0, 2, 2, 3, 3, 2, 2, 2, 4, 0, 0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 4, 1, 2, 0, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 1, 1, 4, 1, 0, 1, 1, 2, 2, 3, 1, 1, 1, 2, 4, 4, 0, 1], 'bins': [-0.03174801915884018, -0.03075028583407402, -0.02975255250930786, -0.028754819184541702, -0.027757085859775543, -0.026759350672364235, -0.025761617347598076, -0.024763884022831917, -0.023766150698065758, -0.0227684173732996, -0.02177068404853344, -0.02077295072376728, -0.019775215536355972, -0.018777482211589813, -0.017779748886823654, -0.016782015562057495, -0.015784282237291336, -0.014786548912525177, -0.013788815587759018, -0.012791081331670284, -0.011793348006904125, -0.010795614682137966, -0.009797880426049232, -0.008800147101283073, -0.007802413776516914, -0.006804680451750755, -0.005806946661323309, -0.004809212870895863, -0.0038114795461297035, -0.002813745988532901, -0.001816012430936098, -0.0008182788733392954, 0.00017945468425750732, 0.00117718824185431, 0.0021749217994511127, 0.0031726553570479155, 0.004170388914644718, 0.005168122239410877, 0.006165856029838324, 0.00716358982026577, 0.008161323145031929, 0.009159056469798088, 0.010156789794564247, 0.01115452405065298, 0.01215225737541914, 0.013149990700185299, 0.014147724956274033, 0.015145458281040192, 0.01614319160580635, 0.01714092493057251, 0.01813865825533867, 0.019136391580104828, 0.020134124904870987, 0.021131860092282295, 0.022129593417048454, 0.023127326741814613, 0.024125060066580772, 0.02512279339134693, 0.02612052671611309, 0.02711826004087925, 0.028115995228290558, 0.029113728553056717, 0.030111461877822876, 0.031109195202589035, 0.032106928527355194]}, '_timestamp': 1717516744.770713}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.weight': {'_type': 'histogram', 'values': [34, 7, 0, 5, 2, 3, 1, 2, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 2, 1, 1, 0, 2, 2, 0, 1, 0, 1, 0, 1], 'bins': [0.9987887144088745, 0.9988265037536621, 0.9988643527030945, 0.9989021420478821, 0.9989399313926697, 0.998977780342102, 0.9990155696868896, 0.9990533590316772, 0.9990911483764648, 0.9991289973258972, 0.9991667866706848, 0.9992045760154724, 0.9992424249649048, 0.9992802143096924, 0.99931800365448, 0.9993558526039124, 0.9993936419487, 0.9994314312934875, 0.9994692802429199, 0.9995070695877075, 0.9995448589324951, 0.9995827078819275, 0.9996204972267151, 0.9996582865715027, 0.9996961355209351, 0.9997339248657227, 0.9997717142105103, 0.9998095035552979, 0.9998473525047302, 0.9998851418495178, 0.9999229311943054, 0.9999607801437378, 0.9999985694885254, 1.000036358833313, 1.0000741481781006, 1.0001119375228882, 1.0001498460769653, 1.000187635421753, 1.0002254247665405, 1.0002632141113281, 1.0003010034561157, 1.0003387928009033, 1.0003767013549805, 1.000414490699768, 1.0004522800445557, 1.0004900693893433, 1.0005278587341309, 1.0005656480789185, 1.000603437423706, 1.0006413459777832, 1.0006791353225708, 1.0007169246673584, 1.000754714012146, 1.0007925033569336, 1.0008302927017212, 1.0008682012557983, 1.000905990600586, 1.0009437799453735, 1.0009815692901611, 1.0010193586349487, 1.0010571479797363, 1.0010950565338135, 1.001132845878601, 1.0011706352233887, 1.0012084245681763]}, '_timestamp': 1717516744.7709062}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.bias': {'_type': 'histogram', 'values': [2, 1, 0, 3, 1, 0, 2, 2, 4, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 1, 26, 0, 2, 2, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 2, 1, 1, 1, 2, 3, 1, 1, 3], 'bins': [-0.0012036464177072048, -0.0011671140091493726, -0.0011305816005915403, -0.001094049192033708, -0.0010575167834758759, -0.0010209842585027218, -0.0009844518499448895, -0.0009479194413870573, -0.0009113870328292251, -0.0008748546242713928, -0.0008383222157135606, -0.0008017897489480674, -0.0007652573403902352, -0.0007287249318324029, -0.0006921924650669098, -0.0006556600565090775, -0.0006191276479512453, -0.0005825952393934131, -0.0005460628308355808, -0.0005095303640700877, -0.00047299795551225543, -0.0004364655469544232, -0.0003999331092927605, -0.0003634006716310978, -0.00032686826307326555, -0.0002903358545154333, -0.0002538034168537706, -0.00021727099374402314, -0.00018073857063427567, -0.0001442061475245282, -0.00010767372441478074, -7.114130130503327e-05, -3.46088781952858e-05, 1.9235449144616723e-06, 3.845596802420914e-05, 7.498839113395661e-05, 0.00011152081424370408, 0.00014805323735345155, 0.00018458566046319902, 0.0002211180835729465, 0.00025765050668269396, 0.0002941829152405262, 0.0003307153529021889, 0.0003672477905638516, 0.00040378019912168384, 0.0004403126076795161, 0.0004768450453411788, 0.0005133774830028415, 0.0005499098915606737, 0.000586442300118506, 0.0006229747086763382, 0.0006595071754418314, 0.0006960395839996636, 0.0007325719925574958, 0.000769104459322989, 0.0008056368678808212, 0.0008421692764386535, 0.0008787016849964857, 0.000915234093554318, 0.0009517665603198111, 0.0009882990270853043, 0.0010248314356431365, 0.0010613638442009687, 0.001097896252758801, 0.0011344286613166332]}, '_timestamp': 1717516744.771065}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.weight': {'_type': 'histogram', 'values': [100, 113, 101, 103, 98, 103, 120, 103, 118, 91, 99, 94, 125, 117, 133, 92, 93, 121, 107, 109, 96, 117, 102, 121, 112, 98, 110, 103, 110, 104, 120, 118, 97, 99, 95, 127, 81, 129, 107, 109, 96, 118, 126, 128, 119, 106, 120, 123, 95, 133, 103, 98, 105, 111, 97, 119, 123, 88, 87, 107, 91, 96, 101, 104], 'bins': [-0.269330233335495, -0.2609083950519562, -0.25248652696609497, -0.24406468868255615, -0.23564283549785614, -0.22722098231315613, -0.21879912912845612, -0.2103772759437561, -0.20195543766021729, -0.19353358447551727, -0.18511173129081726, -0.17668987810611725, -0.16826802492141724, -0.15984617173671722, -0.1514243334531784, -0.1430024802684784, -0.13458062708377838, -0.12615877389907837, -0.11773692816495895, -0.10931507498025894, -0.10089322924613953, -0.09247137606143951, -0.0840495228767395, -0.07562767714262009, -0.06720582395792007, -0.05878397449851036, -0.05036212503910065, -0.041940271854400635, -0.03351842239499092, -0.025096572935581207, -0.016674721613526344, -0.008252871222794056, 0.00016897916793823242, 0.00859082955867052, 0.01701267994940281, 0.025434531271457672, 0.033856380730867386, 0.0422782301902771, 0.05070008337497711, 0.059121932834386826, 0.06754378229379654, 0.07596563547849655, 0.08438748121261597, 0.09280933439731598, 0.10123118758201599, 0.1096530333161354, 0.11807488650083542, 0.12649673223495483, 0.13491858541965485, 0.14334043860435486, 0.15176229178905487, 0.1601841300725937, 0.1686059832572937, 0.1770278364419937, 0.18544968962669373, 0.19387154281139374, 0.20229339599609375, 0.21071523427963257, 0.21913708746433258, 0.2275589406490326, 0.2359807938337326, 0.24440264701843262, 0.25282448530197144, 0.26124635338783264, 0.26966819167137146]}, '_timestamp': 1717516744.771273}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.bias': {'_type': 'histogram', 'values': [3, 0, 2, 0, 2, 1, 0, 0, 1, 1, 0, 1, 2, 3, 1, 2, 0, 3, 2, 0, 2, 1, 2, 4, 1, 1, 0, 0, 1, 2, 0, 2, 0, 1, 3, 0, 1, 2, 1, 3, 1, 2, 3, 0, 3, 3, 0, 1, 1, 0, 1, 1, 0, 1, 1, 3, 2, 1, 0, 1, 2, 3, 0, 2], 'bins': [-0.10704229027032852, -0.10364455729722977, -0.10024683177471161, -0.09684909880161285, -0.0934513732790947, -0.09005364030599594, -0.08665590733289719, -0.08325818181037903, -0.07986044883728027, -0.07646272331476212, -0.07306499034166336, -0.0696672573685646, -0.06626953184604645, -0.06287179887294769, -0.059474069625139236, -0.05607634037733078, -0.052678611129522324, -0.04928088188171387, -0.04588315263390541, -0.042485419660806656, -0.0390876904129982, -0.03568996116518974, -0.03229223191738129, -0.02889450080692768, -0.025496771559119225, -0.022099042311310768, -0.018701311200857162, -0.015303581953048706, -0.011905851773917675, -0.008508121594786644, -0.0051103918813169, -0.0017126619350165129, 0.0016850680112838745, 0.0050827981904149055, 0.008480528369545937, 0.011878257617354393, 0.015275987796485424, 0.018673717975616455, 0.02207144722342491, 0.025469178333878517, 0.028866907581686974, 0.03226463869214058, 0.035662367939949036, 0.03906009718775749, 0.04245782643556595, 0.045855555683374405, 0.04925328865647316, 0.052651017904281616, 0.05604874715209007, 0.05944647639989853, 0.06284420937299728, 0.06624193489551544, 0.0696396678686142, 0.07303739339113235, 0.07643512636423111, 0.07983285933732986, 0.08323058485984802, 0.08662831783294678, 0.09002604335546494, 0.09342377632856369, 0.09682150930166245, 0.1002192348241806, 0.10361696779727936, 0.10701469331979752, 0.11041242629289627]}, '_timestamp': 1717516744.771442}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.weight': {'_type': 'histogram', 'values': [11, 5, 4, 5, 3, 3, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 2, 0, 1, 1, 2, 3, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 4, 1, 0, 1, 1, 0, 0, 1, 0, 0, 3, 1, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 1, 2, 2, 1], 'bins': [0.9987888932228088, 0.9988260269165039, 0.9988631010055542, 0.9989002346992493, 0.9989373683929443, 0.9989744424819946, 0.9990115761756897, 0.99904865026474, 0.9990857839584351, 0.9991229176521301, 0.9991599917411804, 0.9991971254348755, 0.9992342591285706, 0.9992713332176208, 0.9993084669113159, 0.999345600605011, 0.9993826746940613, 0.9994198083877563, 0.9994569420814514, 0.9994940161705017, 0.9995311498641968, 0.9995682239532471, 0.9996053576469421, 0.9996424913406372, 0.9996795654296875, 0.9997166991233826, 0.9997538328170776, 0.9997909069061279, 0.999828040599823, 0.9998651742935181, 0.9999022483825684, 0.9999393820762634, 0.9999765157699585, 1.0000135898590088, 1.000050663948059, 1.000087857246399, 1.0001249313354492, 1.0001620054244995, 1.0001991987228394, 1.0002362728118896, 1.00027334690094, 1.0003105401992798, 1.00034761428833, 1.0003846883773804, 1.0004218816757202, 1.0004589557647705, 1.0004960298538208, 1.0005332231521606, 1.000570297241211, 1.0006073713302612, 1.000644564628601, 1.0006816387176514, 1.0007187128067017, 1.000755786895752, 1.0007929801940918, 1.000830054283142, 1.0008671283721924, 1.0009043216705322, 1.0009413957595825, 1.0009784698486328, 1.0010156631469727, 1.001052737236023, 1.0010898113250732, 1.001127004623413, 1.0011640787124634]}, '_timestamp': 1717516744.7715971}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.bias': {'_type': 'histogram', 'values': [2, 4, 5, 2, 1, 2, 1, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 5, 1, 2, 2, 4, 0, 0, 0, 4, 2, 1, 0, 3, 1, 0, 0, 1, 4, 0, 3, 1, 0, 2, 1, 1, 2, 2, 2, 3, 1, 1, 2, 0, 1, 2], 'bins': [-0.0011933501809835434, -0.0011562538566067815, -0.0011191576486453414, -0.0010820613242685795, -0.0010449649998918176, -0.0010078686755150557, -0.0009707724675536156, -0.0009336761431768537, -0.0008965798770077527, -0.0008594835526309907, -0.0008223872864618897, -0.0007852910202927887, -0.0007481946959160268, -0.0007110984297469258, -0.0006740021053701639, -0.0006369058392010629, -0.0005998095730319619, -0.0005627132486552, -0.000525616982486099, -0.0004885206581093371, -0.0004514243919402361, -0.00041432809666730464, -0.0003772318013943732, -0.0003401355061214417, -0.00030303921084851027, -0.00026594294467940927, -0.0002288466494064778, -0.00019175035413354635, -0.0001546540588606149, -0.00011755777813959867, -8.046148286666721e-05, -4.336519486969337e-05, -6.268906872719526e-06, 3.0827381124254316e-05, 6.792366912122816e-05, 0.00010501996439415962, 0.00014211624511517584, 0.0001792125403881073, 0.00021630883566103876, 0.0002534051309339702, 0.0002905013971030712, 0.00032759769237600267, 0.0003646939876489341, 0.0004017902829218656, 0.00043888657819479704, 0.0004759828734677285, 0.00051307916874066, 0.000550175434909761, 0.0005872717592865229, 0.0006243680254556239, 0.0006614642916247249, 0.0006985606160014868, 0.0007356568821705878, 0.0007727532065473497, 0.0008098494727164507, 0.0008469457388855517, 0.0008840420632623136, 0.0009211383294314146, 0.0009582346538081765, 0.0009953308617696166, 0.0010324271861463785, 0.0010695235105231404, 0.0011066198348999023, 0.0011437160428613424, 0.0011808123672381043]}, '_timestamp': 1717516744.771743}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.weight': {'_type': 'histogram', 'values': [89, 102, 103, 118, 117, 108, 101, 122, 105, 102, 96, 118, 108, 108, 113, 133, 110, 103, 115, 116, 98, 103, 109, 112, 107, 115, 110, 97, 100, 111, 113, 109, 99, 96, 104, 114, 123, 113, 93, 103, 141, 136, 97, 119, 100, 104, 110, 109, 97, 103, 95, 106, 120, 116, 103, 97, 113, 92, 90, 107, 121, 109, 96, 92], 'bins': [-0.26904210448265076, -0.26062193512916565, -0.25220176577568054, -0.24378159642219543, -0.23536141216754913, -0.22694124281406403, -0.21852107346057892, -0.2101009041070938, -0.2016807347536087, -0.1932605654001236, -0.1848403811454773, -0.1764202117919922, -0.16800004243850708, -0.15957987308502197, -0.15115970373153687, -0.14273953437805176, -0.13431936502456665, -0.12589918076992035, -0.11747901141643524, -0.10905884206295013, -0.10063867270946503, -0.09221849590539932, -0.08379832655191422, -0.07537815719842911, -0.0669579803943634, -0.058537811040878296, -0.05011764168739319, -0.04169746860861778, -0.03327729552984238, -0.02485712617635727, -0.016436953097581863, -0.008016781881451607, 0.0004033893346786499, 0.008823560550808907, 0.017243731766939163, 0.02566390484571457, 0.034084074199199677, 0.04250424727797508, 0.05092442035675049, 0.059344589710235596, 0.0677647590637207, 0.07618493586778641, 0.08460510522127151, 0.09302527457475662, 0.10144545137882233, 0.10986562073230743, 0.11828579008579254, 0.12670595943927765, 0.13512614369392395, 0.14354631304740906, 0.15196648240089417, 0.16038665175437927, 0.16880682110786438, 0.1772269904613495, 0.1856471598148346, 0.1940673440694809, 0.202487513422966, 0.2109076827764511, 0.21932785212993622, 0.22774802148342133, 0.23616819083690643, 0.24458837509155273, 0.25300854444503784, 0.26142871379852295, 0.26984888315200806]}, '_timestamp': 1717516744.771936}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.bias': {'_type': 'histogram', 'values': [2, 0, 4, 0, 1, 1, 1, 2, 3, 2, 2, 2, 0, 1, 2, 2, 1, 3, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 0, 3, 1, 3, 2, 3, 0, 3, 3, 1, 0, 1, 1, 1, 2, 1, 1, 0, 3, 1, 1, 1, 2, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 1, 3, 1], 'bins': [-0.1075262725353241, -0.10415181517601013, -0.10077735781669617, -0.0974029004573822, -0.09402844309806824, -0.09065398573875427, -0.08727952837944031, -0.08390507102012634, -0.08053061366081238, -0.07715615630149841, -0.07378169894218445, -0.07040724158287048, -0.06703278422355652, -0.06365832686424255, -0.06028386577963829, -0.056909408420324326, -0.05353495106101036, -0.050160493701696396, -0.04678603634238243, -0.043411578983068466, -0.0400371216237545, -0.036662664264440536, -0.03328820690512657, -0.029913747683167458, -0.026539290323853493, -0.023164832964539528, -0.019790375605225563, -0.016415918245911598, -0.013041459955275059, -0.009667002595961094, -0.006292544770985842, -0.0029180871788412333, 0.00045637041330337524, 0.0038308280054479837, 0.007205285597592592, 0.010579743422567844, 0.01395420078188181, 0.01732865907251835, 0.020703116431832314, 0.02407757379114628, 0.027452031150460243, 0.030826488509774208, 0.03420094773173332, 0.03757540509104729, 0.04094986245036125, 0.04432431980967522, 0.04769877716898918, 0.051073234528303146, 0.05444769188761711, 0.057822149246931076, 0.06119660660624504, 0.0645710676908493, 0.06794552505016327, 0.07131998240947723, 0.0746944397687912, 0.07806889712810516, 0.08144335448741913, 0.0848178118467331, 0.08819226920604706, 0.09156672656536102, 0.09494118392467499, 0.09831564128398895, 0.10169009864330292, 0.10506455600261688, 0.10843901336193085]}, '_timestamp': 1717516744.772099}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.weight': {'_type': 'histogram', 'values': [12, 10, 7, 7, 5, 1, 4, 1, 0, 4, 3, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1], 'bins': [0.9987882375717163, 0.9988258481025696, 0.9988635182380676, 0.9989011287689209, 0.998938798904419, 0.9989764094352722, 0.9990140795707703, 0.9990516901016235, 0.9990893602371216, 0.9991269707679749, 0.9991645812988281, 0.9992022514343262, 0.9992398619651794, 0.9992775321006775, 0.9993151426315308, 0.9993528127670288, 0.9993904232978821, 0.9994280338287354, 0.9994657039642334, 0.9995033144950867, 0.9995409846305847, 0.999578595161438, 0.999616265296936, 0.9996538758277893, 0.9996914863586426, 0.9997291564941406, 0.9997667670249939, 0.9998044371604919, 0.9998420476913452, 0.9998797178268433, 0.9999173283576965, 0.9999549984931946, 0.9999926090240479, 1.000030279159546, 1.0000678300857544, 1.0001055002212524, 1.0001431703567505, 1.0001808404922485, 1.000218391418457, 1.000256061553955, 1.0002937316894531, 1.0003312826156616, 1.0003689527511597, 1.0004066228866577, 1.0004442930221558, 1.0004818439483643, 1.0005195140838623, 1.0005571842193604, 1.0005948543548584, 1.000632405281067, 1.000670075416565, 1.000707745552063, 1.0007452964782715, 1.0007829666137695, 1.0008206367492676, 1.0008583068847656, 1.0008958578109741, 1.0009335279464722, 1.0009711980819702, 1.0010087490081787, 1.0010464191436768, 1.0010840892791748, 1.0011217594146729, 1.0011593103408813, 1.0011969804763794]}, '_timestamp': 1717516744.772247}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.bias': {'_type': 'histogram', 'values': [7, 9, 3, 2, 3, 4, 0, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 3, 1, 2, 3, 3, 0, 0, 1, 2, 1, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 3, 1, 1, 2, 2, 1, 3], 'bins': [-0.0012107735965400934, -0.0011732532875612378, -0.0011357328621670604, -0.0010982125531882048, -0.0010606921277940273, -0.0010231718188151717, -0.0009856513934209943, -0.0009481310262344778, -0.0009106106590479612, -0.0008730902918614447, -0.0008355699246749282, -0.0007980495574884117, -0.0007605291903018951, -0.0007230088231153786, -0.0006854884559288621, -0.0006479680887423456, -0.000610447721555829, -0.0005729274125769734, -0.0005354070453904569, -0.0004978866782039404, -0.0004603662819135934, -0.0004228459147270769, -0.00038532554754056036, -0.00034780518035404384, -0.0003102848422713578, -0.00027276447508484125, -0.0002352440933464095, -0.00019772372615989298, -0.00016020337352529168, -0.00012268300633877516, -8.516263915225863e-05, -4.764227196574211e-05, -1.0121904779225588e-05, 2.7398460588301532e-05, 6.491882959380746e-05, 0.00010243918950436637, 0.0001399595639668405, 0.0001774799166014418, 0.00021500028378795832, 0.0002525206655263901, 0.0002900410327129066, 0.00032756137079559267, 0.0003650817379821092, 0.0004026021051686257, 0.00044012247235514224, 0.00047764283954165876, 0.0005151632358320057, 0.0005526836030185223, 0.0005902039119973779, 0.0006277242791838944, 0.0006652446463704109, 0.0007027650135569274, 0.000740285380743444, 0.0007778057479299605, 0.000815326115116477, 0.0008528464823029935, 0.0008903668494895101, 0.0009278872166760266, 0.0009654075838625431, 0.0010029280092567205, 0.0010404483182355762, 0.0010779687436297536, 0.0011154890526086092, 0.0011530094780027866, 0.0011905297869816422]}, '_timestamp': 1717516744.7723908}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.weight': {'_type': 'histogram', 'values': [3, 1, 0, 1, 2, 1, 1, 3, 1, 2, 0, 1, 0, 2, 1, 0, 3, 0, 1, 1, 1, 0, 3, 1, 2, 0, 2, 2, 2, 1, 1, 2, 1, 1, 1, 0, 3, 1, 1, 0, 0, 2, 0, 1, 0, 3, 1, 2, 1, 0, 0, 2, 0, 1, 1, 1, 4, 2, 2, 0, 2, 3, 2, 4], 'bins': [-0.3706150949001312, -0.3590126633644104, -0.34741026163101196, -0.33580783009529114, -0.3242053985595703, -0.3126029968261719, -0.30100056529045105, -0.2893981337547302, -0.2777957320213318, -0.26619330048561096, -0.25459086894989014, -0.2429884523153305, -0.23138603568077087, -0.21978361904621124, -0.20818118751049042, -0.1965787708759308, -0.18497633934020996, -0.17337392270565033, -0.1617715060710907, -0.15016907453536987, -0.13856665790081024, -0.1269642412662506, -0.11536181718111038, -0.10375939309597015, -0.09215697646141052, -0.0805545523762703, -0.06895212829113007, -0.057349707931280136, -0.045747287571430206, -0.03414486348628998, -0.022542443126440048, -0.01094002090394497, 0.0006624013185501099, 0.012264823541045189, 0.023867245763540268, 0.0354696661233902, 0.047072090208530426, 0.058674510568380356, 0.07027693092823029, 0.08187935501337051, 0.09348177909851074, 0.10508419573307037, 0.1166866198182106, 0.12828904390335083, 0.13989146053791046, 0.1514938771724701, 0.16309630870819092, 0.17469872534275055, 0.18630114197731018, 0.197903573513031, 0.20950599014759064, 0.22110842168331146, 0.2327108383178711, 0.24431325495243073, 0.25591567158699036, 0.2675181031227112, 0.279120534658432, 0.29072293639183044, 0.30232536792755127, 0.3139277994632721, 0.32553020119667053, 0.33713263273239136, 0.3487350642681122, 0.3603374660015106, 0.37193989753723145]}, '_timestamp': 1717516744.772543}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.bias': {'_type': 'histogram', 'values': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'bins': [-0.49739471077919006, -0.48176971077919006, -0.46614471077919006, -0.45051971077919006, -0.43489471077919006, -0.41926971077919006, -0.40364471077919006, -0.38801971077919006, -0.37239471077919006, -0.35676971077919006, -0.34114471077919006, -0.32551971077919006, -0.30989471077919006, -0.29426971077919006, -0.27864471077919006, -0.26301971077919006, -0.24739469587802887, -0.23176969587802887, -0.21614469587802887, -0.20051969587802887, -0.18489469587802887, -0.16926969587802887, -0.15364469587802887, -0.13801969587802887, -0.12239469587802887, -0.10676969587802887, -0.09114469587802887, -0.07551969587802887, -0.05989469587802887, -0.04426969587802887, -0.02864469587802887, -0.013019696809351444, 0.0026053031906485558, 0.01823030412197113, 0.03385530412197113, 0.04948030412197113, 0.06510530412197113, 0.08073030412197113, 0.09635530412197113, 0.11198030412197113, 0.12760530412197113, 0.14323030412197113, 0.15885530412197113, 0.17448030412197113, 0.19010530412197113, 0.20573030412197113, 0.22135530412197113, 0.23698030412197113, 0.25260528922080994, 0.26823028922080994, 0.28385528922080994, 0.29948028922080994, 0.31510528922080994, 0.33073028922080994, 0.34635528922080994, 0.36198028922080994, 0.37760528922080994, 0.39323028922080994, 0.40885528922080994, 0.42448028922080994, 0.44010528922080994, 0.45573028922080994, 0.47135528922080994, 0.48698028922080994, 0.5026053190231323]}, '_timestamp': 1717516744.772713}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TP Reward Distribution': {'_type': 'histogram', 'values': [17, 0, 0, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.933333333333333, 7.574999999999999, 12.216666666666667, 16.858333333333334, 21.5, 26.141666666666666, 30.783333333333335, 35.425, 40.06666666666666, 44.70833333333333, 49.349999999999994, 53.99166666666666, 58.63333333333333, 63.275, 67.91666666666667, 72.55833333333334, 77.2, 81.84166666666667, 86.48333333333333, 91.125, 95.76666666666667, 100.40833333333333, 105.05, 109.69166666666666, 114.33333333333334, 118.97500000000001, 123.61666666666667, 128.25833333333333, 132.9, 137.54166666666666, 142.18333333333334, 146.825, 151.46666666666667, 156.10833333333335, 160.75, 165.39166666666668, 170.03333333333333, 174.675, 179.31666666666666, 183.95833333333334, 188.6, 193.24166666666667, 197.88333333333333, 202.525, 207.16666666666666, 211.80833333333334, 216.45, 221.09166666666667, 225.73333333333335, 230.375, 235.01666666666668, 239.65833333333333, 244.3, 248.94166666666666, 253.58333333333334, 258.22499999999997, 262.8666666666667, 267.5083333333333, 272.15, 276.7916666666667, 281.43333333333334, 286.075, 290.71666666666664, 295.35833333333335, 300.0]}, '_timestamp': 1717516744.7728791}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TN Reward Distribution': {'_type': 'histogram', 'values': [5, 2, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [3.2666666666666666, 4.820833333333333, 6.375, 7.929166666666666, 9.483333333333334, 11.037500000000001, 12.591666666666665, 14.145833333333332, 15.7, 17.254166666666666, 18.808333333333334, 20.3625, 21.916666666666664, 23.47083333333333, 25.025, 26.579166666666666, 28.133333333333333, 29.6875, 31.241666666666667, 32.795833333333334, 34.35, 35.90416666666667, 37.458333333333336, 39.0125, 40.56666666666666, 42.12083333333333, 43.675, 45.229166666666664, 46.78333333333333, 48.3375, 49.891666666666666, 51.44583333333333, 53.0, 54.55416666666667, 56.108333333333334, 57.6625, 59.21666666666667, 60.770833333333336, 62.325, 63.87916666666667, 65.43333333333334, 66.9875, 68.54166666666667, 70.09583333333333, 71.65, 73.20416666666667, 74.75833333333334, 76.3125, 77.86666666666666, 79.42083333333333, 80.975, 82.52916666666667, 84.08333333333333, 85.6375, 87.19166666666666, 88.74583333333334, 90.3, 91.85416666666667, 93.40833333333333, 94.9625, 96.51666666666667, 98.07083333333334, 99.625, 101.17916666666667, 102.73333333333333]}, '_timestamp': 1717516744.773022}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FP Reward Distribution': {'_type': 'histogram', 'values': [4, 1, 1, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.933333333333333, 3.747916666666667, 4.5625, 5.377083333333333, 6.191666666666666, 7.00625, 7.820833333333335, 8.635416666666668, 9.450000000000001, 10.264583333333334, 11.079166666666667, 11.89375, 12.708333333333336, 13.522916666666669, 14.337500000000002, 15.152083333333335, 15.966666666666669, 16.78125, 17.595833333333335, 18.410416666666666, 19.225, 20.039583333333336, 20.854166666666668, 21.668750000000003, 22.483333333333338, 23.29791666666667, 24.112500000000004, 24.927083333333336, 25.74166666666667, 26.556250000000002, 27.370833333333337, 28.18541666666667, 29.000000000000004, 29.81458333333334, 30.62916666666667, 31.443750000000005, 32.25833333333333, 33.07291666666667, 33.8875, 34.702083333333334, 35.516666666666666, 36.331250000000004, 37.145833333333336, 37.96041666666667, 38.775, 39.58958333333334, 40.40416666666667, 41.21875, 42.03333333333334, 42.84791666666667, 43.6625, 44.47708333333333, 45.29166666666667, 46.10625, 46.920833333333334, 47.735416666666666, 48.550000000000004, 49.364583333333336, 50.17916666666667, 50.993750000000006, 51.80833333333334, 52.62291666666667, 53.4375, 54.25208333333334, 55.06666666666667]}, '_timestamp': 1717516744.7731578}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FN Reward Distribution': {'_type': 'histogram', 'values': [10, 2, 1, 0, 0, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [2.6, 5.44375, 8.2875, 11.13125, 13.975, 16.81875, 19.6625, 22.50625, 25.35, 28.19375, 31.0375, 33.88125, 36.725, 39.56875, 42.4125, 45.25625, 48.1, 50.94375, 53.7875, 56.63125, 59.475, 62.31875, 65.1625, 68.00625, 70.85, 73.69375, 76.5375, 79.38125, 82.225, 85.06875, 87.9125, 90.75625, 93.6, 96.44375, 99.2875, 102.13125, 104.975, 107.81875, 110.6625, 113.50625, 116.35, 119.19375, 122.0375, 124.88125, 127.725, 130.56875, 133.4125, 136.25625, 139.1, 141.94375, 144.7875, 147.63125, 150.475, 153.31875, 156.1625, 159.00625, 161.85, 164.69375, 167.5375, 170.38125, 173.225, 176.06875, 178.9125, 181.75625, 184.6]}, '_timestamp': 1717516744.7732952}).
Epoch 980/1000, Train Loss: 0.6858500987291336, Val Loss: 0.2872869372367859, Train Acc: 0.7625, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Epoch 990/1000, Train Loss: 0.6130484342575073, Val Loss: 0.2883768677711487, Train Acc: 0.8125, Val Acc: 0.8999999761581421, LR: 4.040821607952081e-06
Finished training model...
Simulating on true reward function...
Running for a maximum of 11 generations...
 ****** Running generation 0 ******
Population's average fitness: 156.48000 stdev: 265.89395
Best fitness: 1114.33333 - size: (4, 20) - species 1 - id 17
Average adjusted fitness: 0.133
Mean genetic distance 1.328, standard deviation 0.235
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20   1114.3    0.133     0
Total extinctions: 0
Generation time: 1.097 sec
 ****** Running generation 1 ******
[33m[W 2024-06-04 11:59:21,088][39m Trial 0 failed with parameters: {'hidden_size': 83, 'learning_rate': 0.00040408216079520305, 'weight_decay': 0.0007807768573679268} because of the following error: The value None could not be cast to float..
[33m[W 2024-06-04 11:59:21,088][39m Trial 0 failed with value None.
Population's average fitness: 367.23667 stdev: 490.45112
Best fitness: 2135.73333 - size: (5, 21) - species 1 - id 27
Average adjusted fitness: 0.167
Mean genetic distance 1.162, standard deviation 0.269
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    1    20   2135.7    0.167     0
Total extinctions: 0
Generation time: 1.002 sec (1.049 average)
 ****** Running generation 2 ******
Population's average fitness: 2939.52000 stdev: 8890.01129
Best fitness: 40889.33333 - size: (6, 22) - species 1 - id 41
Average adjusted fitness: 0.072
Mean genetic distance 1.204, standard deviation 0.298
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    2    20  40889.3    0.072     0
Total extinctions: 0
Generation time: 7.739 sec (3.279 average)
 ****** Running generation 3 ******
Population's average fitness: 5998.10333 stdev: 12303.21599
Best fitness: 40889.33333 - size: (6, 22) - species 1 - id 41
Average adjusted fitness: 0.146
Mean genetic distance 1.237, standard deviation 0.253
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    3    20  40889.3    0.146     1
Total extinctions: 0
Generation time: 7.746 sec (4.396 average)
 ****** Running generation 4 ******
Population's average fitness: 11730.33667 stdev: 15674.32640
Best fitness: 40889.33333 - size: (6, 22) - species 1 - id 41
Average adjusted fitness: 0.287
Mean genetic distance 1.125, standard deviation 0.268
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    4    20  40889.3    0.287     2
Total extinctions: 0
Generation time: 7.708 sec (5.058 average)
 ****** Running generation 5 ******
Population's average fitness: 14445.01667 stdev: 18446.75002
Best fitness: 48383.00000 - size: (6, 21) - species 1 - id 98
Average adjusted fitness: 0.298
Mean genetic distance 1.134, standard deviation 0.167
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    5    20  48383.0    0.298     0
Total extinctions: 0
Generation time: 7.661 sec (5.492 average)
 ****** Running generation 6 ******
Population's average fitness: 18508.55000 stdev: 20795.26470
Best fitness: 54866.33333 - size: (6, 22) - species 1 - id 122
Average adjusted fitness: 0.337
Mean genetic distance 0.981, standard deviation 0.212
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    6    20  54866.3    0.337     0
Total extinctions: 0
Generation time: 7.613 sec (5.795 average)
 ****** Running generation 7 ******
Population's average fitness: 14267.16667 stdev: 20147.17458
Best fitness: 54866.33333 - size: (6, 22) - species 1 - id 122
Average adjusted fitness: 0.260
Mean genetic distance 0.861, standard deviation 0.242
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    7    20  54866.3    0.260     1
Total extinctions: 0
Generation time: 7.664 sec (6.029 average)
 ****** Running generation 8 ******
Population's average fitness: 17423.80333 stdev: 23051.49072
Best fitness: 67650.00000 - size: (6, 23) - species 1 - id 154
Average adjusted fitness: 0.257
Mean genetic distance 0.945, standard deviation 0.211
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    8    20  67650.0    0.257     0
Total extinctions: 0
Generation time: 7.641 sec (6.208 average)
 ****** Running generation 9 ******
Population's average fitness: 21748.58000 stdev: 29622.69300
Best fitness: 108929.93333 - size: (6, 20) - species 1 - id 170
Average adjusted fitness: 0.200
Mean genetic distance 1.071, standard deviation 0.215
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    9    20  108929.9    0.200     0
Total extinctions: 0
Generation time: 7.607 sec (6.348 average)
 ****** Running generation 10 ******
Population's average fitness: 22133.10667 stdev: 32177.46162
Best fitness: 108929.93333 - size: (6, 20) - species 1 - id 170
Average adjusted fitness: 0.203
Mean genetic distance 1.106, standard deviation 0.336
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1   10    20  108929.9    0.203     1
Total extinctions: 0
Generation time: 7.637 sec (7.002 average)
Simulating on trained reward function...
Running for a maximum of 11 generations...
 ****** Running generation 0 ******
Population's average fitness: 2.12345 stdev: 6.30503
Best fitness: 24.88589 - size: (4, 20) - species 1 - id 17
Average adjusted fitness: 0.197
Mean genetic distance 1.186, standard deviation 0.305
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20     24.9    0.197     0
Total extinctions: 0
Generation time: 7.885 sec
 ****** Running generation 1 ******
Population's average fitness: 11.37809 stdev: 16.92895
Best fitness: 46.59142 - size: (5, 20) - species 1 - id 35
Average adjusted fitness: 0.270
Mean genetic distance 0.877, standard deviation 0.198
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    1    20     46.6    0.270     0
Total extinctions: 0
Generation time: 7.708 sec (7.796 average)
 ****** Running generation 2 ******
Traceback (most recent call last):
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 82, in <module>
    start_simulation("./config/agent_config.txt", args.generations[0])
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 17, in start_simulation
    run_population(
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 405, in run_population
    best_genome = population.run(
  File "/Users/alextang/.pyenv/versions/nocturne_lab/lib/python3.10/site-packages/neat/population.py", line 89, in run
    fitness_function(list(iteritems(self.population)), self.config)
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 325, in run_simulation
    car.update(game_map)
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 175, in update
    self.check_radar(d, game_map)
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 106, in check_radar
    + math.cos(math.radians(360 - (self.angle + degree))) * length
KeyboardInterrupt