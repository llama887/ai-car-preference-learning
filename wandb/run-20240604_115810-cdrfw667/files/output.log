Epoch 0/1000, Train Loss: 2.2764007449150085, Val Loss: 0.6968782544136047, Train Acc: 0.475, Val Acc: 0.3499999940395355, LR: 0.0009371941855053023
Epoch 10/1000, Train Loss: 1.6024277806282043, Val Loss: 0.6073379516601562, Train Acc: 0.55, Val Acc: 1.0, LR: 0.0009092766029756823
Epoch 20/1000, Train Loss: 1.3637133538722992, Val Loss: 0.5716158747673035, Train Acc: 0.5, Val Acc: 1.0, LR: 0.0008813590204460617
Epoch 30/1000, Train Loss: 1.2201733589172363, Val Loss: 0.5406551957130432, Train Acc: 0.625, Val Acc: 1.0, LR: 0.0008534414379164414
Epoch 40/1000, Train Loss: 0.9120146781206131, Val Loss: 0.46819645166397095, Train Acc: 0.725, Val Acc: 1.0, LR: 0.0008255238553868207
Epoch 50/1000, Train Loss: 0.9639267325401306, Val Loss: 0.3805512487888336, Train Acc: 0.65, Val Acc: 1.0, LR: 0.0007976062728572001
Epoch 60/1000, Train Loss: 0.946206733584404, Val Loss: 0.3166201710700989, Train Acc: 0.75, Val Acc: 1.0, LR: 0.0007696886903275794
Epoch 70/1000, Train Loss: 0.7276497036218643, Val Loss: 0.2906387150287628, Train Acc: 0.7375, Val Acc: 1.0, LR: 0.0007417711077979587
Epoch 80/1000, Train Loss: 0.7890935838222504, Val Loss: 0.3062964081764221, Train Acc: 0.7375, Val Acc: 1.0, LR: 0.0007138535252683383
Epoch 90/1000, Train Loss: 0.8257006108760834, Val Loss: 0.30756279826164246, Train Acc: 0.75, Val Acc: 1.0, LR: 0.0006859359427387182
Epoch 100/1000, Train Loss: 0.7615161091089249, Val Loss: 0.305642694234848, Train Acc: 0.7125, Val Acc: 1.0, LR: 0.0006580183602090977
Epoch 110/1000, Train Loss: 0.7304455190896988, Val Loss: 0.3075527846813202, Train Acc: 0.7625, Val Acc: 1.0, LR: 0.0006301007776794768
Epoch 120/1000, Train Loss: 0.6905470192432404, Val Loss: 0.29811930656433105, Train Acc: 0.7375, Val Acc: 1.0, LR: 0.0006021831951498564
Epoch 130/1000, Train Loss: 0.7401033639907837, Val Loss: 0.27096042037010193, Train Acc: 0.7625, Val Acc: 1.0, LR: 0.0005742656126202356
Epoch 140/1000, Train Loss: 0.6334500759840012, Val Loss: 0.29302462935447693, Train Acc: 0.825, Val Acc: 1.0, LR: 0.0005463480300906147
Epoch 150/1000, Train Loss: 0.7099147439002991, Val Loss: 0.28177008032798767, Train Acc: 0.775, Val Acc: 1.0, LR: 0.000518430447560994
Epoch 160/1000, Train Loss: 0.6495541483163834, Val Loss: 0.2945006489753723, Train Acc: 0.7625, Val Acc: 1.0, LR: 0.0004905128650313736
Epoch 170/1000, Train Loss: 0.6925478130578995, Val Loss: 0.2990977466106415, Train Acc: 0.7625, Val Acc: 1.0, LR: 0.00046259528250175327
Epoch 180/1000, Train Loss: 0.6844240576028824, Val Loss: 0.3002609610557556, Train Acc: 0.75, Val Acc: 1.0, LR: 0.000434677699972133
Epoch 190/1000, Train Loss: 0.5316489785909653, Val Loss: 0.27810153365135193, Train Acc: 0.85, Val Acc: 1.0, LR: 0.00040676011744251273
Epoch 200/1000, Train Loss: 0.6711642444133759, Val Loss: 0.28092044591903687, Train Acc: 0.7875, Val Acc: 1.0, LR: 0.00037884253491289247
Epoch 210/1000, Train Loss: 0.6880471557378769, Val Loss: 0.28953421115875244, Train Acc: 0.775, Val Acc: 1.0, LR: 0.0003509249523832722
Epoch 220/1000, Train Loss: 0.72933529317379, Val Loss: 0.2807467579841614, Train Acc: 0.7125, Val Acc: 1.0, LR: 0.00032300736985365193
Epoch 230/1000, Train Loss: 0.6491857171058655, Val Loss: 0.28768190741539, Train Acc: 0.7875, Val Acc: 1.0, LR: 0.00029508978732403166
Epoch 240/1000, Train Loss: 0.7320393621921539, Val Loss: 0.27933168411254883, Train Acc: 0.75, Val Acc: 1.0, LR: 0.0002671722047944114
Epoch 250/1000, Train Loss: 0.5044062286615372, Val Loss: 0.2702825665473938, Train Acc: 0.8625, Val Acc: 1.0, LR: 0.0002392546222647911
Epoch 260/1000, Train Loss: 0.6618356704711914, Val Loss: 0.2697669267654419, Train Acc: 0.725, Val Acc: 1.0, LR: 0.0002113370397351707
Epoch 270/1000, Train Loss: 0.6599284112453461, Val Loss: 0.2534235417842865, Train Acc: 0.8, Val Acc: 1.0, LR: 0.00018341945720555026
Epoch 280/1000, Train Loss: 0.5590486824512482, Val Loss: 0.2728458046913147, Train Acc: 0.825, Val Acc: 1.0, LR: 0.00015550187467592994
Epoch 290/1000, Train Loss: 0.6531755775213242, Val Loss: 0.25692424178123474, Train Acc: 0.75, Val Acc: 1.0, LR: 0.00012758429214630962
Epoch 300/1000, Train Loss: 0.5604892671108246, Val Loss: 0.2527469992637634, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.966670961668914e-05
Epoch 310/1000, Train Loss: 0.5963876694440842, Val Loss: 0.25875887274742126, Train Acc: 0.7875, Val Acc: 1.0, LR: 7.174912708706858e-05
Epoch 320/1000, Train Loss: 0.6608883142471313, Val Loss: 0.2511206865310669, Train Acc: 0.7875, Val Acc: 1.0, LR: 4.3831544557448025e-05
Epoch 330/1000, Train Loss: 0.5358665660023689, Val Loss: 0.24373061954975128, Train Acc: 0.8375, Val Acc: 1.0, LR: 1.591396202782747e-05
Epoch 340/1000, Train Loss: 0.5197640433907509, Val Loss: 0.24359941482543945, Train Acc: 0.8625, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 350/1000, Train Loss: 0.5519618541002274, Val Loss: 0.24425581097602844, Train Acc: 0.825, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 360/1000, Train Loss: 0.5581062436103821, Val Loss: 0.24095316231250763, Train Acc: 0.85, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 370/1000, Train Loss: 0.55735182762146, Val Loss: 0.23973584175109863, Train Acc: 0.8625, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 380/1000, Train Loss: 0.5952078998088837, Val Loss: 0.24205300211906433, Train Acc: 0.7625, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 390/1000, Train Loss: 0.6347407400608063, Val Loss: 0.2423284500837326, Train Acc: 0.8, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 400/1000, Train Loss: 0.5523665100336075, Val Loss: 0.2407921999692917, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 410/1000, Train Loss: 0.6589019447565079, Val Loss: 0.2424541413784027, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 420/1000, Train Loss: 0.5987054109573364, Val Loss: 0.2402639389038086, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 430/1000, Train Loss: 0.7258816361427307, Val Loss: 0.2412167340517044, Train Acc: 0.7875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 440/1000, Train Loss: 0.5172489583492279, Val Loss: 0.23885509371757507, Train Acc: 0.825, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 450/1000, Train Loss: 0.5229194462299347, Val Loss: 0.23478910326957703, Train Acc: 0.8, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 460/1000, Train Loss: 0.6308208853006363, Val Loss: 0.23289820551872253, Train Acc: 0.8, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 470/1000, Train Loss: 0.5036188513040543, Val Loss: 0.2314612865447998, Train Acc: 0.8, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 480/1000, Train Loss: 0.5842137932777405, Val Loss: 0.23171469569206238, Train Acc: 0.7875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 490/1000, Train Loss: 0.6556332856416702, Val Loss: 0.23478618264198303, Train Acc: 0.8, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 500/1000, Train Loss: 0.5415628328919411, Val Loss: 0.23346967995166779, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 510/1000, Train Loss: 0.632730208337307, Val Loss: 0.2330137938261032, Train Acc: 0.7875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 520/1000, Train Loss: 0.4929971694946289, Val Loss: 0.23212449252605438, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 530/1000, Train Loss: 0.5560594499111176, Val Loss: 0.23223181068897247, Train Acc: 0.775, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 540/1000, Train Loss: 0.46728669106960297, Val Loss: 0.2302968055009842, Train Acc: 0.8875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 550/1000, Train Loss: 0.5918100625276566, Val Loss: 0.2298664152622223, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 560/1000, Train Loss: 0.6617414951324463, Val Loss: 0.22644007205963135, Train Acc: 0.7875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 570/1000, Train Loss: 0.6172937452793121, Val Loss: 0.22923922538757324, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 580/1000, Train Loss: 0.5796165764331818, Val Loss: 0.22793348133563995, Train Acc: 0.775, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 590/1000, Train Loss: 0.49339069426059723, Val Loss: 0.23066624999046326, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 600/1000, Train Loss: 0.5655703693628311, Val Loss: 0.2280736267566681, Train Acc: 0.775, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 610/1000, Train Loss: 0.5584829151630402, Val Loss: 0.22468873858451843, Train Acc: 0.825, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 620/1000, Train Loss: 0.5945126712322235, Val Loss: 0.22323672473430634, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 630/1000, Train Loss: 0.6432678252458572, Val Loss: 0.22309961915016174, Train Acc: 0.7875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 640/1000, Train Loss: 0.5117029547691345, Val Loss: 0.22209003567695618, Train Acc: 0.8625, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 650/1000, Train Loss: 0.5659587383270264, Val Loss: 0.22221580147743225, Train Acc: 0.8, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 660/1000, Train Loss: 0.5856101810932159, Val Loss: 0.22327105700969696, Train Acc: 0.7625, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 670/1000, Train Loss: 0.5927965641021729, Val Loss: 0.22379763424396515, Train Acc: 0.7875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 680/1000, Train Loss: 0.5282746702432632, Val Loss: 0.22545728087425232, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 690/1000, Train Loss: 0.5011411234736443, Val Loss: 0.22485217452049255, Train Acc: 0.85, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 700/1000, Train Loss: 0.5251795426011086, Val Loss: 0.2259916067123413, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 710/1000, Train Loss: 0.584998831152916, Val Loss: 0.22288429737091064, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 720/1000, Train Loss: 0.6079177707433701, Val Loss: 0.2217128574848175, Train Acc: 0.7875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 730/1000, Train Loss: 0.5719287097454071, Val Loss: 0.222900390625, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 740/1000, Train Loss: 0.5131047815084457, Val Loss: 0.22124311327934265, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 750/1000, Train Loss: 0.514605849981308, Val Loss: 0.21990342438220978, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 760/1000, Train Loss: 0.4666890352964401, Val Loss: 0.21978643536567688, Train Acc: 0.875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 770/1000, Train Loss: 0.5932352244853973, Val Loss: 0.22229453921318054, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 780/1000, Train Loss: 0.589615136384964, Val Loss: 0.22158639132976532, Train Acc: 0.75, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 790/1000, Train Loss: 0.5122672468423843, Val Loss: 0.2215542495250702, Train Acc: 0.8875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 800/1000, Train Loss: 0.5020857155323029, Val Loss: 0.2209269255399704, Train Acc: 0.775, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 810/1000, Train Loss: 0.48723456263542175, Val Loss: 0.21928277611732483, Train Acc: 0.825, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 820/1000, Train Loss: 0.6359772682189941, Val Loss: 0.22159318625926971, Train Acc: 0.8, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 830/1000, Train Loss: 0.5463648736476898, Val Loss: 0.22038069367408752, Train Acc: 0.85, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 840/1000, Train Loss: 0.498357817530632, Val Loss: 0.22000634670257568, Train Acc: 0.825, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 850/1000, Train Loss: 0.5729749947786331, Val Loss: 0.221424862742424, Train Acc: 0.775, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 860/1000, Train Loss: 0.6110991761088371, Val Loss: 0.21648907661437988, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 870/1000, Train Loss: 0.47353531420230865, Val Loss: 0.21785993874073029, Train Acc: 0.85, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 880/1000, Train Loss: 0.4930672124028206, Val Loss: 0.2184879332780838, Train Acc: 0.875, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 890/1000, Train Loss: 0.5832466781139374, Val Loss: 0.21627011895179749, Train Acc: 0.8625, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 900/1000, Train Loss: 0.5773846209049225, Val Loss: 0.2167322188615799, Train Acc: 0.825, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 910/1000, Train Loss: 0.5504488945007324, Val Loss: 0.2169860154390335, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 920/1000, Train Loss: 0.5661132782697678, Val Loss: 0.21850140392780304, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 930/1000, Train Loss: 0.5568794161081314, Val Loss: 0.22145430743694305, Train Acc: 0.8625, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 940/1000, Train Loss: 0.5461363345384598, Val Loss: 0.21932101249694824, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 950/1000, Train Loss: 0.5336207449436188, Val Loss: 0.22049471735954285, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 960/1000, Train Loss: 0.6894440203905106, Val Loss: 0.22210483253002167, Train Acc: 0.7625, Val Acc: 1.0, LR: 9.39985943758269e-06
[34m[1mwandb[39m[22m: [33mWARNING[39m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'Train Loss': 2.2764007449150085, 'Validation Loss': 0.6968782544136047, 'Train Accuracy': 0.475, 'Validation Accuracy': 0.3499999940395355, '_timestamp': 1717516691.271839}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.weight': {'_type': 'histogram', 'values': [329, 969, 1262, 1333, 1272, 1239, 1231, 1342, 1314, 1220, 1278, 1277, 1314, 1261, 1298, 1240, 1264, 1316, 1275, 1293, 1263, 1311, 1280, 1290, 1313, 1305, 1323, 1277, 1238, 1280, 1287, 1296, 1279, 1305, 1241, 1238, 1222, 1238, 1346, 1279, 1301, 1251, 1294, 1282, 1291, 1207, 1201, 1349, 1324, 1257, 1269, 1266, 1311, 1254, 1256, 1261, 1316, 1239, 1295, 1262, 1257, 1283, 951, 285], 'bins': [-0.11291855573654175, -0.1093883216381073, -0.10585808008909225, -0.1023278459906578, -0.09879761189222336, -0.09526737034320831, -0.09173713624477386, -0.08820690214633942, -0.08467666059732437, -0.08114642649888992, -0.07761619240045547, -0.07408595085144043, -0.07055571675300598, -0.06702548265457153, -0.06349524110555649, -0.05996500700712204, -0.05643477290868759, -0.052904535084962845, -0.0493742972612381, -0.04584406316280365, -0.0423138253390789, -0.038783587515354156, -0.03525335341691971, -0.03172311559319496, -0.028192877769470215, -0.024662641808390617, -0.02113240584731102, -0.017602169886231422, -0.014071932062506676, -0.010541696101427078, -0.007011459209024906, -0.0034812227822840214, 4.90136444568634e-05, 0.003579250071197748, 0.007109486497938633, 0.010639723390340805, 0.014169959351420403, 0.01770019717514515, 0.021230433136224747, 0.024760669097304344, 0.02829090505838394, 0.03182114288210869, 0.035351380705833435, 0.03888161480426788, 0.04241185262799263, 0.04594209045171738, 0.049472324550151825, 0.05300256237387657, 0.05653280019760132, 0.06006303429603577, 0.06359326839447021, 0.06712350994348526, 0.07065374404191971, 0.07418397814035416, 0.0777142196893692, 0.08124445378780365, 0.0847746878862381, 0.08830492943525314, 0.09183516353368759, 0.09536539763212204, 0.09889563918113708, 0.10242587327957153, 0.10595610737800598, 0.10948634892702103, 0.11301658302545547]}, '_timestamp': 1717516691.2756102}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc1.bias': {'_type': 'histogram', 'values': [4, 2, 2, 2, 1, 2, 3, 1, 0, 1, 1, 1, 0, 0, 1, 2, 0, 1, 0, 2, 4, 4, 0, 2, 1, 1, 0, 4, 1, 1, 0, 4, 1, 3, 4, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 4, 2, 1, 0, 1, 0, 0, 2, 0, 1, 2, 1, 2, 4, 3, 1, 0, 2, 1], 'bins': [-0.029924815520644188, -0.028994979336857796, -0.028065141290426254, -0.027135305106639862, -0.02620546706020832, -0.02527563087642193, -0.024345792829990387, -0.023415956646203995, -0.022486118599772453, -0.02155628241598606, -0.02062644436955452, -0.019696608185768127, -0.018766770139336586, -0.017836933955550194, -0.016907095909118652, -0.01597725972533226, -0.015047421678900719, -0.014117585495114326, -0.01318774838000536, -0.012257911264896393, -0.011328074149787426, -0.01039823703467846, -0.009468399919569492, -0.008538562804460526, -0.007608725689351559, -0.006678888574242592, -0.005749051459133625, -0.004819214344024658, -0.0038893772289156914, -0.0029595401138067245, -0.0020297029986977577, -0.001099865883588791, -0.00017002876847982407, 0.0007598083466291428, 0.0016896454617381096, 0.0026194825768470764, 0.0035493196919560432, 0.00447915680706501, 0.005408993922173977, 0.006338831037282944, 0.0072686681523919106, 0.008198505267500877, 0.009128342382609844, 0.010058179497718811, 0.010988016612827778, 0.011917853727936745, 0.012847690843045712, 0.013777527958154678, 0.01470736414194107, 0.015637202188372612, 0.016567038372159004, 0.017496876418590546, 0.018426712602376938, 0.01935655064880848, 0.02028638683259487, 0.021216224879026413, 0.022146061062812805, 0.023075899109244347, 0.02400573529303074, 0.02493557333946228, 0.025865409523248672, 0.026795247569680214, 0.027725083753466606, 0.028654921799898148, 0.02958475798368454]}, '_timestamp': 1717516691.275871}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.weight': {'_type': 'histogram', 'values': [47, 4, 3, 3, 1, 1, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 2], 'bins': [0.9971794486045837, 0.9972673058509827, 0.9973551034927368, 0.9974429607391357, 0.9975307583808899, 0.9976186156272888, 0.997706413269043, 0.9977942705154419, 0.997882068157196, 0.997969925403595, 0.9980577230453491, 0.998145580291748, 0.9982333779335022, 0.9983212351799011, 0.9984090328216553, 0.9984968900680542, 0.9985846877098083, 0.9986725449562073, 0.9987603425979614, 0.9988481998443604, 0.9989359974861145, 0.9990238547325134, 0.9991116523742676, 0.9991995096206665, 0.9992873072624207, 0.9993751645088196, 0.9994629621505737, 0.9995508193969727, 0.9996386170387268, 0.9997264742851257, 0.9998142719268799, 0.9999021291732788, 0.9999899864196777, 1.0000778436660767, 1.000165581703186, 1.000253438949585, 1.0003412961959839, 1.0004291534423828, 1.0005168914794922, 1.0006047487258911, 1.00069260597229, 1.000780463218689, 1.0008682012557983, 1.0009560585021973, 1.0010439157485962, 1.0011317729949951, 1.0012195110321045, 1.0013073682785034, 1.0013952255249023, 1.0014830827713013, 1.0015708208084106, 1.0016586780548096, 1.0017465353012085, 1.0018343925476074, 1.0019221305847168, 1.0020099878311157, 1.0020978450775146, 1.0021857023239136, 1.002273440361023, 1.0023612976074219, 1.0024491548538208, 1.0025370121002197, 1.002624750137329, 1.002712607383728, 1.002800464630127]}, '_timestamp': 1717516691.276056}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn1.bias': {'_type': 'histogram', 'values': [2, 3, 0, 2, 3, 1, 1, 0, 10, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 3, 2, 0, 0, 0, 2, 1, 26, 1, 0, 2, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 2, 3], 'bins': [-0.0028190151788294315, -0.0027310375589877367, -0.002643059939146042, -0.002555082319304347, -0.002467104699462652, -0.0023791270796209574, -0.0022911494597792625, -0.0022031718399375677, -0.002115194220095873, -0.002027216600254178, -0.0019392388639971614, -0.0018512612441554666, -0.0017632836243137717, -0.001675306004472077, -0.001587328384630382, -0.0014993507647886872, -0.0014113731449469924, -0.0013233955251052976, -0.0012354179052636027, -0.001147440285421908, -0.001059462665580213, -0.0009714849875308573, -0.0008835073676891625, -0.0007955297478474677, -0.0007075521280057728, -0.000619574508164078, -0.0005315968883223832, -0.0004436192393768579, -0.00035564161953516304, -0.0002676639996934682, -0.00017968636529985815, -9.170873818220571e-05, -3.731111064553261e-06, 8.424651605309919e-05, 0.00017222414317075163, 0.0002602017775643617, 0.0003481793974060565, 0.00043615701724775136, 0.0005241346661932766, 0.0006121122860349715, 0.0007000899058766663, 0.0007880675257183611, 0.000876045145560056, 0.0009640227654017508, 0.0010520004434511065, 0.0011399780632928014, 0.0012279556831344962, 0.001315933302976191, 0.0014039109228178859, 0.0014918885426595807, 0.0015798661625012755, 0.0016678437823429704, 0.0017558214021846652, 0.00184379902202636, 0.0019317766418680549, 0.0020197543781250715, 0.0021077319979667664, 0.002195709617808461, 0.002283687237650156, 0.002371664857491851, 0.0024596424773335457, 0.0025476200971752405, 0.0026355977170169353, 0.00272357533685863, 0.002811552956700325]}, '_timestamp': 1717516691.2762182}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.weight': {'_type': 'histogram', 'values': [86, 116, 125, 112, 133, 111, 123, 107, 125, 131, 117, 120, 142, 122, 117, 114, 109, 110, 111, 147, 118, 121, 116, 146, 100, 125, 113, 130, 116, 130, 147, 135, 121, 114, 133, 132, 135, 132, 125, 117, 128, 122, 132, 133, 107, 122, 104, 128, 100, 117, 126, 126, 123, 115, 139, 109, 111, 106, 120, 132, 136, 117, 122, 85], 'bins': [-0.26219063997268677, -0.2539907991886139, -0.24579092860221863, -0.23759108781814575, -0.22939123213291168, -0.2211913764476776, -0.21299153566360474, -0.20479167997837067, -0.1965918242931366, -0.18839196860790253, -0.18019211292266846, -0.17199227213859558, -0.1637924164533615, -0.15559256076812744, -0.14739271998405457, -0.1391928642988205, -0.13099300861358643, -0.12279315292835236, -0.11459330469369888, -0.10639345645904541, -0.09819360077381134, -0.08999374508857727, -0.0817938968539238, -0.07359404861927032, -0.06539419293403625, -0.057194340974092484, -0.04899448901414871, -0.04079463705420494, -0.03259478509426117, -0.024394933134317398, -0.016195081174373627, -0.007995229214429855, 0.00020462274551391602, 0.008404474705457687, 0.01660432666540146, 0.02480417862534523, 0.033004030585289, 0.04120388254523277, 0.049403734505176544, 0.057603586465120316, 0.06580343842506409, 0.07400329411029816, 0.08220314234495163, 0.0904029905796051, 0.09860284626483917, 0.10680270195007324, 0.11500255018472672, 0.12320239841938019, 0.13140225410461426, 0.13960210978984833, 0.1478019654750824, 0.15600180625915527, 0.16420166194438934, 0.1724015176296234, 0.1806013584136963, 0.18880121409893036, 0.19700106978416443, 0.2052009254693985, 0.21340078115463257, 0.22160062193870544, 0.22980047762393951, 0.23800033330917358, 0.24620017409324646, 0.2544000446796417, 0.2625998854637146]}, '_timestamp': 1717516691.2764318}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc2.bias': {'_type': 'histogram', 'values': [1, 0, 1, 0, 1, 1, 0, 2, 3, 3, 1, 1, 1, 0, 2, 0, 1, 2, 2, 1, 3, 1, 0, 3, 2, 0, 2, 0, 2, 5, 2, 2, 0, 1, 1, 0, 1, 0, 3, 1, 1, 1, 1, 1, 1, 4, 2, 1, 2, 1, 2, 3, 1, 0, 3, 1, 3, 2, 2, 0, 0, 0, 0, 4], 'bins': [-0.10781624168157578, -0.10453367233276367, -0.10125109553337097, -0.09796852618455887, -0.09468595683574677, -0.09140338003635406, -0.08812081068754196, -0.08483823388814926, -0.08155566453933716, -0.07827309519052505, -0.07499051839113235, -0.07170794904232025, -0.06842537224292755, -0.06514280289411545, -0.061860233545303345, -0.05857766047120094, -0.05529508739709854, -0.05201251432299614, -0.04872994124889374, -0.045447371900081635, -0.04216479882597923, -0.03888222575187683, -0.03559965640306473, -0.032317083328962326, -0.029034510254859924, -0.025751937180757523, -0.02246936596930027, -0.019186794757843018, -0.015904221683740616, -0.012621649540960789, -0.009339077398180962, -0.0060565052554011345, -0.0027739331126213074, 0.0005086390301585197, 0.003791211172938347, 0.007073783315718174, 0.010356355458498001, 0.013638927601277828, 0.016921499744057655, 0.020204070955514908, 0.02348664402961731, 0.02676921710371971, 0.030051788315176964, 0.033334359526634216, 0.03661693260073662, 0.03989950567483902, 0.04318207502365112, 0.046464648097753525, 0.049747221171855927, 0.05302979424595833, 0.05631236732006073, 0.05959493666887283, 0.06287750601768494, 0.06616008281707764, 0.06944265216588974, 0.07272522896528244, 0.07600779831409454, 0.07929036766290665, 0.08257294446229935, 0.08585551381111145, 0.08913809061050415, 0.09242065995931625, 0.09570322930812836, 0.09898580610752106, 0.10226837545633316]}, '_timestamp': 1717516691.276587}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.weight': {'_type': 'histogram', 'values': [7, 5, 2, 8, 1, 0, 5, 1, 1, 3, 4, 0, 1, 1, 2, 0, 0, 1, 1, 2, 2, 0, 3, 1, 1, 2, 1, 2, 0, 0, 4, 3, 0, 2, 0, 1, 1, 1, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 2, 1, 0, 0, 0, 2, 2, 2, 0, 1, 0, 1, 1], 'bins': [0.9971808791160583, 0.9972689747810364, 0.9973571300506592, 0.9974452257156372, 0.9975333213806152, 0.997621476650238, 0.9977095723152161, 0.9977976679801941, 0.9978858232498169, 0.9979739189147949, 0.998062014579773, 0.9981501698493958, 0.9982382655143738, 0.9983263611793518, 0.9984145164489746, 0.9985026121139526, 0.9985907077789307, 0.9986788630485535, 0.9987669587135315, 0.9988550543785095, 0.9989432096481323, 0.9990313053131104, 0.9991194009780884, 0.9992075562477112, 0.9992956519126892, 0.9993837475776672, 0.99947190284729, 0.9995599985122681, 0.9996480941772461, 0.9997362494468689, 0.9998243451118469, 0.999912440776825, 1.0000005960464478, 1.0000886917114258, 1.0001767873764038, 1.0002648830413818, 1.0003529787063599, 1.0004411935806274, 1.0005292892456055, 1.0006173849105835, 1.0007054805755615, 1.0007935762405396, 1.0008816719055176, 1.0009698867797852, 1.0010579824447632, 1.0011460781097412, 1.0012341737747192, 1.0013222694396973, 1.0014103651046753, 1.0014985799789429, 1.001586675643921, 1.001674771308899, 1.001762866973877, 1.001850962638855, 1.001939058303833, 1.0020272731781006, 1.0021153688430786, 1.0022034645080566, 1.0022915601730347, 1.0023796558380127, 1.0024677515029907, 1.0025559663772583, 1.0026440620422363, 1.0027321577072144, 1.0028202533721924]}, '_timestamp': 1717516691.276746}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn2.bias': {'_type': 'histogram', 'values': [3, 1, 3, 2, 2, 2, 4, 3, 0, 1, 1, 1, 2, 0, 0, 2, 2, 0, 2, 2, 1, 4, 0, 1, 0, 3, 1, 2, 2, 1, 0, 2, 3, 2, 0, 2, 0, 1, 2, 1, 0, 0, 0, 3, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 5, 1], 'bins': [-0.0027974082622677088, -0.002711390843614936, -0.0026253731921315193, -0.0025393557734787464, -0.0024533383548259735, -0.0023673209361732006, -0.0022813035175204277, -0.002195285866037011, -0.0021092684473842382, -0.0020232510287314653, -0.0019372334936633706, -0.0018512159585952759, -0.001765198539942503, -0.00167918112128973, -0.0015931635862216353, -0.0015071460511535406, -0.0014211286325007677, -0.0013351112138479948, -0.0012490936787799, -0.0011630761437118053, -0.0010770587250590324, -0.0009910413064062595, -0.0009050237713381648, -0.000819006294477731, -0.0007329888176172972, -0.0006469713407568634, -0.0005609538638964295, -0.0004749363870359957, -0.0003889189101755619, -0.0003029014333151281, -0.00021688395645469427, -0.00013086647959426045, -4.484900273382664e-05, 4.116847412660718e-05, 0.000127185950987041, 0.0002132034278474748, 0.00029922090470790863, 0.00038523838156834245, 0.00047125585842877626, 0.0005572733352892101, 0.0006432908121496439, 0.0007293082890100777, 0.0008153257658705115, 0.0009013432427309453, 0.0009873607195913792, 0.001073378138244152, 0.0011593956733122468, 0.0012454132083803415, 0.0013314306270331144, 0.0014174480456858873, 0.001503465580753982, 0.0015894831158220768, 0.0016755005344748497, 0.0017615179531276226, 0.0018475354881957173, 0.001933553023263812, 0.002019570441916585, 0.002105587860569358, 0.0021916055120527744, 0.0022776229307055473, 0.0023636403493583202, 0.002449657768011093, 0.002535675186663866, 0.0026216928381472826, 0.0027077102568000555]}, '_timestamp': 1717516691.2769}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.weight': {'_type': 'histogram', 'values': [73, 135, 118, 126, 137, 124, 132, 121, 106, 128, 120, 142, 108, 126, 145, 125, 134, 143, 115, 119, 121, 124, 104, 118, 120, 114, 132, 116, 117, 121, 113, 124, 107, 129, 126, 105, 112, 132, 115, 106, 118, 141, 114, 119, 121, 110, 125, 122, 115, 123, 125, 129, 139, 123, 111, 131, 117, 112, 107, 114, 149, 131, 134, 81], 'bins': [-0.26338160037994385, -0.2551596760749817, -0.24693773686885834, -0.23871579766273499, -0.23049387335777283, -0.22227193415164948, -0.21405000984668732, -0.20582807064056396, -0.1976061463356018, -0.18938420712947845, -0.1811622828245163, -0.17294034361839294, -0.1647184193134308, -0.15649648010730743, -0.14827455580234528, -0.14005261659622192, -0.13183069229125977, -0.12360875308513641, -0.11538682132959366, -0.1071648895740509, -0.09894295781850815, -0.0907210260629654, -0.08249909430742264, -0.07427716255187988, -0.06605522334575653, -0.057833295315504074, -0.04961136355996132, -0.041389431804418564, -0.03316749632358551, -0.024945566430687904, -0.0167236328125, -0.008501701056957245, -0.00027976930141448975, 0.007942162454128265, 0.01616409420967102, 0.024386027827858925, 0.03260795772075653, 0.040829893201589584, 0.04905182495713234, 0.057273756712675095, 0.06549568474292755, 0.0737176239490509, 0.08193955570459366, 0.09016148746013641, 0.09838341921567917, 0.10660535097122192, 0.11482728272676468, 0.12304921448230743, 0.1312711536884308, 0.13949307799339294, 0.1477150171995163, 0.15593694150447845, 0.1641588807106018, 0.17238080501556396, 0.18060274422168732, 0.18882466852664948, 0.19704660773277283, 0.20526853203773499, 0.21349047124385834, 0.2217123955488205, 0.22993433475494385, 0.238156259059906, 0.24637819826602936, 0.2546001374721527, 0.26282206177711487]}, '_timestamp': 1717516691.2771049}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc3.bias': {'_type': 'histogram', 'values': [2, 0, 1, 2, 0, 1, 1, 1, 0, 2, 2, 4, 0, 2, 2, 0, 2, 4, 3, 0, 1, 1, 1, 1, 1, 2, 0, 2, 3, 0, 0, 2, 2, 2, 0, 0, 1, 2, 1, 0, 1, 0, 2, 3, 1, 0, 2, 0, 0, 2, 6, 0, 1, 2, 3, 3, 2, 2, 1, 1, 1, 2, 0, 2], 'bins': [-0.1069592759013176, -0.10369880497455597, -0.10043833404779434, -0.09717785567045212, -0.09391738474369049, -0.09065691381692886, -0.08739644289016724, -0.08413597196340561, -0.08087550103664398, -0.07761502265930176, -0.07435455173254013, -0.0710940808057785, -0.06783360987901688, -0.06457313895225525, -0.06131266430020332, -0.058052193373441696, -0.05479171872138977, -0.05153124779462814, -0.048270776867866516, -0.04501030221581459, -0.04174983128905296, -0.038489360362291336, -0.03522888571023941, -0.03196841478347778, -0.028707943856716156, -0.02544747106730938, -0.022186998277902603, -0.018926525488495827, -0.0156660545617342, -0.012405581772327423, -0.009145109914243221, -0.005884637590497732, -0.002624165266752243, 0.0006363069405779243, 0.0038967791479080915, 0.007157251238822937, 0.010417724028229713, 0.013678195886313915, 0.016938667744398117, 0.020199140533804893, 0.02345961332321167, 0.026720084249973297, 0.029980557039380074, 0.03324102982878685, 0.03650150075554848, 0.039761971682310104, 0.04302244633436203, 0.04628291726112366, 0.049543388187885284, 0.05280386283993721, 0.05606433376669884, 0.05932480841875076, 0.06258527934551239, 0.06584575027227402, 0.06910622119903564, 0.07236669212579727, 0.0756271705031395, 0.07888764142990112, 0.08214811235666275, 0.08540858328342438, 0.088669054210186, 0.09192952513694763, 0.09519000351428986, 0.09845047444105148, 0.10171094536781311]}, '_timestamp': 1717516691.277262}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.weight': {'_type': 'histogram', 'values': [15, 11, 5, 5, 5, 4, 2, 0, 1, 1, 1, 3, 1, 2, 2, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2], 'bins': [0.9971795082092285, 0.9972597360610962, 0.9973399639129639, 0.9974202513694763, 0.997500479221344, 0.9975807070732117, 0.9976609945297241, 0.9977412223815918, 0.9978214502334595, 0.9979016780853271, 0.9979819059371948, 0.9980621933937073, 0.998142421245575, 0.9982226490974426, 0.9983029365539551, 0.9983831644058228, 0.9984633922576904, 0.9985436201095581, 0.9986238479614258, 0.9987041354179382, 0.9987843632698059, 0.9988645911216736, 0.998944878578186, 0.9990251064300537, 0.9991053342819214, 0.9991855621337891, 0.9992657899856567, 0.9993460774421692, 0.9994263052940369, 0.9995065331459045, 0.999586820602417, 0.9996670484542847, 0.9997472763061523, 0.99982750415802, 0.9999077320098877, 0.9999880194664001, 1.000068187713623, 1.0001485347747803, 1.000228762626648, 1.0003089904785156, 1.0003892183303833, 1.000469446182251, 1.0005496740341187, 1.0006299018859863, 1.0007102489471436, 1.0007904767990112, 1.000870704650879, 1.0009509325027466, 1.0010311603546143, 1.001111388206482, 1.0011916160583496, 1.0012718439102173, 1.001352071762085, 1.0014324188232422, 1.0015126466751099, 1.0015928745269775, 1.0016731023788452, 1.001753330230713, 1.0018335580825806, 1.0019137859344482, 1.0019941329956055, 1.0020743608474731, 1.0021545886993408, 1.0022348165512085, 1.0023150444030762]}, '_timestamp': 1717516691.277416}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/bn3.bias': {'_type': 'histogram', 'values': [8, 4, 3, 4, 1, 4, 3, 2, 1, 1, 2, 2, 0, 1, 2, 1, 4, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 2, 0, 1, 1, 2, 3, 0, 0, 0, 0, 0, 0, 1, 1, 3, 0, 2, 2, 1, 0, 0, 3, 1, 0, 2, 1, 0, 1, 4], 'bins': [-0.002807093085721135, -0.00272033317014575, -0.002633573254570365, -0.00254681333899498, -0.0024600534234195948, -0.002373293275013566, -0.002286533359438181, -0.002199773443862796, -0.0021130135282874107, -0.0020262536127120256, -0.0019394936971366405, -0.0018527337815612555, -0.0017659737495705485, -0.0016792138339951634, -0.0015924539184197783, -0.0015056940028443933, -0.0014189339708536863, -0.0013321740552783012, -0.0012454141397029161, -0.001158654224127531, -0.001071894308552146, -0.000985134276561439, -0.0008983743609860539, -0.0008116144454106688, -0.0007248545298352838, -0.0006380945560522377, -0.0005513346404768527, -0.00046457466669380665, -0.00037781475111842155, -0.000291054806439206, -0.00020429486175999045, -0.0001175349170807749, -3.077497240155935e-05, 5.598496863967739e-05, 0.00014274491695687175, 0.00022950484708417207, 0.00031626480631530285, 0.00040302472189068794, 0.000489784695673734, 0.000576544611249119, 0.000663304585032165, 0.0007500645006075501, 0.0008368244161829352, 0.0009235843899659812, 0.0010103443637490273, 0.0010971042793244123, 0.0011838641948997974, 0.0012706241104751825, 0.0013573840260505676, 0.0014441440580412745, 0.0015309039736166596, 0.0016176638891920447, 0.0017044238047674298, 0.0017911838367581367, 0.0018779437523335218, 0.001964703667908907, 0.002051463583484292, 0.002138223499059677, 0.0022249834146350622, 0.0023117433302104473, 0.002398503478616476, 0.002485263394191861, 0.0025720233097672462, 0.0026587832253426313, 0.0027455431409180164]}, '_timestamp': 1717516691.277565}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.weight': {'_type': 'histogram', 'values': [3, 0, 4, 2, 0, 3, 2, 0, 2, 0, 4, 1, 1, 0, 0, 1, 0, 2, 1, 1, 1, 1, 3, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 0, 1, 1, 2, 1, 3, 4, 1, 1, 0, 2, 1, 0, 0, 0, 1, 1, 2, 3, 0, 1, 2, 3, 2, 1, 0, 0, 3, 1, 0, 5], 'bins': [-0.3464515805244446, -0.3356418013572693, -0.324832022190094, -0.3140222132205963, -0.303212434053421, -0.2924026548862457, -0.28159287571907043, -0.27078309655189514, -0.25997328758239746, -0.24916352331638336, -0.23835372924804688, -0.22754395008087158, -0.2167341709136963, -0.2059243768453598, -0.1951145976781845, -0.18430480360984802, -0.17349502444267273, -0.16268524527549744, -0.15187545120716095, -0.14106567203998566, -0.13025587797164917, -0.11944609880447388, -0.10863631963729858, -0.0978265330195427, -0.0870167464017868, -0.07620695978403091, -0.06539717316627502, -0.05458739399909973, -0.04377760738134384, -0.03296782076358795, -0.02215803787112236, -0.01134825311601162, -0.0005384683609008789, 0.010271316394209862, 0.021081101149320602, 0.031890884041786194, 0.042700670659542084, 0.053510457277297974, 0.06432023644447327, 0.07513002306222916, 0.08593980967998505, 0.09674959629774094, 0.10755938291549683, 0.11836916208267212, 0.1291789412498474, 0.1399887353181839, 0.1507985144853592, 0.16160830855369568, 0.17241808772087097, 0.18322786688804626, 0.19403766095638275, 0.20484744012355804, 0.21565723419189453, 0.22646701335906982, 0.23727679252624512, 0.2480865865945816, 0.2588963508605957, 0.2697061598300934, 0.2805159389972687, 0.29132571816444397, 0.30213549733161926, 0.31294527649879456, 0.32375508546829224, 0.33456486463546753, 0.3453746438026428]}, '_timestamp': 1717516691.2777212}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'weights/fc4.bias': {'_type': 'histogram', 'values': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'bins': [-0.586293637752533, -0.570668637752533, -0.555043637752533, -0.539418637752533, -0.523793637752533, -0.508168637752533, -0.49254363775253296, -0.47691863775253296, -0.46129363775253296, -0.44566863775253296, -0.43004363775253296, -0.41441863775253296, -0.39879363775253296, -0.38316863775253296, -0.36754363775253296, -0.35191863775253296, -0.33629363775253296, -0.32066863775253296, -0.30504363775253296, -0.28941863775253296, -0.27379363775253296, -0.25816863775253296, -0.24254365265369415, -0.22691865265369415, -0.21129365265369415, -0.19566865265369415, -0.18004365265369415, -0.16441865265369415, -0.14879365265369415, -0.13316865265369415, -0.11754365265369415, -0.10191865265369415, -0.08629365265369415, -0.07066865265369415, -0.05504365265369415, -0.03941865265369415, -0.023793652653694153, -0.008168652653694153, 0.007456347346305847, 0.023081347346305847, 0.03870634734630585, 0.05433134734630585, 0.06995634734630585, 0.08558134734630585, 0.10120634734630585, 0.11683134734630585, 0.13245634734630585, 0.14808134734630585, 0.16370634734630585, 0.17933134734630585, 0.19495634734630585, 0.21058134734630585, 0.22620634734630585, 0.24183134734630585, 0.25745636224746704, 0.27308136224746704, 0.28870636224746704, 0.30433136224746704, 0.31995636224746704, 0.33558136224746704, 0.35120636224746704, 0.36683136224746704, 0.38245636224746704, 0.39808136224746704, 0.41370636224746704]}, '_timestamp': 1717516691.277896}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TP Reward Distribution': {'_type': 'histogram', 'values': [5, 3, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'bins': [2.6666666666666665, 3.4916666666666667, 4.316666666666666, 5.141666666666667, 5.966666666666667, 6.791666666666666, 7.616666666666667, 8.441666666666666, 9.266666666666667, 10.091666666666667, 10.916666666666666, 11.741666666666667, 12.566666666666666, 13.391666666666667, 14.216666666666667, 15.041666666666668, 15.866666666666667, 16.691666666666666, 17.51666666666667, 18.34166666666667, 19.166666666666668, 19.99166666666667, 20.81666666666667, 21.64166666666667, 22.46666666666667, 23.291666666666668, 24.11666666666667, 24.94166666666667, 25.76666666666667, 26.59166666666667, 27.41666666666667, 28.24166666666667, 29.06666666666667, 29.89166666666667, 30.71666666666667, 31.54166666666667, 32.36666666666667, 33.19166666666667, 34.016666666666666, 34.84166666666667, 35.666666666666664, 36.49166666666667, 37.31666666666667, 38.141666666666666, 38.96666666666667, 39.791666666666664, 40.61666666666667, 41.44166666666667, 42.266666666666666, 43.09166666666667, 43.916666666666664, 44.74166666666667, 45.56666666666667, 46.391666666666666, 47.21666666666667, 48.04166666666667, 48.86666666666667, 49.69166666666667, 50.516666666666666, 51.34166666666667, 52.16666666666667, 52.99166666666667, 53.81666666666667, 54.641666666666666, 55.46666666666667]}, '_timestamp': 1717516691.278071}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'TN Reward Distribution': {'_type': 'histogram', 'values': [1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 1], 'bins': [3.3333333333333335, 3.6281250000000003, 3.9229166666666666, 4.217708333333333, 4.5125, 4.807291666666667, 5.102083333333334, 5.396875, 5.691666666666666, 5.986458333333333, 6.28125, 6.576041666666667, 6.870833333333334, 7.165625, 7.460416666666667, 7.755208333333334, 8.05, 8.344791666666667, 8.639583333333334, 8.934375000000001, 9.229166666666668, 9.523958333333333, 9.81875, 10.113541666666666, 10.408333333333333, 10.703125, 10.997916666666667, 11.292708333333334, 11.5875, 11.882291666666667, 12.177083333333334, 12.471875, 12.766666666666667, 13.061458333333334, 13.356250000000001, 13.651041666666668, 13.945833333333335, 14.240625000000001, 14.535416666666668, 14.830208333333335, 15.125000000000002, 15.419791666666667, 15.714583333333334, 16.009375, 16.304166666666667, 16.598958333333332, 16.89375, 17.188541666666666, 17.483333333333334, 17.778125, 18.072916666666668, 18.367708333333333, 18.6625, 18.957291666666666, 19.252083333333335, 19.546875, 19.841666666666665, 20.136458333333334, 20.43125, 20.726041666666667, 21.020833333333332, 21.315625, 21.610416666666666, 21.905208333333334, 22.2]}, '_timestamp': 1717516691.278213}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FP Reward Distribution': {'_type': 'histogram', 'values': [7, 2, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'bins': [3.4, 4.588541666666666, 5.777083333333334, 6.965624999999999, 8.154166666666667, 9.342708333333333, 10.53125, 11.719791666666667, 12.908333333333333, 14.096874999999999, 15.285416666666666, 16.473958333333332, 17.662499999999998, 18.851041666666664, 20.039583333333333, 21.228125, 22.416666666666664, 23.60520833333333, 24.793749999999996, 25.982291666666665, 27.17083333333333, 28.359374999999996, 29.547916666666666, 30.73645833333333, 31.924999999999997, 33.11354166666666, 34.30208333333333, 35.490624999999994, 36.67916666666667, 37.86770833333333, 39.05625, 40.244791666666664, 41.43333333333333, 42.621874999999996, 43.81041666666666, 44.99895833333333, 46.18749999999999, 47.376041666666666, 48.56458333333333, 49.753125, 50.94166666666666, 52.13020833333333, 53.318749999999994, 54.50729166666666, 55.69583333333333, 56.884375, 58.072916666666664, 59.26145833333333, 60.449999999999996, 61.63854166666666, 62.82708333333333, 64.015625, 65.20416666666667, 66.39270833333333, 67.58125, 68.76979166666666, 69.95833333333334, 71.14687500000001, 72.33541666666667, 73.52395833333334, 74.7125, 75.90104166666667, 77.08958333333334, 78.278125, 79.46666666666667]}, '_timestamp': 1717516691.2783601}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 1. Dropping entry: {'FN Reward Distribution': {'_type': 'histogram', 'values': [8, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'bins': [3.3333333333333335, 4.166666666666667, 5.0, 5.833333333333334, 6.666666666666666, 7.5, 8.333333333333334, 9.166666666666666, 10.0, 10.833333333333332, 11.666666666666666, 12.5, 13.333333333333334, 14.166666666666666, 15.0, 15.833333333333332, 16.666666666666664, 17.5, 18.333333333333332, 19.166666666666664, 19.999999999999996, 20.833333333333332, 21.666666666666664, 22.499999999999996, 23.333333333333332, 24.166666666666664, 24.999999999999996, 25.83333333333333, 26.666666666666664, 27.499999999999996, 28.33333333333333, 29.166666666666664, 29.999999999999996, 30.83333333333333, 31.666666666666664, 32.5, 33.33333333333333, 34.166666666666664, 35.0, 35.833333333333336, 36.666666666666664, 37.5, 38.333333333333336, 39.166666666666664, 40.0, 40.833333333333336, 41.666666666666664, 42.5, 43.333333333333336, 44.166666666666664, 45.0, 45.83333333333333, 46.666666666666664, 47.5, 48.33333333333333, 49.166666666666664, 50.0, 50.83333333333333, 51.666666666666664, 52.5, 53.33333333333333, 54.166666666666664, 55.0, 55.83333333333333, 56.666666666666664]}, '_timestamp': 1717516691.2784991}).
Epoch 970/1000, Train Loss: 0.4950448274612427, Val Loss: 0.22074294090270996, Train Acc: 0.8375, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 980/1000, Train Loss: 0.5301206260919571, Val Loss: 0.22274784743785858, Train Acc: 0.7625, Val Acc: 1.0, LR: 9.39985943758269e-06
Epoch 990/1000, Train Loss: 0.4687654376029968, Val Loss: 0.222940132021904, Train Acc: 0.8125, Val Acc: 1.0, LR: 9.39985943758269e-06
Finished training model...
Simulating on true reward function...
Running for a maximum of 11 generations...
 ****** Running generation 0 ******
Population's average fitness: 98.50333 stdev: 155.29137
Best fitness: 542.66667 - size: (4, 20) - species 1 - id 18
Average adjusted fitness: 0.171
Mean genetic distance 1.149, standard deviation 0.192
Population of 20 members in 1 species:
   ID   age  size  fitness  adj fit  stag
  ====  ===  ====  =======  =======  ====
     1    0    20    542.7    0.171     0
Total extinctions: 0
Generation time: 1.111 sec
 ****** Running generation 1 ******
[33m[W 2024-06-04 11:58:27,780][39m Trial 0 failed with parameters: {'hidden_size': 88, 'learning_rate': 0.0009399859437582644, 'weight_decay': 0.0005738979040170213} because of the following error: The value None could not be cast to float..
[33m[W 2024-06-04 11:58:27,780][39m Trial 0 failed with value None.
Traceback (most recent call last):
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 77, in <module>
    start_simulation("./config/agent_config.txt", args.generations[0])
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/main.py", line 17, in start_simulation
    run_population(
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 406, in run_population
    run_simulation,
  File "/Users/alextang/.pyenv/versions/nocturne_lab/lib/python3.10/site-packages/neat/population.py", line 89, in run
    fitness_function(list(iteritems(self.population)), self.config)
  File "/Users/alextang/Documents/EmergeLab/ai-car-preference-learning/agent.py", line 379, in run_simulation
    clock.tick(60)  # 60 FPS
KeyboardInterrupt